"""
Q-Quest é‡å­ç¥è¨— - Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
Human-Centric Quantum Philosophy
"""

import streamlit as st
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import itertools
import math
import random
import re
import time
from collections import Counter
import pandas as pd
import io
import os
import requests
import json

# Janome for Japanese morphological analysis (é•·æœŸçš„æ”¹å–„)
try:
    from janome.tokenizer import Tokenizer
    JANOME_AVAILABLE = True
except ImportError:
    JANOME_AVAILABLE = False
    Tokenizer = None

# Optuna for QUBO optimization visualization
try:
    import optuna
    from optuna.visualization import (
        plot_optimization_history,
        plot_param_importances,
        plot_parallel_coordinate,
        plot_contour,
        plot_slice,
        plot_timeline
    )
    OPTUNA_AVAILABLE = True
except ImportError:
    OPTUNA_AVAILABLE = False
    optuna = None
    # å¯è¦–åŒ–é–¢æ•°ã‚‚Noneã«è¨­å®š
    plot_optimization_history = None
    plot_param_importances = None
    plot_parallel_coordinate = None
    plot_contour = None
    plot_slice = None
    plot_timeline = None

# -------------------------
# æ–‡å­—åˆ—ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# -------------------------
def _split_multi_text(cell_value: str) -> List[str]:
    """Excelã‚»ãƒ«å†…ã®è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²ï¼ˆæ”¹è¡Œ / '||' åŒºåˆ‡ã‚Šå¯¾å¿œï¼‰"""
    if cell_value is None:
        return []
    s = str(cell_value).strip()
    if not s or s.lower() in ("nan", "none"):
        return []
    # '||' ã¨æ”¹è¡Œã‚’åŒä¸€è¦–ã—ã¦åˆ†å‰²
    s = s.replace("\r\n", "\n").replace("\r", "\n")
    parts: List[str] = []
    for chunk in s.split("||"):
        parts.extend([p.strip() for p in chunk.split("\n") if p.strip()])
    return [p for p in parts if p]

def _parse_tagged_quote(line: str) -> Dict[str, object]:
    """'ã‚¿ã‚°1,ã‚¿ã‚°2::æœ¬æ–‡' å½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹ã€‚ã‚¿ã‚°ãŒãªã‘ã‚Œã° tags=[]"""
    raw = (line or "").strip()
    if "::" in raw:
        tag_part, quote_part = raw.split("::", 1)
        tags = [t.strip() for t in tag_part.split(",") if t.strip()]
        quote = quote_part.strip()
        return {"text": quote, "tags": tags}
    return {"text": raw, "tags": []}

def extract_keywords_safe(text: str, top_n: int = 6, use_llm: bool = False, llm_type: str = "huggingface") -> List[str]:
    """UI/æœ€é©åŒ–ç”¨ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆå¤±æ•—ã—ã¦ã‚‚è½ã¨ã•ãªã„ + LLMã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"""
    try:
        keywords = extract_keywords(text, top_n=top_n, use_llm=use_llm, llm_type=llm_type)  # æ—¢å­˜é–¢æ•°ã‚’åˆ©ç”¨ï¼ˆå¾Œæ–¹ã§å®šç¾©ã•ã‚Œã‚‹ï¼‰
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæŠ½å‡ºã•ã‚Œãªã„å ´åˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
        if not keywords:
            t = (text or "").strip()
            if not t:
                return []
            # ç°¡æ˜“: 2æ–‡å­—ä»¥ä¸Šã®é€£ç¶šã‚’ä¸Šä½
            import re
            text_clean = re.sub(r'[0-9ï¼-ï¼™\W]+', ' ', t)
            words = text_clean.split()
            keywords = [w for w in words if len(w) >= 2][:top_n]
        return keywords
    except Exception:
        # extract_keywords å®šç¾©å‰ã«å‘¼ã°ã‚ŒãŸç­‰ã®ä¿é™º
        t = (text or "").strip()
        if not t:
            return []
        # ç°¡æ˜“: 2æ–‡å­—ä»¥ä¸Šã®é€£ç¶šã‚’ä¸Šä½
        tokens = [w for w in re.split(r"[\sã€ã€‚,.!ï¼?ï¼Ÿ]+", t) if len(w) >= 2]
        return tokens[:top_n]

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Q-Quest é‡å­ç¥è¨—",
    page_icon="ğŸ”®",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆStreamlitç”¨ï¼‰
import matplotlib
matplotlib.use('Agg')  # Streamlitã§ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰è¨­å®š

# -------------------------
# ãƒ‡ãƒ¼ã‚¿å®šç¾©
# -------------------------
# 12ç¥ã®å®šç¾©ã¨å±æ€§ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆç§‹è‘‰åŸãƒ†ãƒ¼ãƒï¼‰
# å„ç¥ã¯12å€‹ã®èª“é¡˜ï¼ˆèª“é¡˜01ï½12ï¼‰ã¨4ã¤ã®å½¹å‰²å±æ€§ï¼ˆé™ã€æµã€é–“ã€èª ï¼‰ã‚’æŒã¤
TWELVE_GODS = [
    {
        "id": 0,
        "name": "ç§‹è‘‰ä¸‰å°ºåŠ",
        "name_en": "Akiba Sanjakubo",
        "attribute": "ç«",
        "emoji": "ğŸ”¥",
        # èª“é¡˜01ï½12ã®æ•°å€¤é…ç½®ï¼ˆæ·»ä»˜è³‡æ–™ã‚ˆã‚Šï¼‰
        "vows": {
            "vow01": -0.4, "vow02": 0.2, "vow03": -0.2, "vow04": 0.0, "vow05": 0.0,
            "vow06": 0.0, "vow07": 0.0, "vow08": -0.4, "vow09": 0.0, "vow10": 0.0,
            "vow11": 0.0, "vow12": -0.2
        },
        # å½¹å‰²å±æ€§ï¼ˆé™ã€æµã€é–“ã€èª ï¼‰
        "roles": {"stillness": 0.0, "flow": -0.2, "ma": 0.0, "sincerity": -0.4},
        "maxim": "å‹¢ã„MAX: æƒ…ç†±çš„ãªç­†è‡´ã«é™è‡¨ã€‚",
        "description": "ç§‹è‘‰åŸã®å®ˆè­·ç¥ã€‚ç«ä¼ã›=ã€Œç‚ä¸Šå›é¿ã€ã®ç¥ã€‚"
    },
    {
        "id": 1,
        "name": "çœŸç©ºç®¡å¤§å°†è»",
        "name_en": "Vacuum Tube General",
        "attribute": "é›»",
        "emoji": "âš¡",
        "vows": {
            "vow01": -0.2, "vow02": 0.2, "vow03": 0.0, "vow04": -0.4, "vow05": -0.2,
            "vow06": 0.0, "vow07": 0.0, "vow08": 0.0, "vow09": 0.0, "vow10": 0.0,
            "vow11": 0.0, "vow12": -0.4
        },
        "roles": {"stillness": 0.0, "flow": -0.4, "ma": 0.0, "sincerity": -0.2},
        "maxim": "ç·šã®å¤ªã•: åŠ›å¼·ãã€å¤ªã„ç·šã«åå¿œã€‚",
        "description": "ç§‹è‘‰åŸã®åŸç‚¹ã€‚å¢—å¹…=ã€Œæ‰èƒ½é–‹èŠ±ã€ã®ç¥ã€‚"
    },
    {
        "id": 2,
        "name": "LEDå¼è²¡å¤©",
        "name_en": "LED Benzaiten",
        "attribute": "å…‰",
        "emoji": "ğŸ’¡",
        "vows": {
            "vow01": 0.0, "vow02": 0.2, "vow03": 0.0, "vow04": -0.4, "vow05": 0.0,
            "vow06": 0.0, "vow07": 0.0, "vow08": 0.0, "vow09": -0.4, "vow10": 0.0,
            "vow11": -0.2, "vow12": -0.2
        },
        "roles": {"stillness": 0.0, "flow": -0.4, "ma": -0.2, "sincerity": 0.0},
        "maxim": "ä¸¸ã¿: è¯ã‚„ã‹ã§æ›²ç·šçš„ãªç­†è·¡ã€‚",
        "description": "ã‚¤ãƒ«ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã¨ç™ºå…‰ã€‚ã€Œè‡ªå·±è¡¨ç¾ã€ã®ç¥ã€‚"
    },
    {
        "id": 3,
        "name": "ç£æ°—è¨˜éŒ²é»’é¾",
        "name_en": "Magnetic Recording Black Dragon",
        "attribute": "ç£",
        "emoji": "ğŸ‰",
        "vows": {
            "vow01": 0.0, "vow02": 0.0, "vow03": -0.4, "vow04": 0.0, "vow05": -0.2,
            "vow06": 0.0, "vow07": 0.0, "vow08": 0.0, "vow09": 0.0, "vow10": -0.4,
            "vow11": -0.2, "vow12": 0.2
        },
        "roles": {"stillness": -0.2, "flow": 0.0, "ma": 0.0, "sincerity": -0.4},
        "maxim": "ç·»å¯†ã•: ç´°ã‹ãä¸å¯§ãªæ›¸ãè¾¼ã¿ã€‚",
        "description": "HDDã‚„ãƒ†ãƒ¼ãƒ—ã€‚è¨˜æ†¶=ã€Œæ¸©æ•…çŸ¥æ–°ã€ã®å®ˆè­·é¾ã€‚"
    },
    {
        "id": 4,
        "name": "ç„¡ç·šå‚å—è¦³éŸ³",
        "name_en": "Wireless Interception Kannon",
        "attribute": "æ³¢",
        "emoji": "ğŸ“¡",
        "vows": {
            "vow01": -0.4, "vow02": 0.2, "vow03": 0.0, "vow04": -0.2, "vow05": -0.4,
            "vow06": 0.0, "vow07": 0.0, "vow08": 0.0, "vow09": 0.0, "vow10": 0.0,
            "vow11": 0.0, "vow12": -0.2
        },
        "roles": {"stillness": 0.0, "flow": -0.4, "ma": -0.2, "sincerity": 0.0},
        "maxim": "ã‚†ã‚‰ã: éœ‡ãˆã‚„è¿·ã„ãŒã‚ã‚‹ç­†è·¡ã«å¯„ã‚Šæ·»ã†ã€‚",
        "description": "é›»æ³¢ã¨é€šä¿¡ã€‚ç¸çµã³=ã€Œãƒãƒƒãƒãƒ³ã‚°ã€ã®ç¥ã€‚"
    },
    {
        "id": 5,
        "name": "åŸºæ¿æ›¼è¼ç¾…",
        "name_en": "Circuit Board Mandala",
        "attribute": "åŸº",
        "emoji": "ğŸ”Œ",
        "vows": {
            "vow01": 0.0, "vow02": -0.2, "vow03": 0.0, "vow04": 0.0, "vow05": 0.0,
            "vow06": -0.4, "vow07": -0.4, "vow08": 0.0, "vow09": 0.2, "vow10": -0.2,
            "vow11": 0.0, "vow12": 0.0
        },
        "roles": {"stillness": -0.4, "flow": 0.0, "ma": 0.0, "sincerity": -0.2},
        "maxim": "ç›´ç·šçš„: è¿·ã„ã®ãªã„ã€ã‚«ã‚¯ã‚«ã‚¯ã—ãŸç·šã€‚",
        "description": "å›è·¯è¨­è¨ˆã€‚ç§©åº=ã€Œè«–ç†çš„æ€è€ƒã€ã®ç¥ã€‚"
    },
    {
        "id": 6,
        "name": "çµ¶å¯¾é›¶åº¦æ˜ç‹",
        "name_en": "Absolute Zero Myo-o",
        "attribute": "å†·",
        "emoji": "â„ï¸",
        "vows": {
            "vow01": 0.0, "vow02": -0.4, "vow03": -0.2, "vow04": 0.0, "vow05": 0.0,
            "vow06": 0.0, "vow07": -0.4, "vow08": 0.0, "vow09": 0.0, "vow10": 0.0,
            "vow11": -0.2, "vow12": 0.2
        },
        "roles": {"stillness": -0.4, "flow": 0.0, "ma": -0.2, "sincerity": 0.0},
        "maxim": "ç­†åœ§å¼±ã‚: ã‚¯ãƒ¼ãƒ«ã§æ·¡ã€…ã¨ã—ãŸç­†è·¡ã€‚",
        "description": "å†·å´ãƒ•ã‚¡ãƒ³ãƒ»è¶…é›»å°ã€‚å†·é™=ã€Œæ²ˆç€å†·é™ã€ã®ç¥ã€‚"
    },
    {
        "id": 7,
        "name": "ã‚¸ãƒ£ãƒ³ã‚¯å†ç”Ÿç«¥å­",
        "name_en": "Junk Regeneration Child",
        "attribute": "å£Š",
        "emoji": "ğŸ”§",
        "vows": {
            "vow01": -0.2, "vow02": 0.0, "vow03": 0.0, "vow04": -0.2, "vow05": 0.0,
            "vow06": 0.0, "vow07": 0.2, "vow08": -0.4, "vow09": 0.0, "vow10": 0.0,
            "vow11": 0.0, "vow12": -0.4
        },
        "roles": {"stillness": 0.0, "flow": -0.4, "ma": 0.0, "sincerity": -0.2},
        "maxim": "ã‹ã™ã‚Œ: è’ã€…ã—ã„ã€ã¾ãŸã¯æ ã‚ŒãŸç·šã€‚",
        "description": "ç§‹è‘‰åŸã®ã‚¸ãƒ£ãƒ³ã‚¯å“ã€‚å¾©æ´»=ã€Œå†èµ·ãƒ»ãƒªãƒˆãƒ²ã€ã®ç¥ã€‚"
    },
    {
        "id": 8,
        "name": "çœŸç©ºã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå¦‚æ¥",
        "name_en": "Vacuum Audio Nyorai",
        "attribute": "éŸ³",
        "emoji": "ğŸ§",
        "vows": {
            "vow01": 0.0, "vow02": 0.0, "vow03": 0.0, "vow04": -0.2, "vow05": -0.4,
            "vow06": 0.0, "vow07": 0.2, "vow08": 0.0, "vow09": -0.2, "vow10": 0.0,
            "vow11": -0.4, "vow12": 0.0
        },
        "roles": {"stillness": 0.0, "flow": -0.4, "ma": -0.2, "sincerity": 0.0},
        "maxim": "èª¿å’Œ: æ–‡å­—å…¨ä½“ã®ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ã€‚",
        "description": "é«˜éŸ³è³ªãƒ»å…±é³´ã€‚ã€Œæœ¬è³ªã‚’è¦‹æ¥µã‚ã‚‹ã€ç¥ã€‚"
    },
    {
        "id": 9,
        "name": "ãƒãƒ³ãƒ€ä»˜ã‘çµã³ç¥",
        "name_en": "Soldering Connection Deity",
        "attribute": "çµ",
        "emoji": "ğŸ”—",
        "vows": {
            "vow01": 0.0, "vow02": -0.4, "vow03": -0.2, "vow04": 0.0, "vow05": -0.4,
            "vow06": 0.0, "vow07": -0.2, "vow08": 0.0, "vow09": 0.0, "vow10": 0.0,
            "vow11": 0.0, "vow12": 0.2
        },
        "roles": {"stillness": -0.2, "flow": 0.0, "ma": -0.4, "sincerity": 0.0},
        "maxim": "ãƒˆãƒ¡ãƒ»ãƒãƒ: ç¹‹ãéƒ¨åˆ†ãŒã—ã£ã‹ã‚Šã—ã¦ã„ã‚‹ã€‚",
        "description": "æ¥ç‚¹ã¨çµåˆã€‚å”åŠ›=ã€Œãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ã®ç¥ã€‚"
    },
    {
        "id": 10,
        "name": "å…‰é€Ÿé€šä¿¡éŸ‹é§„å¤©",
        "name_en": "Light-speed Communication Idaten",
        "attribute": "é€Ÿ",
        "emoji": "ğŸš€",
        "vows": {
            "vow01": 0.0, "vow02": 0.2, "vow03": 0.0, "vow04": -0.2, "vow05": -0.4,
            "vow06": 0.0, "vow07": 0.0, "vow08": 0.0, "vow09": -0.2, "vow10": 0.0,
            "vow11": 0.0, "vow12": -0.4
        },
        "roles": {"stillness": 0.0, "flow": -0.4, "ma": 0.0, "sincerity": -0.2},
        "maxim": "æ›¸ãé€Ÿåº¦: ã‚µãƒƒã¨çŸ­æ™‚é–“ã§æ›¸ã„ãŸç·šã€‚",
        "description": "5Gãƒ»å…‰å›ç·šã€‚çˆ†é€Ÿ=ã€Œå³æ–­å³æ±ºã€ã®ç¥ã€‚"
    },
    {
        "id": 11,
        "name": "åŠå°ä½“æ–‡æ®Š",
        "name_en": "Semiconductor Manjushri",
        "attribute": "æ™º",
        "emoji": "ğŸ§ ",
        "vows": {
            "vow01": 0.0, "vow02": 0.0, "vow03": -0.2, "vow04": 0.0, "vow05": 0.0,
            "vow06": -0.4, "vow07": -0.2, "vow08": 0.0, "vow09": 0.0, "vow10": -0.4,
            "vow11": 0.0, "vow12": 0.2
        },
        "roles": {"stillness": -0.4, "flow": 0.0, "ma": 0.0, "sincerity": -0.2},
        "maxim": "è¦å‰‡æ€§: ç­‰é–“éš”ã§æ•´ç†ã•ã‚ŒãŸç­†è·¡ã€‚",
        "description": "CPUãƒ»AIã€‚è¨ˆç®—=ã€Œåˆæ ¼ãƒ»çŸ¥ç•¥ã€ã®ç¥ã€‚"
    },
]

# æ°—æŒã¡ã‚’æ•´ãˆã‚‹ãŸã‚ã®æ ¼è¨€ï¼ˆVARIABLESï¼‰ã‚’12ç¥ã®æ ¼è¨€ã«æ›´æ–°
VARIABLES = [god["maxim"] for god in TWELVE_GODS]

# æ„Ÿè¦šå±¤ã®å¤‰æ•°å®šç¾©ï¼ˆæ·»ä»˜è³‡æ–™ã‚ˆã‚Šï¼‰
SENSATION_VARIABLES = [
    "è¿·ã„",      # x1: Hesitation/Confusion
    "ç„¦ã‚Š",      # x2: Impatience/Anxiety
    "é™ã‘ã•",    # x3: Stillness/Calmness
    "å†…çœ",      # x4: Introspection
    "è¡Œå‹•",      # x5: Action
    "ã¤ãªãŒã‚Š",  # x6: Connection
    "æŒ‘æˆ¦",      # x7: Challenge
    "å¾…ã¤",      # x8: Wait
]

# æ ¼è¨€ã®å¼•ç”¨å…ƒï¼ˆ12ç¥ã®æ ¼è¨€ã«å¯¾å¿œï¼‰
MAXIM_SOURCES = {god["maxim"]: {
    "source": god["name"],
    "origin": god["name_en"],
    "reference": god["description"]
} for god in TWELVE_GODS}

GLOBAL_WORDS_DATABASE = [
    # é¡˜ã„ãƒ»ç›®æ¨™
    "ä¸–ç•Œå¹³å’Œ", "è²¢çŒ®", "æˆé•·", "å­¦ã³", "æŒ‘æˆ¦", "å¤¢", "å¸Œæœ›", "æœªæ¥",
    # æ„Ÿæƒ…ãƒ»çŠ¶æ…‹
    "æ„Ÿè¬", "æ„›", "å¹¸ã›", "å–œã³", "å®‰å¿ƒ", "å……å®Ÿ", "æº€è¶³", "å¹³å’Œ",
    # è¡Œå‹•ãƒ»å§¿å‹¢
    "åŠªåŠ›", "ç¶™ç¶š", "å¿è€", "èª å®Ÿ", "æ­£ç›´", "å„ªã—ã•", "æ€ã„ã‚„ã‚Š", "å…±æ„Ÿ",
    # å“²å­¦ãƒ»æ¦‚å¿µ
    "èª¿å’Œ", "ãƒãƒ©ãƒ³ã‚¹", "è‡ªç„¶", "ç¾", "çœŸå®Ÿ", "è‡ªç”±", "æ­£ç¾©", "é“",
    # é–¢ä¿‚æ€§
    "çµ†", "ã¤ãªãŒã‚Š", "å®¶æ—", "å‹äºº", "ä»²é–“", "ä¿¡é ¼", "å°Šæ•¬", "å”åŠ›", "å¤«å©¦", "ç”Ÿæ´»", "å††æº€",
    # æ™‚é–“ãƒ»æµã‚Œ
    "ä»Š", "ç¬é–“", "éç¨‹", "å¤‰åŒ–", "é€²åŒ–", "ç™ºå±•", "å¾ªç’°", "æµã‚Œ",
    # å†…çš„çŠ¶æ…‹
    "é™ã‘ã•", "é›†ä¸­", "è¦šæ‚Ÿ", "æ±ºæ„", "å‹‡æ°—", "å¼·ã•", "æŸ”è»Ÿæ€§", "å¯›å®¹",
]

FAMOUS_QUOTES = [
    {
        "keywords": ["å¹³å’Œ", "ä¸–ç•Œ", "è²¢çŒ®", "å¸Œæœ›"], 
        "quote": "é›ªã®ä¸‹ã§ç¨®ã¯æ˜¥ã‚’å¾…ã£ã¦ã„ã‚‹ã€‚ç„¦ã‚‹ã¹ã‹ã‚‰ãšã€æ™‚æº€ã¡ã‚‹ã‚’å¾…ã¦ã€‚",
        "source": "æ—¥æœ¬ã®å¤èªãƒ»ã“ã¨ã‚ã–",
        "origin": "è‡ªç„¶ã®æ‘‚ç†ã‚’èª¬ãä¼çµ±çš„ãªæ•™ãˆ",
        "reference": "å­£ç¯€ã®å¾ªç’°ã¨å¿è€ã®é‡è¦æ€§ã‚’è¡¨ç¾"
    },
    {
        "keywords": ["æˆé•·", "åŠªåŠ›", "ç¶™ç¶š", "æŒ‘æˆ¦"], 
        "quote": "åƒé‡Œã®é“ã‚‚ä¸€æ­©ã‹ã‚‰ã€‚æ­©ã¿ã‚’æ­¢ã‚ãšã€ç¶šã‘ã‚‹ã“ã¨ã«æ„å‘³ãŒã‚ã‚‹ã€‚",
        "source": "è€å­ã€é“å¾³çµŒã€",
        "origin": "ç¬¬å…­åå››ç« ",
        "reference": "ã€Œåƒé‡Œã®è¡Œã‚‚è¶³ä¸‹ã«å§‹ã¾ã‚‹ã€ã«åŸºã¥ã"
    },
    {
        "keywords": ["æ„Ÿè¬", "æ„›", "çµ†", "ã¤ãªãŒã‚Š"], 
        "quote": "ä¸€æœŸä¸€ä¼šã€‚ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚",
        "source": "åƒåˆ©ä¼‘ã®èŒ¶é“ç²¾ç¥",
        "origin": "ã€Œä¸€æœŸä¸€ä¼šã€ã®æ€æƒ³",
        "reference": "åƒåˆ©ä¼‘ã«é€£ãªã‚‹èŒ¶é“ã®æ•™ãˆã€Œä¸€æœŸä¸€ä¼šã€ã¨ç¸ã®æ¦‚å¿µ"
    },
    {
        "keywords": ["è‡ªç„¶", "èª¿å’Œ", "ãƒãƒ©ãƒ³ã‚¹", "æµã‚Œ"], 
        "quote": "æ°´ã¯ã€äº‰ã‚ãªã„ã€‚å½¢ã«ã“ã ã‚ã‚‰ãšã€æµã‚Œã‚‹ãŒã¾ã¾ã«ã€‚",
        "source": "è€å­ã€é“å¾³çµŒã€",
        "origin": "ç¬¬å…«ç« ã€Œä¸Šå–„è‹¥æ°´ã€",
        "reference": "ã€Œä¸Šå–„ã¯æ°´ã®è‹¥ã—ã€‚æ°´ã¯å–„ãä¸‡ç‰©ã‚’åˆ©ã—ã¦äº‰ã‚ãšã€"
    },
    {
        "keywords": ["é™ã‘ã•", "é›†ä¸­", "ä»Š", "ç¬é–“"], 
        "quote": "æ­¢ã¾ã‚‹ã“ã¨ã§ã€æµã‚ŒãŒè¦‹ãˆã‚‹ã€‚å‹•ã®ä¸­ã«é™ãŒã‚ã‚‹ã€‚",
        "source": "ç¦…ã®æ€æƒ³",
        "origin": "ç¦…å®—ã®æ•™ãˆã‹ã‚‰",
        "reference": "å‹•ã¨é™ã®èª¿å’Œã‚’èª¬ãç¦…ã®æ•™ç¾©ã«åŸºã¥ã"
    },
    {
        "keywords": ["å‹‡æ°—", "æ±ºæ„", "æŒ‘æˆ¦", "é“"], 
        "quote": "é“ãŒåˆ†ã‚Œã¦ã„ãŸã‚‰ã€å¿µãŒãªã„æ–¹ã¸è¡Œã‘ã€‚",
        "source": "æŸ³ã®ã“ã¨ã°ï¼ˆå‰µä½œï¼‰",
        "origin": "æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å‰µä½œ",
        "reference": "ç¦…çš„æ€è€ƒã«åŸºã¥ãå‰µä½œæ ¼è¨€"
    },
    {
        "keywords": ["æ€ã„ã‚„ã‚Š", "å„ªã—ã•", "å…±æ„Ÿ", "ä¿¡é ¼"], 
        "quote": "äººã®å¿ƒã«å¯„ã‚Šæ·»ã†ã€‚ãã‚ŒãŒçœŸã®å¼·ã•ã§ã‚ã‚‹ã€‚",
        "source": "æ—¥æœ¬ã®ä¼çµ±çš„ä¾¡å€¤è¦³",
        "origin": "å’Œã®ç²¾ç¥",
        "reference": "ä»–è€…ã¸ã®å…±æ„Ÿã¨å¯„ã‚Šæ·»ã„ã‚’é‡è¦–ã™ã‚‹æ—¥æœ¬ã®æ–‡åŒ–"
    },
    {
        "keywords": ["å¤‰åŒ–", "é€²åŒ–", "ç™ºå±•", "æœªæ¥"], 
        "quote": "ç„¡ç‚ºã«ã—ã¦ç‚ºã™ã€‚å‹•ãã“ã¨ãŒé™ã§ã‚ã‚‹ã€‚",
        "source": "è€å­ã€é“å¾³çµŒã€",
        "origin": "ç¬¬ä¸‰åä¸ƒç« ",
        "reference": "ã€Œé“ã¯å¸¸ã«ç„¡ç‚ºã«ã—ã¦ç‚ºã•ãšã€ã«åŸºã¥ãç„¡ç‚ºè‡ªç„¶ã®æ€æƒ³"
    },
    {
        "keywords": ["ç¾", "çœŸå®Ÿ", "è‡ªç„¶", "èª¿å’Œ"], 
        "quote": "é–“ã“ããŒç­”ãˆã§ã‚ã‚‹ã€‚ä½™ç™½ã«ã“ãæœ¬è³ªãŒã‚ã‚‹ã€‚",
        "source": "æ—¥æœ¬ã®ç¾å­¦æ€æƒ³",
        "origin": "ã€Œé–“ï¼ˆMaï¼‰ã€ã®æ¦‚å¿µ",
        "reference": "èƒ½æ¥½ã€èŒ¶é“ã€ä¿³å¥ãªã©ã«é€šåº•ã™ã‚‹æ—¥æœ¬ã®ç¾æ„è­˜"
    },
    {
        "keywords": ["è‡ªç”±", "æ­£ç¾©", "é“", "èª å®Ÿ"], 
        "quote": "å·±ã«èª å®Ÿã§ã‚ã‚‹ã“ã¨ã€‚ãã‚ŒãŒè‡ªç”±ã¸ã®é“ã§ã‚ã‚‹ã€‚",
        "source": "ã‚¨ãƒ”ã‚¯ãƒ†ãƒˆã‚¹ã€èªéŒ²ã€",
        "origin": "ã‚¹ãƒˆã‚¢æ´¾å“²å­¦",
        "reference": "ã€Œè‡ªåˆ†è‡ªèº«ã«å¯¾ã—ã¦èª å®Ÿã§ã‚ã‚‹ã“ã¨ã“ãã€çœŸã®è‡ªç”±ã«ã¤ãªãŒã‚‹ã€ã¨ã„ã†æ€æƒ³"
    },
]

SEASONS = ["è–„æ°·", "ç«‹æ˜¥", "æ˜¥éœ", "è‹¥è‘‰", "å¤•ç«‹", "ç§‹å£°", "æœ¨æ¯ã‚‰ã—", "é›ªæ˜ã‚Š"]

# Moodã«å¿œã˜ãŸæ¬¡ã®ä¸€æ­©ã®ææ¡ˆ
NEXT_STEPS_BY_MOOD = {
    "fatigue": [
        "ä¸€ã¤ã ã‘ã€ä»Šæ—¥ã‚„ã‚‹ã“ã¨ã‚’æ¸›ã‚‰ã—ãªã•ã„ã€‚",
        "é å›ã‚Šã‚’é¸ã³ãªã•ã„ã€‚ç­”ãˆã¯é“ã®é€”ä¸­ã«ã‚ã‚‹ã€‚",
        "æ±ºã‚ãªãã¦ã‚ˆã„ã€‚ä¿ç•™ã¯ã€ç«‹æ´¾ãªé¸æŠã§ã‚ã‚‹ã€‚",
    ],
    "anxiety": [
        "è©±ã™ãªã‚‰ã€Œçµè«–ã€ã‚ˆã‚Šã€Œæ°—é…ã€ã‚’æ¸¡ã—ãªã•ã„ã€‚",
        "å¢ƒç•Œï¼ˆã—ãã„ï¼‰ã‚’è¶Šãˆã‚‹ã®ã¯ã€é™ã‹ãªä¸€æ­©ã§ã‚ˆã„ã€‚",
        "æ°´ã®ã‚ˆã†ã«æµã‚Œã‚‹ãŒã¾ã¾ã«ã€‚å½¢ã«ã“ã ã‚ã‚‰ãªã„ã€‚",
    ],
    "curiosity": [
        "åƒé‡Œã®é“ã‚‚ä¸€æ­©ã‹ã‚‰ã€‚æ­©ã¿ã‚’æ­¢ã‚ãšã€ç¶šã‘ã‚‹ã“ã¨ã«æ„å‘³ãŒã‚ã‚‹ã€‚",
        "æˆé•·ã¯éç¨‹ã«ã‚ã‚Šã€‚ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚",
        "æŒ‘æˆ¦ã™ã‚‹å‹‡æ°—ã“ããŒã€æœªæ¥ã‚’é–‹ãéµã§ã‚ã‚‹ã€‚",
    ],
    "loneliness": [
        "ä¸€æœŸä¸€ä¼šã€‚ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚",
        "äººã®å¿ƒã«å¯„ã‚Šæ·»ã†ã€‚ãã‚ŒãŒçœŸã®å¼·ã•ã§ã‚ã‚‹ã€‚",
        "çµ†ã¯è¦‹ãˆãªãã¦ã‚‚ã€ãã“ã«ã‚ã‚‹ã€‚",
    ],
    "decisiveness": [
        "æ±ºã‚ãªãã¦ã‚ˆã„ã€‚ä¿ç•™ã¯ã€ç«‹æ´¾ãªé¸æŠã§ã‚ã‚‹ã€‚",
        "å·±ã«èª å®Ÿã§ã‚ã‚‹ã“ã¨ã€‚ãã‚ŒãŒè‡ªç”±ã¸ã®é“ã§ã‚ã‚‹ã€‚",
        "é“ãŒåˆ†ã‚Œã¦ã„ãŸã‚‰ã€å¿µãŒãªã„æ–¹ã¸è¡Œã‘ã€‚",
    ],
    "default": [
        "ä¸€ã¤ã ã‘ã€ä»Šæ—¥ã‚„ã‚‹ã“ã¨ã‚’æ¸›ã‚‰ã—ãªã•ã„ã€‚",
        "é å›ã‚Šã‚’é¸ã³ãªã•ã„ã€‚ç­”ãˆã¯é“ã®é€”ä¸­ã«ã‚ã‚‹ã€‚",
        "è©±ã™ãªã‚‰ã€Œçµè«–ã€ã‚ˆã‚Šã€Œæ°—é…ã€ã‚’æ¸¡ã—ãªã•ã„ã€‚",
        "æ±ºã‚ãªãã¦ã‚ˆã„ã€‚ä¿ç•™ã¯ã€ç«‹æ´¾ãªé¸æŠã§ã‚ã‚‹ã€‚",
        "å¢ƒç•Œï¼ˆã—ãã„ï¼‰ã‚’è¶Šãˆã‚‹ã®ã¯ã€é™ã‹ãªä¸€æ­©ã§ã‚ˆã„ã€‚"
    ]
}

# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼ˆå¤ã„ã‚³ãƒ¼ãƒ‰ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
NEXT_STEPS = NEXT_STEPS_BY_MOOD["default"]

# -------------------------
# QUBOé–¢é€£é–¢æ•°
# -------------------------
def qubo_energy(x: np.ndarray, Q: Dict[Tuple[int,int], float]) -> float:
    """QUBOã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’è¨ˆç®—"""
    e = 0.0
    n = len(x)
    for i in range(n):
        e += Q.get((i,i), 0.0) * x[i]
    for i in range(n):
        for j in range(i+1, n):
            e += Q.get((i,j), 0.0) * x[i] * x[j]
    return float(e)

def bitstring(x: np.ndarray) -> str:
    return "".join(str(int(v)) for v in x)

# -------------------------
# Moodæ¨å®š
# -------------------------
@dataclass
class Mood:
    fatigue: float
    anxiety: float
    curiosity: float
    loneliness: float
    decisiveness: float

KEYWORDS = {
    "fatigue": ["ç–²", "ã—ã‚“ã©", "çœ ", "ã ã‚‹", "æ¶ˆè€—", "é™ç•Œ", "ä½“èª¿", "é‡", "å‹•ã‘ãªã„"],
    "anxiety": [
        "ä¸å®‰", "ç„¦", "æ€–", "å¿ƒé…", "è¿·", "è½ã¡ç€ã‹", "ç·Šå¼µ", "æ°—ã«ãªã‚‹", 
        "è‡ªä¿¡", "æŒã¦ãªã„", "è¨€è‘‰", "ä»–è€…", "è©•ä¾¡", "ç›®", "å‘¨ã‚Š", "ã©ã†æ€",
        "å¤±æ•—", "é–“é•ã„", "å¦å®š", "æ‰¹åˆ¤", "ä¸å®‰", "æ", "æ€¯"
    ],
    "curiosity": [
        "ã‚„ã£ã¦ã¿", "èˆˆå‘³", "é¢ç™½", "å­¦ã³", "è©¦", "æŒ‘æˆ¦", "ãƒ¯ã‚¯ãƒ¯ã‚¯", "çŸ¥ã‚ŠãŸã„", "æ¢ç´¢",
        "æˆé•·", "å‘ä¸Š", "é€²åŒ–", "é«˜ã‚", "ä¼¸ã°ã™", "æ”¹å–„", "ç™ºå±•", "é€²æ­©", "å‰é€²", "å¸¸ã«"
    ],
    "loneliness": ["å­¤ç‹¬", "ä¸€äºº", "å¯‚", "èª°ã«ã‚‚", "åˆ†ã‹ã£ã¦", "è©±ã›", "å­¤ç«‹", "ç–å¤–"],
    "decisiveness": [
        "æ±ºã‚", "çµè«–", "é¸", "åˆ¤æ–­", "æ–­", "æ–¹é‡", "æœŸé™", "æ±ºæ–­",
        "è‡ªä¿¡", "æŒã¦ãªã„", "è¿·ã†", "æ‚©ã‚€", "èºŠèº‡", "ãŸã‚ã‚‰", "å„ªæŸ”ä¸æ–­"
    ],
    # ã€è¿½åŠ ã€‘é¡˜ã„ãƒ»ç¥ˆã‚Šãƒ»å¸Œæœ›ã®ã‚«ãƒ†ã‚´ãƒª
    "wish": [
        "é¡˜ã„", "ç¥ˆã‚Š", "å¸Œæœ›", "é¡˜ã†", "ç¥ˆã‚‹", "æœ›ã‚€", "é¡˜æœ›", "åˆ‡æœ›",
        "ã§ã‚ã‚Šã¾ã™ã‚ˆã†ã«", "ã‚ˆã†ã«", "ã§ã‚ã‚Šã¾ã™", "ã‚ã‚Šã¾ã™ã‚ˆã†ã«",
        "ã§ãã¾ã™ã‚ˆã†ã«", "ãªã‚Šã¾ã™ã‚ˆã†ã«", "éã”ã›ã¾ã™ã‚ˆã†ã«"
    ],
    # ã€è¿½åŠ ã€‘å®¶æ—ãƒ»é–¢ä¿‚æ€§ã®ã‚«ãƒ†ã‚´ãƒª
    "family": [
        "å®¶æ—", "å¤«å©¦", "è¦ª", "å­", "å…„å¼Ÿ", "å§‰å¦¹", "ç¥–çˆ¶æ¯", "è¦ªæˆš",
        "å®¶åº­", "ç”Ÿæ´»", "å††æº€", "ä»²è‰¯ã", "å¹¸ã›", "å¹³å’Œ", "èª¿å’Œ",
        "çµ†", "ã¤ãªãŒã‚Š", "æ„›æƒ…", "æ€ã„ã‚„ã‚Š", "æ”¯ãˆ", "å”åŠ›"
    ],
    # ã€è¿½åŠ ã€‘å¥åº·ãƒ»ä½“èª¿ã®ã‚«ãƒ†ã‚´ãƒª
    "health": [
        "å¥åº·", "ä½“èª¿", "èº«ä½“", "ä½“", "ç—…æ°—", "æ²»ç™‚", "å›å¾©", "å…ƒæ°—",
        "éã”ã—ãŸã„", "éã”ã›ã¾ã™ã‚ˆã†ã«", "å¥ã‚„ã‹", "ä¸ˆå¤«", "å¼·ã"
    ],
    # ã€è¿½åŠ ã€‘ä»•äº‹ãƒ»ã‚­ãƒ£ãƒªã‚¢ã®ã‚«ãƒ†ã‚´ãƒª
    "work": [
        "ä»•äº‹", "è·å ´", "ã‚­ãƒ£ãƒªã‚¢", "åƒã", "å°±è·", "è»¢è·", "æ˜‡é€²",
        "æˆåŠŸ", "æˆæœ", "é”æˆ", "ç›®æ¨™", "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ", "æ¥­å‹™"
    ],
    # ã€è¿½åŠ ã€‘å­¦ã³ãƒ»æˆé•·ã®ã‚«ãƒ†ã‚´ãƒª
    "learning": [
        "å­¦ã³", "å­¦ç¿’", "å‹‰å¼·", "æ•™è‚²", "çŸ¥è­˜", "ã‚¹ã‚­ãƒ«", "å‘ä¸Š",
        "æˆé•·", "ç™ºå±•", "é€²æ­©", "ç¿’å¾—", "ç†è§£", "è¦šãˆã‚‹"
    ],
}

def score_from_text(text: str, keys: List[str]) -> float:
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œç´¢ã—ã¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
    s = 0.0
    text_lower = text.lower()  # ä¸€åº¦ã ã‘å°æ–‡å­—åŒ–
    
    for k in keys:
        k_lower = k.lower()
        # éƒ¨åˆ†ãƒãƒƒãƒã§æ¤œç´¢
        matches = len(re.findall(re.escape(k_lower), text_lower))
        if matches > 0:
            # ãƒãƒƒãƒã—ãŸå›æ•°ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢ã‚’åŠ ç®—
            base_score = matches * 0.5  # åŸºæœ¬ã‚¹ã‚³ã‚¢
            # é•·ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã¯è¿½åŠ ã®é‡ã¿
            if len(k) >= 3:
                base_score += 0.5
            if len(k) >= 4:
                base_score += 0.3
            s += base_score
    
    return float(s)

def infer_mood(text: str) -> Mood:
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å¿ƒã®å‚¾ãï¼ˆMoodï¼‰ã‚’æ¨å®šï¼ˆæ”¹å–„ç‰ˆï¼šã‚ˆã‚Šæ•æ„Ÿã§å¤šæ§˜ãªæ¤œå‡ºï¼‰"""
    t = text.strip()
    if not t:
        # ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆã€å…¨ã¦0.0ã‚’è¿”ã™
        return Mood(0.0, 0.0, 0.0, 0.0, 0.0)
    
    raw = {k: score_from_text(t, v) for k, v in KEYWORDS.items()}
    
    # å…¨ã¦ã®ã‚¹ã‚³ã‚¢ã®æœ€å¤§å€¤ã‚’è¨ˆç®—ï¼ˆç›¸å¯¾çš„ãªæ­£è¦åŒ–ã®ãŸã‚ï¼‰
    max_raw = max(raw.values()) if max(raw.values()) > 0 else 1.0
    
    # æ­£è¦åŒ–é–¢æ•°ï¼ˆç›¸å¯¾çš„ãªæ­£è¦åŒ–ã¨çµ¶å¯¾çš„ãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®çµ„ã¿åˆã‚ã›ï¼‰
    def norm(x: float, scale: float = 1.5, use_relative: bool = True) -> float:
        if x == 0.0:
            return 0.0
        
        # ç›¸å¯¾çš„ãªæ­£è¦åŒ–ï¼ˆä»–ã®Moodã¨ã®æ¯”è¼ƒï¼‰
        if use_relative and max_raw > 0:
            relative = x / max_raw
        else:
            relative = 1.0
        
        # çµ¶å¯¾çš„ãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ã«åŸºã¥ãï¼‰
        absolute = min(1.0, x / scale)
        
        # ä¸¡æ–¹ã‚’çµ„ã¿åˆã‚ã›ã¦ã€ã‚ˆã‚Šè±Šã‹ãªè¡¨ç¾ã‚’å®Ÿç¾
        combined = (relative * 0.6 + absolute * 0.4)
        
        # æœ€å°å€¤ã®ç¢ºä¿ï¼ˆ0.0ã§ãªã„é™ã‚Šã€ã‚ã‚‹ç¨‹åº¦ã®å€¤ã‚’ä¿è¨¼ï¼‰
        if x > 0:
            combined = max(0.15, min(1.0, combined))
        
        return combined
    
    # å„Moodå€¤ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’å€‹åˆ¥ã«èª¿æ•´ï¼ˆã‚ˆã‚Šæ•æ„Ÿãªæ¤œå‡ºï¼‰
    return Mood(
        fatigue=norm(raw["fatigue"], scale=1.2),  # ç–²ã‚Œã¯æ•æ„Ÿã«æ¤œå‡º
        anxiety=norm(raw["anxiety"], scale=1.0),  # ä¸å®‰ã¯æœ€ã‚‚æ•æ„Ÿã«
        curiosity=norm(raw["curiosity"], scale=1.3),
        loneliness=norm(raw["loneliness"], scale=1.2),
        decisiveness=norm(raw["decisiveness"], scale=1.1),  # æ±ºæ–­åŠ›ã‚‚æ•æ„Ÿã«
    )

def mood_to_sensation_vector(m: Mood, binary: bool = False, scale: float = 5.0) -> np.ndarray:
    """Moodã‹ã‚‰æ„Ÿè¦šãƒ™ã‚¯ãƒˆãƒ«ï¼ˆx1ï½x8ï¼‰ã‚’ç”Ÿæˆ
    
    Args:
        m: Moodã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        binary: Trueã®å ´åˆã€ãƒã‚¤ãƒŠãƒªåŒ–ï¼ˆ0.3ä»¥ä¸Šã§1ã€ãã‚Œä»¥ä¸‹ã§0ï¼‰
        scale: æ„Ÿè¦šãƒ™ã‚¯ãƒˆãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆ0ã€œscaleã®ç¯„å›²ã«æ­£è¦åŒ–ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5.0ï¼‰
    
    Returns:
        æ„Ÿè¦šãƒ™ã‚¯ãƒˆãƒ«ï¼ˆ8æ¬¡å…ƒï¼‰
        - x0: è¿·ã„, x1: ç„¦ã‚Š, x2: é™ã‘ã•, x3: å†…çœ, x4: è¡Œå‹•, x5: ã¤ãªãŒã‚Š, x6: æŒ‘æˆ¦, x7: å¾…ã¤
    """
    # æ„Ÿè¦šå¤‰æ•°ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    x = np.zeros(8)
    
    # è¿·ã„ï¼ˆx0ï¼‰: ä¸å®‰ã¨æ±ºæ–­åŠ›ã®ä½ã•ã‹ã‚‰
    x[0] = m.anxiety * (1.0 - m.decisiveness)
    
    # ç„¦ã‚Šï¼ˆx1ï¼‰: ä¸å®‰ã‹ã‚‰
    x[1] = m.anxiety
    
    # é™ã‘ã•ï¼ˆx2ï¼‰: ç–²ã‚Œã¨å­¤ç‹¬ã‹ã‚‰
    x[2] = (m.fatigue + m.loneliness) / 2.0
    
    # å†…çœï¼ˆx3ï¼‰: å­¤ç‹¬ã¨ç–²ã‚Œã‹ã‚‰
    x[3] = (m.loneliness + m.fatigue) / 2.0
    
    # è¡Œå‹•ï¼ˆx4ï¼‰: å¥½å¥‡å¿ƒã¨æ±ºæ–­åŠ›ã‹ã‚‰
    x[4] = (m.curiosity + m.decisiveness) / 2.0
    
    # ã¤ãªãŒã‚Šï¼ˆx5ï¼‰: å­¤ç‹¬ã®é€†ã¨å¥½å¥‡å¿ƒã‹ã‚‰
    x[5] = (1.0 - m.loneliness) * m.curiosity
    
    # æŒ‘æˆ¦ï¼ˆx6ï¼‰: å¥½å¥‡å¿ƒã¨æ±ºæ–­åŠ›ã‹ã‚‰
    x[6] = m.curiosity * m.decisiveness
    
    # å¾…ã¤ï¼ˆx7ï¼‰: ç–²ã‚Œã¨æ±ºæ–­åŠ›ã®ä½ã•ã‹ã‚‰
    x[7] = m.fatigue * (1.0 - m.decisiveness)
    
    # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´ï¼ˆ0ã€œscaleã®ç¯„å›²ã«æ­£è¦åŒ–ï¼‰
    x = x * scale
    
    if binary:
        # ãƒã‚¤ãƒŠãƒªåŒ–ï¼ˆé–¾å€¤0.3*scaleä»¥ä¸Šã§1ã€ãã‚Œä»¥ä¸‹ã§0ï¼‰
        x_binary = (x >= 0.3 * scale).astype(float)
        return x_binary
    else:
        # é€£ç¶šå€¤ã®ã¾ã¾è¿”ã™ï¼ˆ0ã€œscaleã®ç¯„å›²ï¼‰
        return x

# -------------------------
# Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æ©Ÿèƒ½
# -------------------------
# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ï¼šExcelã‹ã‚‰èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒ
SENSE_TO_VOW_MATRIX: Optional[np.ndarray] = None  # sense_to_vowè¡Œåˆ—ï¼ˆ8x12ï¼šæ„Ÿè¦š Ã— èª“é¡˜ï¼‰
K_MATRIX: Optional[np.ndarray] = None  # kè¡Œåˆ—ï¼ˆ12x12ï¼šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ Ã— èª“é¡˜ï¼‰
L_MATRIX: Optional[np.ndarray] = None  # lè¡Œåˆ—ï¼ˆ12x4ï¼šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ Ã— ä¸–ç•Œè¦³è»¸ï¼‰
LOADED_GODS: Optional[List[Dict]] = None  # Excelã‹ã‚‰èª­ã¿è¾¼ã‚“ã 12ç¥ã®æƒ…å ±
CHAR_MASTER: Optional[pd.DataFrame] = None  # CHAR_MASTERã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿
SELECTED_ATTRIBUTE: Optional[str] = None  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠã—ãŸå±æ€§
SELECTED_CHARACTER: Optional[str] = None  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠã—ãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ï¼ˆå…¬å¼ã‚­ãƒ£ãƒ©åï¼‰
MAXIMS_DATABASE: Optional[List[Dict]] = None  # æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚“ã æ ¼è¨€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹

def rebuild_globals_from_gods(gods_list: List[Dict]) -> None:
    """TWELVE_GODS å¤‰æ›´å¾Œã«ã€VARIABLES / MAXIM_SOURCES ã‚’å†ç”Ÿæˆ"""
    global VARIABLES, MAXIM_SOURCES
    VARIABLES = [god.get("maxim", "") for god in gods_list]
    # ã™ã¹ã¦ã®æ ¼è¨€ï¼ˆè¤‡æ•°ï¼‰ã‚‚å‡ºå…¸ã«è¼‰ã›ã‚‹
    maxim_sources: Dict[str, Dict] = {}
    for god in gods_list:
        # å˜ä¸€æ ¼è¨€
        if god.get("maxim"):
            maxim_sources[god["maxim"]] = {
                "source": god.get("name", "ç¥è¨—"),
                "origin": god.get("name_en", ""),
                "reference": god.get("description", ""),
            }
        # è¤‡æ•°æ ¼è¨€
        for item in god.get("maxims", []) or []:
            text = (item.get("text") if isinstance(item, dict) else str(item)).strip()
            if text:
                maxim_sources[text] = {
                    "source": god.get("name", "ç¥è¨—"),
                    "origin": god.get("name_en", ""),
                    "reference": god.get("description", ""),
                }
    MAXIM_SOURCES = maxim_sources

def load_gods_from_separate_files(
    character_file: io.BytesIO = None,
    k_matrix_file: io.BytesIO = None,
    l_matrix_file: io.BytesIO = None
) -> Tuple[List[Dict], np.ndarray, np.ndarray]:
    """3ã¤ã®åˆ¥ã€…ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰12ç¥ã®æƒ…å ±ã€kè¡Œåˆ—ã€lè¡Œåˆ—ã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        character_file: 12ç¥åŸºæœ¬æƒ…å ±ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆakiba12_character_list.xlsxï¼‰
        k_matrix_file: kè¡Œåˆ—ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆakiba12_character_to_vow_K.xlsxï¼‰
        l_matrix_file: lè¡Œåˆ—ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆakiba12_character_to_axis_L.xlsxï¼‰
    
    Returns:
        (gods_list, k_matrix, l_matrix)
    """
    try:
        # kè¡Œåˆ—ã‚’èª­ã¿è¾¼ã‚€ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã‚’è¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦ä½¿ç”¨ï¼‰
        if k_matrix_file is not None:
            k_matrix_file.seek(0)
            df_k = pd.read_excel(k_matrix_file, engine="openpyxl", header=0, index_col=0)
            # å…ˆé ­12åˆ—ãƒ»12è¡Œã«æ­£è¦åŒ–ï¼ˆä½™åˆ†ãŒã‚ã£ã¦ã‚‚OKï¼‰
            df_k = df_k.iloc[:12, :12]
            k_matrix = df_k.values.astype(float)
            character_names_from_k = df_k.index.tolist()
        else:
            raise ValueError("kè¡Œåˆ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™")
        
        # lè¡Œåˆ—ã‚’èª­ã¿è¾¼ã‚€ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã‚’è¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦ä½¿ç”¨ï¼‰
        if l_matrix_file is not None:
            l_matrix_file.seek(0)
            df_l = pd.read_excel(l_matrix_file, engine="openpyxl", header=0, index_col=0)
            df_l = df_l.iloc[:12, :4]
            l_matrix = df_l.values.astype(float)
            character_names_from_l = df_l.index.tolist()
        else:
            raise ValueError("lè¡Œåˆ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™")
        
        # 12ç¥åŸºæœ¬æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€
        if character_file is not None:
            character_file.seek(0)
            df_gods = pd.read_excel(character_file, engine="openpyxl")
        else:
            # åŸºæœ¬æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã€kè¡Œåˆ—ã¨lè¡Œåˆ—ã‹ã‚‰ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã‚’å–å¾—
            # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã®ä¸€è‡´ã‚’ç¢ºèª
            common_names = [name for name in character_names_from_k if name in character_names_from_l]
            if len(common_names) != 12:
                raise ValueError(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚kè¡Œåˆ—: {len(character_names_from_k)}å€‹, lè¡Œåˆ—: {len(character_names_from_l)}å€‹")
            
            # ãƒ€ãƒŸãƒ¼ã®åŸºæœ¬æƒ…å ±ã‚’ä½œæˆ
            df_gods = pd.DataFrame({
                "ID": range(12),
                "åå‰": common_names,
                "åå‰(è‹±èª)": [f"God {i+1}" for i in range(12)],
                "å±æ€§": [""] * 12,
                "çµµæ–‡å­—": ["ğŸ”®"] * 12,
                "èª¬æ˜": [""] * 12,
                "æ ¼è¨€": [""] * 12
            })
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆï¼ˆkè¡Œåˆ—ã¨lè¡Œåˆ—ã®è¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨åŸºæœ¬æƒ…å ±ã®åå‰ã‚’å¯¾å¿œï¼‰
        name_to_id = {}
        for idx, row in df_gods.iterrows():
            god_name = str(row.get("åå‰", ""))
            if god_name:
                name_to_id[god_name] = int(row.get("ID", idx))
        
        # 12ç¥ã®æƒ…å ±ã‚’æ§‹ç¯‰
        gods_list = []
        for idx, row in df_gods.iterrows():
            god_id = int(row.get("ID", idx))
            god_name = str(row.get("åå‰", ""))
            god_name_en = str(row.get("åå‰(è‹±èª)", ""))
            god_attribute = str(row.get("å±æ€§", ""))
            god_emoji = str(row.get("çµµæ–‡å­—", "ğŸ”®"))
            god_description = str(row.get("èª¬æ˜", ""))
            # è¤‡æ•°æ ¼è¨€å¯¾å¿œï¼šæ ¼è¨€ / æ ¼è¨€1.. / æ”¹è¡Œ / '||' / 'ã‚¿ã‚°::æœ¬æ–‡'
            maxim_cells: List[str] = []
            # åˆ—åãŒ "æ ¼è¨€" ã ã‘ã®ã‚±ãƒ¼ã‚¹
            maxim_cells.extend(_split_multi_text(row.get("æ ¼è¨€", "")))
            # åˆ—åãŒ "æ ¼è¨€1","æ ¼è¨€2"... ã®ã‚±ãƒ¼ã‚¹
            for col in row.index:
                if isinstance(col, str) and col.startswith("æ ¼è¨€") and col != "æ ¼è¨€":
                    maxim_cells.extend(_split_multi_text(row.get(col, "")))
            maxims_parsed = [_parse_tagged_quote(m) for m in maxim_cells if str(m).strip()]
            # äº’æ›æ€§ã®ãŸã‚å…ˆé ­ã‚’ maxim ã«å…¥ã‚Œã‚‹
            god_maxim = maxims_parsed[0]["text"] if maxims_parsed else ""
            
            # kè¡Œåˆ—ã‹ã‚‰èª“é¡˜å€¤ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã§æ¤œç´¢ï¼‰
            vows = {}
            if god_name in df_k.index:
                k_row_idx = df_k.index.get_loc(god_name)
                for j in range(min(12, len(df_k.columns))):
                    vow_key = f"vow{j+1:02d}"
                    col_name = df_k.columns[j]
                    vows[vow_key] = float(k_matrix[k_row_idx, j])
            else:
                # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€IDã§æ¤œç´¢
                if god_id < len(k_matrix):
                    for j in range(min(12, len(df_k.columns))):
                        vow_key = f"vow{j+1:02d}"
                        vows[vow_key] = float(k_matrix[god_id, j])
            
            # lè¡Œåˆ—ã‹ã‚‰å½¹å‰²å±æ€§ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã§æ¤œç´¢ï¼‰
            role_names = ["stillness", "flow", "ma", "sincerity"]
            roles = {}
            if god_name in df_l.index:
                l_row_idx = df_l.index.get_loc(god_name)
                for j, role_name in enumerate(role_names):
                    if j < len(df_l.columns):
                        roles[role_name] = float(l_matrix[l_row_idx, j])
                    else:
                        roles[role_name] = 0.0
            else:
                # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€IDã§æ¤œç´¢
                if god_id < len(l_matrix):
                    for j, role_name in enumerate(role_names):
                        if j < len(l_matrix[god_id]):
                            roles[role_name] = float(l_matrix[god_id, j])
                        else:
                            roles[role_name] = 0.0
            
            god_dict = {
                "id": god_id,
                "name": god_name,
                "name_en": god_name_en,
                "attribute": god_attribute,
                "emoji": god_emoji,
                "vows": vows,
                "roles": roles,
                "maxim": god_maxim,
                "maxims": maxims_parsed,  # è¤‡æ•°æ ¼è¨€
                "description": god_description,
            }
            gods_list.append(god_dict)
        
        return gods_list, k_matrix, l_matrix
    
    except Exception as e:
        st.error(f"Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        st.error(f"è©³ç´°: {traceback.format_exc()}")
        raise

def get_excel_sheet_names(excel_file: io.BytesIO) -> List[str]:
    """Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚·ãƒ¼ãƒˆåä¸€è¦§ã‚’å–å¾—"""
    try:
        excel_file.seek(0)
        xl_file = pd.ExcelFile(excel_file, engine="openpyxl")
        return xl_file.sheet_names
    except Exception:
        return []

def find_sheet_by_keywords(excel_file: io.BytesIO, keywords: List[str]) -> Optional[str]:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ã‚·ãƒ¼ãƒˆåã‚’æ¤œç´¢"""
    sheet_names = get_excel_sheet_names(excel_file)
    for sheet_name in sheet_names:
        for keyword in keywords:
            if keyword in sheet_name:
                return sheet_name
    return None

def load_gods_from_excel(excel_file: io.BytesIO) -> Tuple[List[Dict], np.ndarray, np.ndarray]:
    """1ã¤ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰12ç¥ã®æƒ…å ±ã€kè¡Œåˆ—ã€lè¡Œåˆ—ã‚’èª­ã¿è¾¼ã‚€ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
    
    Args:
        excel_file: Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆBytesIOï¼‰- è¤‡æ•°ã®ã‚·ãƒ¼ãƒˆã‚’å«ã‚€
    
    Returns:
        (gods_list, k_matrix, l_matrix)
    """
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆè¤‡æ•°ã‚·ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã‚€ãŸã‚ï¼‰
        excel_file.seek(0)
        
        # ã‚·ãƒ¼ãƒˆåã‚’è‡ªå‹•æ¤œå‡º
        sheet_names = get_excel_sheet_names(excel_file)
        
        # 12ç¥åŸºæœ¬æƒ…å ±ã®ã‚·ãƒ¼ãƒˆã‚’æ¤œç´¢
        gods_sheet = find_sheet_by_keywords(excel_file, ["CHAR_MASTER", "12ç¥", "åŸºæœ¬æƒ…å ±", "character", "CHAR"])
        if gods_sheet is None:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚·ãƒ¼ãƒˆåã‚’è©¦ã™
            try:
                excel_file.seek(0)
                df_gods = pd.read_excel(excel_file, sheet_name=0, engine="openpyxl")  # æœ€åˆã®ã‚·ãƒ¼ãƒˆ
            except:
                raise ValueError(f"ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±ã®ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªã‚·ãƒ¼ãƒˆ: {sheet_names}")
        else:
            excel_file.seek(0)
            df_gods = pd.read_excel(excel_file, sheet_name=gods_sheet, engine="openpyxl")
        
        # CHAR_MASTERã‚·ãƒ¼ãƒˆã®å ´åˆã€ã™ã¹ã¦ã®æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹
        is_char_master = gods_sheet and "CHAR_MASTER" in gods_sheet.upper()
        
        # kè¡Œåˆ—ã®èª­ã¿è¾¼ã¿
        if is_char_master:
            # CHAR_MASTERã‚·ãƒ¼ãƒˆã«VOW_01ï½VOW_12ãŒå«ã¾ã‚Œã¦ã„ã‚‹
            vow_columns = [f"VOW_{i:02d}" for i in range(1, 13)]
            if all(col in df_gods.columns for col in vow_columns):
                # CHAR_MASTERã‹ã‚‰kè¡Œåˆ—ã‚’æ§‹ç¯‰
                df_k = df_gods.set_index("å…¬å¼ã‚­ãƒ£ãƒ©å")[vow_columns]
                k_matrix = df_k.values.astype(float)
            else:
                # VOWåˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€CHAR_TO_VOWã‚·ãƒ¼ãƒˆã‚’æ¢ã™
                excel_file.seek(0)
                k_sheet = find_sheet_by_keywords(excel_file, ["CHAR_TO_VOW", "kè¡Œåˆ—", "K"])
                if k_sheet:
                    excel_file.seek(0)
                    df_k = pd.read_excel(excel_file, sheet_name=k_sheet, engine="openpyxl", header=0)
                    df_k = df_k.set_index("å…¬å¼ã‚­ãƒ£ãƒ©å")
                    vow_columns = [col for col in df_k.columns if str(col).startswith("VOW_")]
                    df_k = df_k[vow_columns[:12]]
                    k_matrix = df_k.values.astype(float)
                else:
                    raise ValueError(f"kè¡Œåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚CHAR_MASTERã«VOWåˆ—ãŒãªã„ã‹ã€CHAR_TO_VOWã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        else:
            # CHAR_TO_VOWã‚·ãƒ¼ãƒˆã‹ã‚‰èª­ã¿è¾¼ã‚€
            excel_file.seek(0)
            k_sheet = find_sheet_by_keywords(excel_file, ["CHAR_TO_VOW", "kè¡Œåˆ—", "K"])
            if k_sheet is None:
                raise ValueError(f"kè¡Œåˆ—ã®ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªã‚·ãƒ¼ãƒˆ: {sheet_names}")
            
            excel_file.seek(0)
            df_k = pd.read_excel(excel_file, sheet_name=k_sheet, engine="openpyxl", header=0)
            
            # è¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®šï¼ˆå…¬å¼ã‚­ãƒ£ãƒ©åã¾ãŸã¯CHAR_IDï¼‰
            index_col = None
            if "å…¬å¼ã‚­ãƒ£ãƒ©å" in df_k.columns:
                index_col = "å…¬å¼ã‚­ãƒ£ãƒ©å"
            elif "CHAR_ID" in df_k.columns:
                index_col = "CHAR_ID"
            
            if index_col:
                df_k = df_k.set_index(index_col)
            
            # VOW_01ï½VOW_12ã®åˆ—ã®ã¿ã‚’é¸æŠï¼ˆæ•°å€¤åˆ—ã®ã¿ï¼‰
            vow_columns = [col for col in df_k.columns if str(col).startswith("VOW_")]
            if len(vow_columns) >= 12:
                df_k = df_k[vow_columns[:12]]
            else:
                raise ValueError(f"VOWåˆ—ãŒ12å€‹è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è¦‹ã¤ã‹ã£ãŸåˆ—: {vow_columns}")
            
            df_k = df_k.iloc[:12, :12]
            k_matrix = df_k.values.astype(float)
        
        # lè¡Œåˆ—ã®èª­ã¿è¾¼ã¿
        if is_char_master:
            # CHAR_MASTERã‚·ãƒ¼ãƒˆã«AXIS_SEI, AXIS_RYU, AXIS_MA, AXIS_MAKOTOãŒå«ã¾ã‚Œã¦ã„ã‚‹
            axis_columns = ["AXIS_SEI", "AXIS_RYU", "AXIS_MA", "AXIS_MAKOTO"]
            if all(col in df_gods.columns for col in axis_columns):
                # CHAR_MASTERã‹ã‚‰lè¡Œåˆ—ã‚’æ§‹ç¯‰
                df_l = df_gods.set_index("å…¬å¼ã‚­ãƒ£ãƒ©å")[axis_columns]
                l_matrix = df_l.values.astype(float)
            else:
                # AXISåˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€CHAR_TO_AXISã‚·ãƒ¼ãƒˆã‚’æ¢ã™
                excel_file.seek(0)
                l_sheet = find_sheet_by_keywords(excel_file, ["CHAR_TO_AXIS", "lè¡Œåˆ—", "L"])
                if l_sheet:
                    excel_file.seek(0)
                    df_l = pd.read_excel(excel_file, sheet_name=l_sheet, engine="openpyxl", header=0)
                    df_l = df_l.set_index("å…¬å¼ã‚­ãƒ£ãƒ©å")
                    axis_columns = ["AXIS_SEI", "AXIS_RYU", "AXIS_MA", "AXIS_MAKOTO"]
                    df_l = df_l[axis_columns]
                    l_matrix = df_l.values.astype(float)
                else:
                    raise ValueError(f"lè¡Œåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚CHAR_MASTERã«AXISåˆ—ãŒãªã„ã‹ã€CHAR_TO_AXISã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        else:
            # CHAR_TO_AXISã‚·ãƒ¼ãƒˆã‹ã‚‰èª­ã¿è¾¼ã‚€
            excel_file.seek(0)
            l_sheet = find_sheet_by_keywords(excel_file, ["CHAR_TO_AXIS", "lè¡Œåˆ—", "L"])
            if l_sheet is None:
                raise ValueError(f"lè¡Œåˆ—ã®ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªã‚·ãƒ¼ãƒˆ: {sheet_names}")
            
            excel_file.seek(0)
            df_l = pd.read_excel(excel_file, sheet_name=l_sheet, engine="openpyxl", header=0)
            
            # è¡Œã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®šï¼ˆå…¬å¼ã‚­ãƒ£ãƒ©åï¼‰
            if "å…¬å¼ã‚­ãƒ£ãƒ©å" in df_l.columns:
                df_l = df_l.set_index("å…¬å¼ã‚­ãƒ£ãƒ©å")
            
            # AXIS_SEI, AXIS_RYU, AXIS_MA, AXIS_MAKOTOã®åˆ—ã®ã¿ã‚’é¸æŠ
            axis_columns = ["AXIS_SEI", "AXIS_RYU", "AXIS_MA", "AXIS_MAKOTO"]
            if all(col in df_l.columns for col in axis_columns):
                df_l = df_l[axis_columns]
            else:
                raise ValueError(f"AXISåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å¿…è¦ãªåˆ—: {axis_columns}")
            
            df_l = df_l.iloc[:12, :4]
            l_matrix = df_l.values.astype(float)
        
        # 12ç¥ã®æƒ…å ±ã‚’æ§‹ç¯‰
        gods_list = []
        for idx, row in df_gods.iterrows():
            # CHAR_IDã‹ã‚‰IDã‚’å–å¾—ï¼ˆCHAR_01 â†’ 0, CHAR_02 â†’ 1, ...ï¼‰
            char_id = str(row.get("CHAR_ID", "")).strip()
            if char_id and char_id.startswith("CHAR_"):
                try:
                    god_id = int(char_id.replace("CHAR_", "")) - 1  # CHAR_01 â†’ 0
                except:
                    god_id = int(row.get("ID", idx))
            else:
                god_id = int(row.get("ID", idx))
            
            # åå‰ã®å–å¾—ï¼ˆCHAR_MASTERã®å ´åˆã€å…¬å¼ã‚­ãƒ£ãƒ©åã‚’ä½¿ç”¨ï¼‰
            if "å…¬å¼ã‚­ãƒ£ãƒ©å" in row.index:
                god_name = str(row.get("å…¬å¼ã‚­ãƒ£ãƒ©å", "")).strip()
            else:
                god_name = str(row.get("åå‰", ""))
            
            god_name_en = str(row.get("åå‰(è‹±èª)", ""))
            god_attribute = str(row.get("å±æ€§", ""))
            god_emoji = str(row.get("çµµæ–‡å­—", "ğŸ”®"))
            
            # èª¬æ˜ã®å–å¾—ï¼ˆå½¹å‰²è£œè¶³èª¬æ˜ã¾ãŸã¯èª¬æ˜ï¼‰
            if "å½¹å‰²è£œè¶³èª¬æ˜" in row.index:
                god_description = str(row.get("å½¹å‰²è£œè¶³èª¬æ˜", ""))
            else:
                god_description = str(row.get("èª¬æ˜", ""))
            
            # å…¬å¼ã‚­ãƒ£ãƒ©åã‚’å–å¾—ï¼ˆå…ˆã«å–å¾—ï¼‰
            official_name = str(row.get("å…¬å¼ã‚­ãƒ£ãƒ©å", "")).strip()
            
            # IMAGE_FILEã‚’å–å¾—ï¼ˆCHAR_TO_VOWã‚·ãƒ¼ãƒˆã‹ã‚‰å–å¾—ã™ã‚‹å ´åˆã‚‚ã‚ã‚‹ï¼‰
            image_file = str(row.get("IMAGE_FILE", "")).strip()
            # CHAR_TO_VOWã‚·ãƒ¼ãƒˆã‹ã‚‰IMAGE_FILEã‚’å–å¾—ï¼ˆCHAR_MASTERã«ãªã„å ´åˆï¼‰
            if not image_file and is_char_master:
                excel_file.seek(0)
                k_sheet = find_sheet_by_keywords(excel_file, ["CHAR_TO_VOW"])
                if k_sheet:
                    try:
                        excel_file.seek(0)
                        df_char_to_vow = pd.read_excel(excel_file, sheet_name=k_sheet, engine="openpyxl", header=0)
                        # å…¬å¼ã‚­ãƒ£ãƒ©åã§ãƒãƒƒãƒãƒ³ã‚°
                        if official_name and "å…¬å¼ã‚­ãƒ£ãƒ©å" in df_char_to_vow.columns:
                            matched_row = df_char_to_vow[df_char_to_vow["å…¬å¼ã‚­ãƒ£ãƒ©å"] == official_name]
                            if not matched_row.empty and "IMAGE_FILE" in matched_row.columns:
                                image_file = str(matched_row.iloc[0]["IMAGE_FILE"]).strip()
                    except:
                        pass
            
            maxim_cells: List[str] = []
            maxim_cells.extend(_split_multi_text(row.get("æ ¼è¨€", "")))
            for col in row.index:
                if isinstance(col, str) and col.startswith("æ ¼è¨€") and col != "æ ¼è¨€":
                    maxim_cells.extend(_split_multi_text(row.get(col, "")))
            maxims_parsed = [_parse_tagged_quote(m) for m in maxim_cells if str(m).strip()]
            god_maxim = maxims_parsed[0]["text"] if maxims_parsed else str(row.get("æ ¼è¨€", ""))
            
            # kè¡Œåˆ—ã‹ã‚‰èª“é¡˜å€¤ã‚’å–å¾—ï¼ˆvow01ï½vow12ï¼‰
            vows = {}
            # CHAR_MASTERã‚·ãƒ¼ãƒˆã«VOW_01ï½VOW_12ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ç›´æ¥å–å¾—
            if is_char_master and all(f"VOW_{i:02d}" in row.index for i in range(1, 13)):
                for j in range(1, 13):
                    vow_key = f"vow{j:02d}"
                    vows[vow_key] = float(row.get(f"VOW_{j:02d}", 0.0))
            else:
                # k_matrixã‹ã‚‰å–å¾—
                if god_id < len(k_matrix):
                    for j in range(12):
                        vow_key = f"vow{j+1:02d}"
                        vows[vow_key] = float(k_matrix[god_id, j])
            
            # lè¡Œåˆ—ã‹ã‚‰å½¹å‰²å±æ€§ã‚’å–å¾—
            role_names = ["stillness", "flow", "ma", "sincerity"]
            roles = {}
            # CHAR_MASTERã‚·ãƒ¼ãƒˆã«AXISåˆ—ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ç›´æ¥å–å¾—
            if is_char_master and all(col in row.index for col in ["AXIS_SEI", "AXIS_RYU", "AXIS_MA", "AXIS_MAKOTO"]):
                roles["stillness"] = float(row.get("AXIS_SEI", 0.0))
                roles["flow"] = float(row.get("AXIS_RYU", 0.0))
                roles["ma"] = float(row.get("AXIS_MA", 0.0))
                roles["sincerity"] = float(row.get("AXIS_MAKOTO", 0.0))
            else:
                # l_matrixã‹ã‚‰å–å¾—
                if god_id < len(l_matrix):
                    for j, role_name in enumerate(role_names):
                        roles[role_name] = float(l_matrix[god_id, j])
            
            god_dict = {
                "id": god_id,
                "name": god_name,
                "name_en": god_name_en,
                "attribute": god_attribute,
                "emoji": god_emoji,
                "vows": vows,
                "roles": roles,
                "maxim": god_maxim,
                "maxims": maxims_parsed,
                "description": god_description,
                "char_id": char_id if char_id else None,  # CHAR_IDã‚’è¿½åŠ 
                "image_file": image_file if image_file else None,  # IMAGE_FILEã‚’è¿½åŠ 
                "official_name": official_name if official_name else None,  # å…¬å¼ã‚­ãƒ£ãƒ©åã‚’è¿½åŠ 
            }
            gods_list.append(god_dict)
        
        return gods_list, k_matrix, l_matrix
    
    except Exception as e:
        st.error(f"Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise

def load_sense_to_vow_matrix(sense_to_vow_file: io.BytesIO) -> np.ndarray:
    """sense_to_vowè¡Œåˆ—ã‚’èª­ã¿è¾¼ã‚€ï¼ˆ8æ„Ÿè¦š Ã— 12èª“é¡˜ï¼‰
    
    Args:
        sense_to_vow_file: sense_to_vowè¡Œåˆ—ã®Excelãƒ•ã‚¡ã‚¤ãƒ«
    
    Returns:
        sense_to_vowè¡Œåˆ—ï¼ˆ8x12ï¼‰
    """
    try:
        sense_to_vow_file.seek(0)
        df_sv = pd.read_excel(sense_to_vow_file, engine="openpyxl", header=0, index_col=0)
        # 8è¡ŒÃ—12åˆ—ã«æ­£è¦åŒ–
        df_sv = df_sv.iloc[:8, :12]
        sense_to_vow_matrix = df_sv.values.astype(float)
        return sense_to_vow_matrix
    except Exception as e:
        st.error(f"sense_to_vowè¡Œåˆ—ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise

def load_maxims_from_excel(maxim_file: io.BytesIO) -> List[Dict]:
    """æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆExcelï¼‰ã‚’èª­ã¿è¾¼ã‚€
    
    Args:
        maxim_file: æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆExcelï¼‰
    
    Returns:
        æ ¼è¨€ã®ãƒªã‚¹ãƒˆï¼ˆå„è¦ç´ ã¯ {"text": "æ ¼è¨€", "source": "å‡ºå…¸", "tags": ["ã‚¿ã‚°1", "ã‚¿ã‚°2"]}ï¼‰
    """
    global MAXIMS_DATABASE
    try:
        maxim_file.seek(0)
        df = pd.read_excel(maxim_file, engine="openpyxl", header=0)
        
        maxims_list = []
        for idx, row in df.iterrows():
            maxim_text = str(row.get("æ ¼è¨€", "")).strip()
            source = str(row.get("å‡ºå…¸", "")).strip()
            
            if not maxim_text or maxim_text.lower() in ("nan", "none", ""):
                continue
            
            # ã‚¿ã‚°ã®å‡¦ç†ï¼ˆã‚¿ã‚°åˆ—ãŒã‚ã‚‹å ´åˆï¼‰
            tags = []
            if "ã‚¿ã‚°" in df.columns:
                tag_str = str(row.get("ã‚¿ã‚°", "")).strip()
                if tag_str and tag_str.lower() not in ("nan", "none"):
                    tags = [t.strip() for t in tag_str.split(",") if t.strip()]
            
            maxims_list.append({
                "text": maxim_text,
                "source": source if source else "ä¼çµ±çš„ãªæ•™ãˆ",
                "tags": tags
            })
        
        MAXIMS_DATABASE = maxims_list
        return maxims_list
    except Exception as e:
        st.error(f"æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

def load_all_excel_files(
    character_file: io.BytesIO = None,
    maxim_file: io.BytesIO = None,
    k_matrix_file: io.BytesIO = None,
    l_matrix_file: io.BytesIO = None,
    sense_to_vow_file: io.BytesIO = None
) -> bool:
    """5ã¤ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã¾ã¨ã‚ã¦èª­ã¿è¾¼ã‚€
    
    Args:
        character_file: 12ç¥åŸºæœ¬æƒ…å ± (akiba12_character_list.xlsx)
        maxim_file: æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ« (æ ¼è¨€.xlsx) - ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        k_matrix_file: kè¡Œåˆ— (akiba12_character_to_vow_K.xlsx)
        l_matrix_file: lè¡Œåˆ— (akiba12_character_to_axis_L.xlsx)
        sense_to_vow_file: sense_to_vowè¡Œåˆ— (sense_to_vow_initial_filled_from_user.xlsx)
    
    Returns:
        True: æˆåŠŸ, False: å¤±æ•—
    """
    result = load_excel_config(
        character_file=character_file,
        k_matrix_file=k_matrix_file,
        l_matrix_file=l_matrix_file,
        sense_to_vow_file=sense_to_vow_file
    )
    
    # æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if maxim_file is not None and result:
        maxims = load_maxims_from_excel(maxim_file)
        if maxims:
            st.success(f"âœ… æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{len(maxims)}ä»¶ï¼‰")
    
    return result

def load_excel_config(
    excel_file: io.BytesIO = None,
    character_file: io.BytesIO = None,
    k_matrix_file: io.BytesIO = None,
    l_matrix_file: io.BytesIO = None,
    sense_to_vow_file: io.BytesIO = None
) -> bool:
    """Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’æ›´æ–°
    
    Args:
        excel_file: 1ã¤ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ3ã¤ã®ã‚·ãƒ¼ãƒˆã‚’å«ã‚€ï¼‰- å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚
        character_file: 12ç¥åŸºæœ¬æƒ…å ±ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆåˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆï¼‰
        k_matrix_file: kè¡Œåˆ—ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆåˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆï¼‰
        l_matrix_file: lè¡Œåˆ—ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆåˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆï¼‰
        sense_to_vow_file: sense_to_vowè¡Œåˆ—ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ8æ„Ÿè¦š Ã— 12èª“é¡˜ï¼‰
    
    Returns:
        True: æˆåŠŸ, False: å¤±æ•—
    """
    global SENSE_TO_VOW_MATRIX, K_MATRIX, L_MATRIX, LOADED_GODS, TWELVE_GODS
    
    try:
        # 1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
        if excel_file is not None:
            gods_list, k_matrix, l_matrix = load_gods_from_excel(excel_file)
        # 3ã¤ã®åˆ¥ã€…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
        elif k_matrix_file is not None and l_matrix_file is not None:
            gods_list, k_matrix, l_matrix = load_gods_from_separate_files(
                character_file=character_file,
                k_matrix_file=k_matrix_file,
                l_matrix_file=l_matrix_file
            )
        else:
            raise ValueError("Excelãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # sense_to_vowè¡Œåˆ—ã‚’èª­ã¿è¾¼ã‚€ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if sense_to_vow_file is not None:
            sense_to_vow_matrix = load_sense_to_vow_matrix(sense_to_vow_file)
            SENSE_TO_VOW_MATRIX = sense_to_vow_matrix
        else:
            # sense_to_vowè¡Œåˆ—ãŒãªã„å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®šï¼ˆæ„Ÿè¦šã¨èª“é¡˜ã®åŸºæœ¬çš„ãªå¯¾å¿œï¼‰
            # å¾Œã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ã‚ˆã†ã«ã€Noneã®ã¾ã¾ã«ã—ã¦ãŠã
            SENSE_TO_VOW_MATRIX = None
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’æ›´æ–°
        K_MATRIX = k_matrix
        L_MATRIX = l_matrix
        LOADED_GODS = gods_list
        TWELVE_GODS = gods_list  # æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã¨ã®äº’æ›æ€§ã®ãŸã‚
        rebuild_globals_from_gods(gods_list)
        
        return True
    except Exception as e:
        st.error(f"è¨­å®šã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        import traceback
        st.error(f"è©³ç´°: {traceback.format_exc()}")
        return False

# -------------------------
# QUBOç”Ÿæˆï¼ˆ12ç¥ãƒ™ãƒ¼ã‚¹ï¼‰
# -------------------------
# QUBOãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ12ç¥åŒå£«ã®é–¢ä¿‚æ€§ï¼‰
# è² ã®å€¤ = ç›¸ä¹—åŠ¹æœï¼ˆä¸€ç·’ã«é¸ã°ã‚Œã‚„ã™ã„ï¼‰
# æ­£ã®å€¤ = æŠ‘åˆ¶ï¼ˆåŒæ™‚ã«é¸ã°ã‚Œã«ãã„ï¼‰

def calculate_god_similarity(god1: Dict, god2: Dict) -> float:
    """2ã¤ã®ç¥ã®å±æ€§ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ï¼ˆ-1.0 ï½ 1.0ï¼‰
    èª“é¡˜å±æ€§ï¼ˆvowsï¼‰ã¨å½¹å‰²å±æ€§ï¼ˆrolesï¼‰ã®ä¸¡æ–¹ã‚’è€ƒæ…®"""
    # èª“é¡˜å±æ€§ã®é¡ä¼¼åº¦ï¼ˆvow01ï½vow12ï¼‰
    vow_keys = [f"vow{i:02d}" for i in range(1, 13)]
    vow_diff_sum = 0.0
    for key in vow_keys:
        diff = abs(god1["vows"][key] - god2["vows"][key])
        vow_diff_sum += diff
    vow_similarity = 1.0 - (vow_diff_sum / len(vow_keys))
    
    # å½¹å‰²å±æ€§ã®é¡ä¼¼åº¦
    role_attrs = ["stillness", "flow", "ma", "sincerity"]
    role_diff_sum = 0.0
    for attr in role_attrs:
        diff = abs(god1["roles"][attr] - god2["roles"][attr])
        role_diff_sum += diff
    role_similarity = 1.0 - (role_diff_sum / len(role_attrs))
    
    # ä¸¡æ–¹ã®é¡ä¼¼åº¦ã‚’é‡ã¿ä»˜ã‘ã—ã¦çµ±åˆï¼ˆèª“é¡˜:0.6ã€å½¹å‰²:0.4ï¼‰
    similarity = vow_similarity * 0.6 + role_similarity * 0.4
    return similarity

def build_qubo_hierarchical(x: np.ndarray, lambda_v: float = 5.0, lambda_c: float = 5.0, 
                            lambda_neg: float = 2.0, lambda_conf: float = 2.0,
                            sense_to_vow_matrix: Optional[np.ndarray] = None,
                            k_matrix: Optional[np.ndarray] = None,
                            l_matrix: Optional[np.ndarray] = None,
                            x_continuous: Optional[np.ndarray] = None,
                            selected_attribute: Optional[str] = None,
                            selected_character: Optional[str] = None,
                            char_master: Optional[pd.DataFrame] = None) -> Dict[Tuple[int,int], float]:
    """å¤šå±¤ãƒã‚¤ãƒŠãƒªæ§‹é€ QUBOã‚’ç”Ÿæˆï¼ˆæ·»ä»˜è³‡æ–™ã®è¨­è¨ˆã«åŸºã¥ãï¼‰
    
    Args:
        x: æ„Ÿè¦šãƒ™ã‚¯ãƒˆãƒ«ï¼ˆx1ï½x8ã€ãƒã‚¤ãƒŠãƒªï¼‰
        lambda_v: èª“é¡˜å±¤ã®one-hotåˆ¶ç´„ã®å¼·åº¦
        lambda_c: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å±¤ã®one-hotåˆ¶ç´„ã®å¼·åº¦
        lambda_neg: çŸ›ç›¾åˆ¶ç´„ã®å¼·åº¦ï¼ˆè¿·ã„Ã—è¡Œå‹•ï¼‰
        lambda_conf: çŸ›ç›¾åˆ¶ç´„ã®å¼·åº¦ï¼ˆç„¦ã‚ŠÃ—å¾…ã¤ï¼‰
        sense_to_vow_matrix: sense_to_vowè¡Œåˆ—ï¼ˆ8x12ï¼šæ„Ÿè¦š Ã— èª“é¡˜ï¼‰ã€‚Noneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
        k_matrix: kè¡Œåˆ—ï¼ˆ12x12ï¼šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ Ã— èª“é¡˜ï¼‰ã€‚Noneã®å ´åˆã¯TWELVE_GODSã‹ã‚‰ç”Ÿæˆ
        l_matrix: lè¡Œåˆ—ï¼ˆ12x4ï¼šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ Ã— ä¸–ç•Œè¦³è»¸ï¼‰ã€‚Noneã®å ´åˆã¯TWELVE_GODSã‹ã‚‰ç”Ÿæˆ
        x_continuous: æ„Ÿè¦šãƒ™ã‚¯ãƒˆãƒ«ã®é€£ç¶šå€¤ï¼ˆ0ã€œ5ï¼‰ã€‚Noneã®å ´åˆã¯xã‚’ä½¿ç”¨
    
    Returns:
        QUBOè¾æ›¸ï¼ˆ(i,j) -> ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿‚æ•°ï¼‰
    
    è¨­è¨ˆã®æµã‚Œ:
    1. ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ› â†’ Mood â†’ æ„Ÿè¦šãƒ™ã‚¯ãƒˆãƒ« xï¼ˆ8æ¬¡å…ƒã€é€£ç¶šå€¤0ã€œ5ï¼‰
    2. xï¼ˆæ„Ÿè¦šï¼‰â†’ vï¼ˆèª“é¡˜ï¼‰ã‚’å¼•ãå¯„ã›ã‚‹ï¼ˆsense_to_vow_matrixã‚’ä½¿ç”¨ï¼‰
       - H_sense-vow = Î£_{i,j} W_{ij} x_i v_j
       - W_{ij}: sense_to_vow_matrix[i, j] = æ„Ÿè¦šiãŒèª“é¡˜jã‚’å¼•ãå¯„ã›ã‚‹å¼·ã•
    3. vï¼ˆèª“é¡˜ï¼‰â†’ cï¼ˆã‚­ãƒ£ãƒ©ï¼‰ã‚’å¼•ãå¯„ã›ã‚‹ï¼ˆk_matrixã‚’ä½¿ç”¨ï¼‰
    4. QUBOã§one-hotåˆ¶ç´„ã«ã‚ˆã‚Šã€èª“é¡˜1ã¤ã€ã‚­ãƒ£ãƒ©1ä½“ãŒé¸ã°ã‚Œã‚‹
    """
    Q: Dict[Tuple[int,int], float] = {}
    
    n_sense = len(x)  # 8ï¼ˆæ„Ÿè¦šå¤‰æ•°ï¼‰
    n_vows = 12  # 12èª“é¡˜
    n_chars = 12  # 12ç¥
    
    # å¤‰æ•°ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®šç¾©
    # x: 0ï½7ï¼ˆæ„Ÿè¦šå¤‰æ•°ï¼‰
    # v: 8ï½19ï¼ˆèª“é¡˜å¤‰æ•°ï¼‰
    # c: 20ï½31ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ•°ï¼‰
    v_start = n_sense
    c_start = n_sense + n_vows
    
    # kè¡Œåˆ—ã¨lè¡Œåˆ—ã‚’å–å¾—ï¼ˆExcelã‹ã‚‰èª­ã¿è¾¼ã‚“ã å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ã€ãã†ã§ãªã‘ã‚Œã°TWELVE_GODSã‹ã‚‰ç”Ÿæˆï¼‰
    if k_matrix is None:
        # TWELVE_GODSã‹ã‚‰kè¡Œåˆ—ã‚’ç”Ÿæˆ
        k_matrix = np.zeros((n_chars, n_vows))
        for k, god in enumerate(TWELVE_GODS):
            for j in range(n_vows):
                vow_key = f"vow{j+1:02d}"
                k_matrix[k, j] = god["vows"][vow_key]
    
    if l_matrix is None:
        # TWELVE_GODSã‹ã‚‰lè¡Œåˆ—ã‚’ç”Ÿæˆ
        l_matrix = np.zeros((n_chars, 4))
        role_names = ["stillness", "flow", "ma", "sincerity"]
        for k, god in enumerate(TWELVE_GODS):
            for j, role_name in enumerate(role_names):
                l_matrix[k, j] = god["roles"][role_name]
    
    # === H_sense: æ„Ÿè¦šã‚¨ãƒãƒ«ã‚®ãƒ¼é … ===
    # H_sense = Î£_i a_i x_i
    # æ„Ÿè¦šãŒå¼·ã„ã»ã©é¸ã°ã‚Œã‚„ã™ã„ï¼ˆè² ã®å€¤ã§ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸‹ã’ã‚‹ï¼‰
    for i in range(n_sense):
        # é€£ç¶šå€¤ã®å ´åˆã€å¼·ã•ã«å¿œã˜ã¦ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸‹ã’ã‚‹
        # ãƒã‚¤ãƒŠãƒªã®å ´åˆã€ç«‹ã¡ä¸ŠãŒã£ã¦ã„ã‚‹å ´åˆã®ã¿
        if x[i] > 0:
            # æ„Ÿè¦šã®å¼·ã•ã«æ¯”ä¾‹ã—ã¦ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸‹ã’ã‚‹ï¼ˆè² ã®å€¤ï¼‰
            # ãŸã ã—ã€æ„Ÿè¦šå¤‰æ•°è‡ªä½“ã¯ãƒã‚¤ãƒŠãƒªãªã®ã§ã€ç«‹ã¡ä¸ŠãŒã£ã¦ã„ã‚‹å ´åˆã®ã¿
            Q[(i, i)] = -0.5 * min(x[i], 1.0)  # æœ€å¤§1.0ã«åˆ¶é™
    
    # === H_vow: èª“é¡˜é¸æŠé …ï¼ˆone-hotåˆ¶ç´„ï¼‰ ===
    # H_vow = Î»_v (Î£_j v_j - 1)^2 = Î»_v (Î£_j v_j^2 - 2Î£_j v_j + 1)
    # = Î»_v (Î£_j v_j - 2Î£_j v_j + 1) = Î»_v (1 - Î£_j v_j)
    # å±•é–‹ã™ã‚‹ã¨: Î»_v * Î£_j v_j^2 - 2Î»_v * Î£_j v_j + Î»_v
    # ç·šå½¢é …: -2Î»_v * v_j
    # äºŒæ¬¡é …: Î»_v * v_j^2 (j=jã®å ´åˆ) + Î»_v * 2 * v_i * v_j (iâ‰ jã®å ´åˆ)
    for j in range(n_vows):
        v_idx = v_start + j
        # ç·šå½¢é …
        Q[(v_idx, v_idx)] = -2.0 * lambda_v
        # äºŒæ¬¡é …ï¼ˆèª“é¡˜åŒå£«ã®ç›¸äº’ä½œç”¨ï¼‰
        for k in range(j+1, n_vows):
            v_idx2 = v_start + k
            Q[(v_idx, v_idx2)] = 2.0 * lambda_v
    
    # å®šæ•°é …ï¼ˆÎ»_vï¼‰ã¯ç„¡è¦–ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼å·®ã®ã¿ãŒé‡è¦ï¼‰
    
    # === H_char: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é¸æŠé …ï¼ˆone-hotåˆ¶ç´„ï¼‰ ===
    # H_char = Î»_c (Î£_k c_k - 1)^2
    for k in range(n_chars):
        c_idx = c_start + k
        # ç·šå½¢é …
        Q[(c_idx, c_idx)] = -2.0 * lambda_c
        # äºŒæ¬¡é …ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åŒå£«ã®ç›¸äº’ä½œç”¨ï¼‰
        for l in range(k+1, n_chars):
            c_idx2 = c_start + l
            Q[(c_idx, c_idx2)] = 2.0 * lambda_c
    
    # === H_interaction: ç›¸äº’ä½œç”¨é … ===
    # H_interaction = Î£_{i,j} S_{ij} x_i v_j + Î£_{j,k} K_{jk} v_j c_k + Î£_{i,k} L_{ik} x_i c_k
    
    # æ„Ÿè¦š Ã— èª“é¡˜: S_{ij} x_i v_jï¼ˆsense_to_vow_matrixã‚’ä½¿ç”¨ï¼‰
    # H_sense-vow = Î£_{i,j} W_{ij} x_i v_j
    # W_{ij}: sense_to_vow_matrix[i, j] = æ„Ÿè¦šiãŒèª“é¡˜jã‚’å¼•ãå¯„ã›ã‚‹å¼·ã•
    # è² ã®å€¤ï¼ˆä¾‹ï¼š-0.4ï¼‰= å¼•ãå¯„ã›ï¼ˆç›¸æ€§ãŒè‰¯ã„ï¼‰â†’ ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸‹ã’ã‚‹
    # æ­£ã®å€¤ï¼ˆä¾‹ï¼š+0.2ï¼‰= é›¢ã™ï¼ˆç›¸æ€§ãŒæ‚ªã„ï¼‰â†’ ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸Šã’ã‚‹
    if sense_to_vow_matrix is not None:
        # sense_to_vowè¡Œåˆ—ã‚’ä½¿ç”¨ï¼ˆä¸­æ ¸ãƒ‡ãƒ¼ã‚¿ï¼‰
        for i in range(n_sense):
            if x[i] > 0:  # æ„Ÿè¦šãŒç«‹ã¡ä¸ŠãŒã£ã¦ã„ã‚‹å ´åˆã®ã¿
                for j in range(n_vows):
                    v_idx = v_start + j
                    # sense_to_vowè¡Œåˆ—ã®å€¤ã‚’ç›´æ¥ä½¿ç”¨
                    if i < sense_to_vow_matrix.shape[0] and j < sense_to_vow_matrix.shape[1]:
                        W_ij = sense_to_vow_matrix[i, j]  # æ„Ÿè¦šiãŒèª“é¡˜jã‚’å¼•ãå¯„ã›ã‚‹å¼·ã•
                        # QUBOã®ç›¸äº’ä½œç”¨é …: W_{ij} * x_i * v_j
                        # x_iã¯ãƒã‚¤ãƒŠãƒªå¤‰æ•°ã ãŒã€é€£ç¶šå€¤ã®å¼·ã•ã‚’é‡ã¿ã¨ã—ã¦ä½¿ç”¨
                        if x_continuous is not None and i < len(x_continuous):
                            x_strength = min(x_continuous[i], 5.0) / 5.0  # 0ã€œ1ã«æ­£è¦åŒ–
                        else:
                            x_strength = 1.0 if x[i] > 0 else 0.0
                        # W_{ij} * x_i * v_j ã®ä¿‚æ•°
                        # è² ã®å€¤ = å¼•ãå¯„ã›ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸‹ã’ã‚‹ï¼‰ã€æ­£ã®å€¤ = é›¢ã™ï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸Šã’ã‚‹ï¼‰
                        Q[(i, v_idx)] = W_ij * x_strength
    else:
        # sense_to_vowè¡Œåˆ—ãŒãªã„å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å¯¾å¿œé–¢ä¿‚ã‚’ä½¿ç”¨
        # è¿·ã„ãŒå¼·ã„ â†’ èª“é¡˜05/07/10ãŒå‘¼ã°ã‚Œã‚„ã™ã„ã€ãªã©
        default_mapping = {
            0: [4, 6, 9],  # è¿·ã„ â†’ èª“é¡˜05, 07, 10
            1: [0, 1, 3],  # ç„¦ã‚Š â†’ èª“é¡˜01, 02, 04
            2: [1, 10],    # é™ã‘ã• â†’ èª“é¡˜02, 11
            3: [2, 8],     # å†…çœ â†’ èª“é¡˜03, 09
            4: [3, 5],     # è¡Œå‹• â†’ èª“é¡˜04, 06
            5: [7, 11],    # ã¤ãªãŒã‚Š â†’ èª“é¡˜08, 12
            6: [4, 6],     # æŒ‘æˆ¦ â†’ èª“é¡˜05, 07
            7: [2, 8],     # å¾…ã¤ â†’ èª“é¡˜03, 09
        }
        for i in range(n_sense):
            if x[i] > 0:
                for j in range(n_vows):
                    v_idx = v_start + j
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨
                    if i in default_mapping and j in default_mapping[i]:
                        Q[(i, v_idx)] = -0.3 * x[i]  # è² ã®å€¤ã§å¼•ãå¯„ã›ã‚‹
                    else:
                        Q[(i, v_idx)] = 0.1 * x[i]  # æ­£ã®å€¤ã§å°‘ã—æŠ‘åˆ¶
    
    # èª“é¡˜ Ã— ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: K_{jk} v_j c_k = k_matrix[k, j] v_j c_k
    # kè¡Œåˆ—ã‚’ä½¿ç”¨ã—ã¦èª“é¡˜ã¨ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ç›¸äº’ä½œç”¨ã‚’å®šç¾©
    # ã“ã®èª“é¡˜ãªã‚‰ã€ã“ã®ç¥ãŒã€Œèªã‚Šæ‰‹ã¨ã—ã¦è‡ªç„¶ã€ã¨ã„ã†é–¢ä¿‚ã‚’æ•°å€¤ã§æŒã£ã¦ã„ã‚‹
    for j in range(n_vows):
        v_idx = v_start + j
        for k in range(n_chars):
            c_idx = c_start + k
            # kè¡Œåˆ—ã®å€¤ã‚’ä½¿ç”¨ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼kã®èª“é¡˜jã®å€¤ï¼‰
            # è² ã®å€¤ = ãã®èª“é¡˜ãŒé¸ã°ã‚Œã‚„ã™ã„ã€æ­£ã®å€¤ = é¸ã°ã‚Œã«ãã„
            if k < k_matrix.shape[0] and j < k_matrix.shape[1]:
                Q[(v_idx, c_idx)] = k_matrix[k, j]
    
    # æ„Ÿè¦š Ã— ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: L_{ik} x_i c_k = l_matrix[k, role_i] x_i c_k
    # lè¡Œåˆ—ã‚’ä½¿ç”¨ã—ã¦æ„Ÿè¦šã¨ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ç›¸äº’ä½œç”¨ã‚’å®šç¾©
    # æ„Ÿè¦šå¤‰æ•°ã¨å½¹å‰²å±æ€§ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    role_mapping = {
        0: 0,  # è¿·ã„ â†’ stillness (l_matrixã®åˆ—0)
        1: 1,  # ç„¦ã‚Š â†’ flow (l_matrixã®åˆ—1)
        2: 0,  # é™ã‘ã• â†’ stillness (l_matrixã®åˆ—0)
        3: 2,  # å†…çœ â†’ ma (l_matrixã®åˆ—2)
        4: 1,  # è¡Œå‹• â†’ flow (l_matrixã®åˆ—1)
        5: 2,  # ã¤ãªãŒã‚Š â†’ ma (l_matrixã®åˆ—2)
        6: 1,  # æŒ‘æˆ¦ â†’ flow (l_matrixã®åˆ—1)
        7: 3,  # å¾…ã¤ â†’ sincerity (l_matrixã®åˆ—3)
    }
    
    for i in range(n_sense):
        if x[i] > 0:
            role_col = role_mapping.get(i, 0)
            for k in range(n_chars):
                c_idx = c_start + k
                # lè¡Œåˆ—ã®å€¤ã‚’ä½¿ç”¨ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼kã®å½¹å‰²å±æ€§role_colã®å€¤ï¼‰
                Q[(i, c_idx)] = l_matrix[k, role_col] * x[i]
    
    # === H_constraint: åˆ¶ç´„é … ===
    # H_constraint = Î»_neg (x_è¿·ã„ãƒ»x_è¡Œå‹•) + Î»_conf (x_ç„¦ã‚Šãƒ»x_å¾…ã¤)
    # è¿·ã„ï¼ˆx0ï¼‰ã¨è¡Œå‹•ï¼ˆx4ï¼‰ã®çŸ›ç›¾
    if x[0] > 0 and x[4] > 0:
        Q[(0, 4)] = lambda_neg
    
    # ç„¦ã‚Šï¼ˆx1ï¼‰ã¨å¾…ã¤ï¼ˆx7ï¼‰ã®çŸ›ç›¾
    if x[1] > 0 and x[7] > 0:
        Q[(1, 7)] = lambda_conf
    
    # === é¸æŠã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼/å±æ€§ã®èª¿æ•´ ===
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠã—ãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¾ãŸã¯å±æ€§ã‚’æŒã¤ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸‹ã’ã‚‹
    if selected_character or selected_attribute:
        gods_list = LOADED_GODS if LOADED_GODS else TWELVE_GODS
        for k, god in enumerate(gods_list):
            c_idx = c_start + k
            should_boost = False
            
            # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ç›´æ¥é¸æŠ
            if selected_character:
                god_name = god.get("name", "")
                official_name = god.get("official_name", "")
                if selected_character == god_name or selected_character == official_name:
                    should_boost = True
            
            # å±æ€§ã®é¸æŠ
            if selected_attribute and not should_boost:
                god_attribute = god.get("attribute", "")
                if selected_attribute == god_attribute:
                    should_boost = True
            
            # é¸æŠã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼/å±æ€§ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸‹ã’ã‚‹ï¼ˆé¸ã°ã‚Œã‚„ã™ãã™ã‚‹ï¼‰
            if should_boost:
                # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ•°ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸‹ã’ã‚‹ï¼ˆè² ã®å€¤ã§å¼•ãå¯„ã›ã‚‹ï¼‰
                current_energy = Q.get((c_idx, c_idx), 0)
                Q[(c_idx, c_idx)] = current_energy - 3.0  # å¤§å¹…ã«ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸‹ã’ã‚‹
    
    return Q

def build_qubo_base() -> Dict[Tuple[int,int], float]:
    """å¾“æ¥ã®QUBOãƒ™ãƒ¼ã‚¹ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰"""
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ„Ÿè¦šãƒ™ã‚¯ãƒˆãƒ«ï¼ˆå…¨ã¦0ï¼‰ã§QUBOã‚’ç”Ÿæˆ
    x_default = np.zeros(8)
    return build_qubo_hierarchical(x_default)

# åŸºæœ¬QUBOãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
Q_BASE = build_qubo_base()

def clamp(v: float, lo: float=-3.0, hi: float=3.0) -> float:
    return max(lo, min(hi, v))

def select_god_from_mood(m: Mood) -> Dict:
    """Moodã«åŸºã¥ã„ã¦æœ€ã‚‚é©ã—ãŸ12ç¥ã®1ã¤ã‚’é¸æŠ
    å½¹å‰²å±æ€§ï¼ˆrolesï¼‰ã‚’ä¸»ã«è€ƒæ…®ï¼ˆæ–°ã—ã„èª“é¡˜æ§‹é€ ã«å¯¾å¿œï¼‰"""
    best_god = None
    best_score = -float('inf')
    
    for god in TWELVE_GODS:
        # Moodã¨ç¥ã®å½¹å‰²å±æ€§ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
        score = 0.0
        
        # ç–²ã‚ŒãŒé«˜ã„ â†’ é™ï¼ˆstillnessï¼‰ãŒé«˜ã„ç¥ã‚’é¸ã¶
        if m.fatigue > 0.3:
            score += abs(god["roles"]["stillness"]) * m.fatigue * 0.3
        
        # ä¸å®‰ãŒé«˜ã„ â†’ æµï¼ˆflowï¼‰ãŒé«˜ã„ç¥ã‚’é¸ã¶
        if m.anxiety > 0.3:
            score += abs(god["roles"]["flow"]) * m.anxiety * 0.3
        
        # å¥½å¥‡å¿ƒãŒé«˜ã„ â†’ é–“ï¼ˆmaï¼‰ãŒé«˜ã„ç¥ã‚’é¸ã¶
        if m.curiosity > 0.3:
            score += abs(god["roles"]["ma"]) * m.curiosity * 0.3
        
        # æ±ºæ–­åŠ›ãŒé«˜ã„ â†’ èª ï¼ˆsincerityï¼‰ãŒé«˜ã„ç¥ã‚’é¸ã¶
        if m.decisiveness > 0.3:
            score += abs(god["roles"]["sincerity"]) * m.decisiveness * 0.3
        
        # å­¤ç‹¬æ„ŸãŒé«˜ã„ â†’ é–“ï¼ˆmaï¼‰ã¨é™ï¼ˆstillnessï¼‰ãŒé«˜ã„ç¥ã‚’é¸ã¶
        if m.loneliness > 0.3:
            score += (abs(god["roles"]["ma"]) + abs(god["roles"]["stillness"])) * m.loneliness * 0.2
        
        if score > best_score:
            best_score = score
            best_god = god
    
    return best_god if best_god else TWELVE_GODS[0]

def build_qubo_from_mood(m: Mood, 
                         sense_to_vow_matrix: Optional[np.ndarray] = None,
                         k_matrix: Optional[np.ndarray] = None,
                         l_matrix: Optional[np.ndarray] = None,
                         selected_attribute: Optional[str] = None,
                         selected_character: Optional[str] = None,
                         char_master: Optional[pd.DataFrame] = None) -> Dict[Tuple[int,int], float]:
    """Moodã«åŸºã¥ã„ã¦å¤šå±¤ãƒã‚¤ãƒŠãƒªæ§‹é€ QUBOã‚’ç”Ÿæˆ
    
    è¨­è¨ˆã®æµã‚Œ:
    1. ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ› â†’ Mood â†’ æ„Ÿè¦šãƒ™ã‚¯ãƒˆãƒ« xï¼ˆ8æ¬¡å…ƒã€é€£ç¶šå€¤0ã€œ5ï¼‰
    2. xï¼ˆæ„Ÿè¦šï¼‰â†’ vï¼ˆèª“é¡˜ï¼‰ã‚’å¼•ãå¯„ã›ã‚‹ï¼ˆsense_to_vow_matrixã‚’ä½¿ç”¨ï¼‰
       - H_sense-vow = Î£_{i,j} W_{ij} x_i v_j
       - W_{ij}: sense_to_vow_matrix[i, j] = æ„Ÿè¦šiãŒèª“é¡˜jã‚’å¼•ãå¯„ã›ã‚‹å¼·ã•
    3. vï¼ˆèª“é¡˜ï¼‰â†’ cï¼ˆã‚­ãƒ£ãƒ©ï¼‰ã‚’å¼•ãå¯„ã›ã‚‹ï¼ˆk_matrixã‚’ä½¿ç”¨ï¼‰
    4. QUBOã§one-hotåˆ¶ç´„ã«ã‚ˆã‚Šã€èª“é¡˜1ã¤ã€ã‚­ãƒ£ãƒ©1ä½“ãŒé¸ã°ã‚Œã‚‹
    
    Args:
        m: Moodã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        sense_to_vow_matrix: sense_to_vowè¡Œåˆ—ï¼ˆ8x12ï¼šæ„Ÿè¦š Ã— èª“é¡˜ï¼‰
        k_matrix: kè¡Œåˆ—ï¼ˆ12x12ï¼šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ Ã— èª“é¡˜ï¼‰
        l_matrix: lè¡Œåˆ—ï¼ˆ12x4ï¼šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ Ã— ä¸–ç•Œè¦³è»¸ï¼‰
    
    Returns:
        QUBOè¾æ›¸ï¼ˆ(i,j) -> ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿‚æ•°ï¼‰
    """
    # Moodã‹ã‚‰æ„Ÿè¦šãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆï¼ˆé€£ç¶šå€¤0ã€œ5ã¨ã—ã¦æ‰±ã†ï¼‰
    # ãŸã ã—ã€QUBOå¤‰æ•°ã¯ãƒã‚¤ãƒŠãƒªãªã®ã§ã€æ„Ÿè¦šã®å¼·ã•ã¯é‡ã¿ã¨ã—ã¦ä½¿ç”¨
    x_continuous = mood_to_sensation_vector(m, binary=False, scale=5.0)
    # QUBOæ§‹ç¯‰æ™‚ã¯ã€æ„Ÿè¦šãŒç«‹ã¡ä¸ŠãŒã£ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’ãƒã‚¤ãƒŠãƒªã§åˆ¤å®š
    x = (x_continuous > 0.3).astype(float)  # é–¾å€¤0.3*5=1.5ä»¥ä¸Šã§1
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‹ã‚‰è¡Œåˆ—ã‚’å–å¾—ï¼ˆæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
    if sense_to_vow_matrix is None:
        sense_to_vow_matrix = SENSE_TO_VOW_MATRIX
    if k_matrix is None:
        k_matrix = K_MATRIX
    if l_matrix is None:
        l_matrix = L_MATRIX
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‹ã‚‰é¸æŠã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼/å±æ€§ã‚’å–å¾—
    global SELECTED_ATTRIBUTE, SELECTED_CHARACTER, CHAR_MASTER
    if selected_attribute is None:
        selected_attribute = SELECTED_ATTRIBUTE
    if selected_character is None:
        selected_character = SELECTED_CHARACTER
    if char_master is None:
        char_master = CHAR_MASTER
    
    # å¤šå±¤ãƒã‚¤ãƒŠãƒªæ§‹é€ QUBOã‚’ç”Ÿæˆ
    # x_continuousã‚’æ¸¡ã—ã¦ã€æ„Ÿè¦šã®å¼·ã•ã‚’é‡ã¿ã¨ã—ã¦ä½¿ç”¨
    Q = build_qubo_hierarchical(x, 
                                 sense_to_vow_matrix=sense_to_vow_matrix,
                                 k_matrix=k_matrix, 
                                 l_matrix=l_matrix,
                                 x_continuous=x_continuous,
                                 selected_attribute=selected_attribute,
                                 selected_character=selected_character,
                                 char_master=char_master)
    
    return Q

# -------------------------
# è§£æ¢ç´¢
# -------------------------
def solve_all_with_optuna(Q: Dict[Tuple[int,int], float], use_hierarchical: bool = False, 
                          progress_container=None, n_trials: int = 100):
    """Optunaã‚’ä½¿ã£ãŸQUBOæœ€é©åŒ–ï¼ˆé€²æ—è¡¨ç¤ºä»˜ãï¼‰
    
    Args:
        Q: QUBOè¾æ›¸
        use_hierarchical: å¤šå±¤ãƒã‚¤ãƒŠãƒªæ§‹é€ ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆTrue
        progress_container: Streamlitã®ã‚³ãƒ³ãƒ†ãƒŠï¼ˆé€²æ—è¡¨ç¤ºç”¨ï¼‰
        n_trials: è©¦è¡Œå›æ•°
    
    Returns:
        (è§£ã®ãƒªã‚¹ãƒˆ, Optuna Study)
    """
    if not OPTUNA_AVAILABLE:
        # OptunaãŒä½¿ãˆãªã„å ´åˆã¯é€šå¸¸ã®solve_allã‚’ä½¿ç”¨
        if progress_container is not None:
            with progress_container:
                st.info("â„¹ï¸ OptunaãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚é€šå¸¸ã®æœ€é©åŒ–ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        return solve_all(Q, use_hierarchical), None
    
    if use_hierarchical:
        n = 32
        v_start = 8
        c_start = 20
    else:
        n = len(VARIABLES)
        v_start = None
        c_start = None
    
    # æ¯å›ç•°ãªã‚‹çµæœã‚’å¾—ã‚‹ãŸã‚ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ™ãƒ¼ã‚¹ã®ã‚·ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
    import time
    random_seed = int(time.time() * 1000) % 1000000
    np.random.seed(random_seed)
    random.seed(random_seed)
    
    # Optuna Studyã‚’ä½œæˆï¼ˆin-memory databaseã€ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®šï¼‰
    study = optuna.create_study(
        direction='minimize', 
        study_name='qubo_optimization',
        sampler=optuna.samplers.TPESampler(seed=random_seed) if OPTUNA_AVAILABLE else None
    )
    
    def objective(trial):
        # ãƒã‚¤ãƒŠãƒªå¤‰æ•°ã‚’ç”Ÿæˆ
        if use_hierarchical:
            # one-hotåˆ¶ç´„ã‚’æº€ãŸã™ã‚ˆã†ã«ç”Ÿæˆ
            # èª“é¡˜å¤‰æ•°: 12å€‹ã®ã†ã¡1ã¤ã ã‘1
            vow_idx = trial.suggest_int('vow_idx', 0, 11)
            # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ•°: 12å€‹ã®ã†ã¡1ã¤ã ã‘1
            char_idx = trial.suggest_int('char_idx', 0, 11)
            
            x = np.zeros(n, dtype=int)
            x[v_start + vow_idx] = 1
            x[c_start + char_idx] = 1
            
            # æ„Ÿè¦šå¤‰æ•°ã¯ãƒ©ãƒ³ãƒ€ãƒ ã«è¨­å®š
            for i in range(8):
                x[i] = trial.suggest_int(f'sense_{i}', 0, 1)
        else:
            x = np.zeros(n, dtype=int)
            for i in range(n):
                x[i] = trial.suggest_int(f'x_{i}', 0, 1)
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’è¨ˆç®—
        energy = qubo_energy(x, Q)
        
        # é€²æ—è¡¨ç¤º
        if progress_container is not None:
            with progress_container:
                st.write(f"è©¦è¡Œ {trial.number + 1}/{n_trials}: ã‚¨ãƒãƒ«ã‚®ãƒ¼ = {energy:.3f}")
        
        return energy
    
    # æœ€é©åŒ–å®Ÿè¡Œ
    if progress_container is not None:
        with progress_container:
            st.info("ğŸ”® QUBOæœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")
            progress_bar = st.progress(0)
    
    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)
    
    # æœ€é©è§£ã‚’å–å¾—
    best_x = np.zeros(n, dtype=int)
    if use_hierarchical:
        best_vow = study.best_params['vow_idx']
        best_char = study.best_params['char_idx']
        best_x[v_start + best_vow] = 1
        best_x[c_start + best_char] = 1
        for i in range(8):
            best_x[i] = study.best_params[f'sense_{i}']
    else:
        for i in range(n):
            best_x[i] = study.best_params[f'x_{i}']
    
    # è§£ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆï¼ˆæœ€é©è§£ã¨ãã®å‘¨è¾ºï¼‰
    sols = [(study.best_value, best_x)]
    
    # è¿½åŠ ã®è§£ã‚’ç”Ÿæˆï¼ˆãƒˆãƒ©ã‚¤ã‚¢ãƒ«ã‹ã‚‰ï¼‰
    for trial in study.trials[:min(100, len(study.trials))]:
        if trial.state == optuna.trial.TrialState.COMPLETE:
            x = np.zeros(n, dtype=int)
            if use_hierarchical:
                x[v_start + trial.params['vow_idx']] = 1
                x[c_start + trial.params['char_idx']] = 1
                for i in range(8):
                    x[i] = trial.params[f'sense_{i}']
            else:
                for i in range(n):
                    x[i] = trial.params[f'x_{i}']
            sols.append((trial.value, x))
    
    sols.sort(key=lambda t: t[0])
    
    # åŒã‚¨ãƒãƒ«ã‚®ãƒ¼ã®è§£ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¦å¤šæ§˜æ€§ã‚’ç¢ºä¿
    grouped_sols = []
    current_energy = None
    current_group = []
    for e, x in sols:
        if current_energy is None or abs(e - current_energy) < 0.001:
            current_group.append((e, x))
            current_energy = e
        else:
            random.shuffle(current_group)
            grouped_sols.extend(current_group)
            current_group = [(e, x)]
            current_energy = e
    if current_group:
        random.shuffle(current_group)
        grouped_sols.extend(current_group)
    
    if progress_container is not None:
        with progress_container:
            st.success(f"âœ… æœ€é©åŒ–å®Œäº†ï¼æœ€é©ã‚¨ãƒãƒ«ã‚®ãƒ¼: {study.best_value:.3f}")
    
    return grouped_sols, study

def solve_all(Q: Dict[Tuple[int,int], float], use_hierarchical: bool = False) -> List[Tuple[float, np.ndarray]]:
    """QUBOã®å…¨è§£ã‚’æ¢ç´¢ï¼ˆæ¯å›ç•°ãªã‚‹çµæœã‚’å¾—ã‚‹ãŸã‚ã€ãƒ©ãƒ³ãƒ€ãƒ è¦ç´ ã‚’è¿½åŠ ï¼‰
    
    Args:
        Q: QUBOè¾æ›¸
        use_hierarchical: å¤šå±¤ãƒã‚¤ãƒŠãƒªæ§‹é€ ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆTrue
    """
    # æ¯å›ç•°ãªã‚‹çµæœã‚’å¾—ã‚‹ãŸã‚ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ™ãƒ¼ã‚¹ã®ã‚·ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
    import time
    random_seed = int(time.time() * 1000) % 1000000
    np.random.seed(random_seed)
    random.seed(random_seed)
    
    if use_hierarchical:
        # å¤šå±¤ãƒã‚¤ãƒŠãƒªæ§‹é€ ã®å ´åˆ
        # å¤‰æ•°ã®ç·æ•°: 8ï¼ˆæ„Ÿè¦šï¼‰+ 12ï¼ˆèª“é¡˜ï¼‰+ 12ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ï¼‰= 32
        n = 32
        v_start = 8  # èª“é¡˜å¤‰æ•°ã®é–‹å§‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        c_start = 20  # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ•°ã®é–‹å§‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    else:
        # å¾“æ¥ã®æ§‹é€ ã®å ´åˆ
        n = len(VARIABLES)
        v_start = None
        c_start = None
    
    sols = []
    # å…¨æ¢ç´¢ã¯è¨ˆç®—é‡ãŒå¤§ãã„ãŸã‚ã€ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¾ãŸã¯ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚’ä½¿ç”¨
    # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«å…¨æ¢ç´¢ã‚’å®Ÿè£…ï¼ˆå®Ÿéš›ã®é‹ç”¨ã§ã¯æœ€é©åŒ–ãŒå¿…è¦ï¼‰
    max_samples = 2**min(n, 16)  # 2^16 = 65536ã¾ã§
    if n <= 16:
        # å…¨æ¢ç´¢ã®å ´åˆã§ã‚‚ã€çµæœã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¦å¤šæ§˜æ€§ã‚’ç¢ºä¿
        all_sols = []
        for bits in itertools.product([0,1], repeat=n):
            x = np.array(bits, dtype=int)
            # one-hotåˆ¶ç´„ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆéšå±¤æ§‹é€ ã®å ´åˆï¼‰
            if use_hierarchical:
                # èª“é¡˜å¤‰æ•°ï¼ˆ8ã€œ19ï¼‰ã®one-hotåˆ¶ç´„
                vow_sum = np.sum(x[v_start:v_start+12])
                # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ•°ï¼ˆ20ã€œ31ï¼‰ã®one-hotåˆ¶ç´„
                char_sum = np.sum(x[c_start:c_start+12])
                # one-hotåˆ¶ç´„ã‚’æº€ãŸã™è§£ã®ã¿ã‚’è¿½åŠ ï¼ˆå³å¯†ã«1ã¤ã ã‘é¸ã°ã‚Œã¦ã„ã‚‹ï¼‰
                if vow_sum == 1 and char_sum == 1:
                    e = qubo_energy(x, Q)
                    all_sols.append((e, x))
            else:
                e = qubo_energy(x, Q)
                all_sols.append((e, x))
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã§ã‚½ãƒ¼ãƒˆå¾Œã€åŒã‚¨ãƒãƒ«ã‚®ãƒ¼ã®è§£ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«
        all_sols.sort(key=lambda t: t[0])
        # åŒã‚¨ãƒãƒ«ã‚®ãƒ¼ã®ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«
        grouped_sols = []
        current_energy = None
        current_group = []
        for e, x in all_sols:
            if current_energy is None or abs(e - current_energy) < 0.001:
                current_group.append((e, x))
                current_energy = e
            else:
                random.shuffle(current_group)
                grouped_sols.extend(current_group)
                current_group = [(e, x)]
                current_energy = e
        if current_group:
            random.shuffle(current_group)
            grouped_sols.extend(current_group)
        sols = grouped_sols
    else:
        # å¤§ãã„å ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆone-hotåˆ¶ç´„ã‚’æº€ãŸã™è§£ã®ã¿ï¼‰
        valid_samples = 0
        max_attempts = 50000  # æœ€å¤§è©¦è¡Œå›æ•°
        attempts = 0
        
        while valid_samples < min(10000, max_samples) and attempts < max_attempts:
            attempts += 1
            x = np.random.randint(0, 2, size=n, dtype=int)
            
            # one-hotåˆ¶ç´„ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆéšå±¤æ§‹é€ ã®å ´åˆï¼‰
            if use_hierarchical:
                # èª“é¡˜å¤‰æ•°ï¼ˆ8ã€œ19ï¼‰ã®one-hotåˆ¶ç´„
                vow_sum = np.sum(x[v_start:v_start+12])
                # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ•°ï¼ˆ20ã€œ31ï¼‰ã®one-hotåˆ¶ç´„
                char_sum = np.sum(x[c_start:c_start+12])
                # one-hotåˆ¶ç´„ã‚’æº€ãŸã™è§£ã®ã¿ã‚’è¿½åŠ ï¼ˆå³å¯†ã«1ã¤ã ã‘é¸ã°ã‚Œã¦ã„ã‚‹ï¼‰
                if vow_sum == 1 and char_sum == 1:
                    e = qubo_energy(x, Q)
                    sols.append((e, x))
                    valid_samples += 1
            else:
                e = qubo_energy(x, Q)
                sols.append((e, x))
                valid_samples += 1
        
        # one-hotåˆ¶ç´„ã‚’æº€ãŸã™è§£ãŒå°‘ãªã„å ´åˆã€åˆ¶ç´„ã‚’ç·©å’Œ
        if len(sols) < 10 and use_hierarchical:
            # åˆ¶ç´„ã‚’ç·©å’Œã—ã¦è¿½åŠ ã®è§£ã‚’ç”Ÿæˆ
            for _ in range(min(1000, max_samples - len(sols))):
                x = np.random.randint(0, 2, size=n, dtype=int)
                # èª“é¡˜ã¨ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ã©ã¡ã‚‰ã‹ãŒé¸ã°ã‚Œã¦ã„ã‚Œã°OKï¼ˆç·©å’Œï¼‰
                vow_sum = np.sum(x[v_start:v_start+12])
                char_sum = np.sum(x[c_start:c_start+12])
                if vow_sum >= 1 and char_sum >= 1:
                    e = qubo_energy(x, Q)
                    sols.append((e, x))
    
    # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã§ã‚½ãƒ¼ãƒˆå¾Œã€åŒã‚¨ãƒãƒ«ã‚®ãƒ¼ã®è§£ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«
    sols.sort(key=lambda t: t[0])
    # åŒã‚¨ãƒãƒ«ã‚®ãƒ¼ã®ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«
    grouped_sols = []
    current_energy = None
    current_group = []
    for e, x in sols:
        if current_energy is None or abs(e - current_energy) < 0.001:
            current_group.append((e, x))
            current_energy = e
        else:
            random.shuffle(current_group)
            grouped_sols.extend(current_group)
            current_group = [(e, x)]
            current_energy = e
    if current_group:
        random.shuffle(current_group)
        grouped_sols.extend(current_group)
    
    return grouped_sols

# -------------------------
# ãƒœãƒ«ãƒ„ãƒãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
# -------------------------
def boltzmann_sample(cands: List[Tuple[float, np.ndarray]], T: float) -> Tuple[float, np.ndarray]:
    """ãƒœãƒ«ãƒ„ãƒãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§å€™è£œã‹ã‚‰1ã¤ã‚’é¸æŠ
    
    Args:
        cands: å€™è£œãƒªã‚¹ãƒˆï¼ˆ(ã‚¨ãƒãƒ«ã‚®ãƒ¼, è§£ãƒ™ã‚¯ãƒˆãƒ«)ã®ã‚¿ãƒ—ãƒ«ã®ãƒªã‚¹ãƒˆï¼‰
        T: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    
    Returns:
        é¸ã°ã‚ŒãŸå€™è£œï¼ˆ(ã‚¨ãƒãƒ«ã‚®ãƒ¼, è§£ãƒ™ã‚¯ãƒˆãƒ«)ã®ã‚¿ãƒ—ãƒ«ï¼‰
    """
    if not cands:
        raise ValueError("å€™è£œãŒç©ºã§ã™")
    
    if len(cands) == 1:
        return cands[0]
    
    # ã‚¨ãƒãƒ«ã‚®ãƒ¼å€¤ã‚’å–å¾—
    es = np.array([e for e,_ in cands], dtype=float)
    
    # NaNã‚„Infã‚’ãƒã‚§ãƒƒã‚¯
    if np.any(np.isnan(es)) or np.any(np.isinf(es)):
        # NaNã‚„InfãŒã‚ã‚‹å ´åˆã€æœ€åˆã®å€™è£œã‚’è¿”ã™
        return cands[0]
    
    # æ¸©åº¦ã®æœ€å°å€¤ã‚’ç¢ºä¿
    T = max(T, 1e-6)
    
    # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’æ­£è¦åŒ–ï¼ˆæœ€å°å€¤ã‚’0ã«ï¼‰
    es_min = es.min()
    es0 = es - es_min
    
    # é‡ã¿ã‚’è¨ˆç®—ï¼ˆãƒœãƒ«ãƒ„ãƒãƒ³åˆ†å¸ƒï¼‰
    # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒå¤§ãã™ãã‚‹å ´åˆã‚’é˜²ããŸã‚ã€æœ€å¤§å€¤ã‚’åˆ¶é™
    es0_clamped = np.clip(es0, 0, 100)  # æœ€å¤§100ã«åˆ¶é™
    weights = np.exp(-es0_clamped / T)
    
    # NaNã‚„Infã‚’ãƒã‚§ãƒƒã‚¯
    if np.any(np.isnan(weights)) or np.any(np.isinf(weights)):
        # å‡ç­‰ãªé‡ã¿ã‚’ä½¿ç”¨
        weights = np.ones(len(cands)) / len(cands)
    else:
        # æ­£è¦åŒ–
        weights_sum = weights.sum()
        if weights_sum == 0 or np.isnan(weights_sum) or np.isinf(weights_sum):
            # åˆè¨ˆãŒ0ã¾ãŸã¯NaN/Infã®å ´åˆã€å‡ç­‰ãªé‡ã¿ã‚’ä½¿ç”¨
            weights = np.ones(len(cands)) / len(cands)
        else:
            weights = weights / weights_sum
    
    # æœ€çµ‚çš„ãªNaNãƒã‚§ãƒƒã‚¯
    if np.any(np.isnan(weights)):
        weights = np.ones(len(cands)) / len(cands)
    
    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    try:
        idx = np.random.choice(len(cands), p=weights)
    except ValueError as e:
        # é‡ã¿ã®åˆè¨ˆãŒ1ã§ãªã„å ´åˆãªã©ã€å‡ç­‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        idx = np.random.randint(0, len(cands))
    
    return cands[idx]

def temperature_from_mood(m: Mood, selected_character: Optional[str] = None) -> float:
    """Moodã«åŸºã¥ã„ã¦ãƒœãƒ«ãƒ„ãƒãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®æ¸©åº¦ã‚’èª¿æ•´ï¼ˆæ”¹å–„ç‰ˆï¼‰
    
    Args:
        m: Moodã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        selected_character: é¸æŠã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    Returns:
        æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    """
    # ãƒ™ãƒ¼ã‚¹æ¸©åº¦ï¼ˆå¥½å¥‡å¿ƒãŒé«˜ã„ã¨æºã‚‰ããŒå¤§ãããªã‚‹ï¼‰
    T = 0.4 + 0.3 * m.curiosity
    
    # æ±ºæ–­åŠ›ãŒé«˜ã„ã¨ã€ã‚ˆã‚Šç¢ºå®šçš„ã«ï¼ˆæ¸©åº¦ã‚’ä¸‹ã’ã‚‹ï¼‰
    T *= (1.0 - 0.3 * m.decisiveness)
    
    # ä¸å®‰ãŒé«˜ã„ã¨ã€ã‚ˆã‚Šæ¢ç´¢çš„ã«ãªã‚‹ï¼ˆæ¸©åº¦ã‚’ä¸Šã’ã‚‹ï¼‰
    T *= (1.0 + 0.2 * m.anxiety)
    
    # ç–²ã‚ŒãŒé«˜ã„ã¨ã€å°‘ã—æºã‚‰ãã‚’å¢—ã‚„ã™ï¼ˆå¤šæ§˜ãªé¸æŠè‚¢ã‚’æç¤ºï¼‰
    T *= (1.0 + 0.15 * m.fatigue)
    
    # å­¤ç‹¬æ„ŸãŒé«˜ã„ã¨ã€ã‚ˆã‚Šç¢ºå®šçš„ã«ï¼ˆæ¸©åº¦ã‚’ä¸‹ã’ã‚‹ï¼‰
    T *= (1.0 - 0.2 * m.loneliness)
    
    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã€æœ€ä½æ¸©åº¦ã‚’ç¢ºä¿ã—ã¦å¤šæ§˜æ€§ã‚’ç¶­æŒ
    if selected_character:
        T = max(0.35, T)  # æœ€ä½æ¸©åº¦0.35ã‚’ç¢ºä¿
    
    # æ¸©åº¦ã®ç¯„å›²ã‚’åˆ¶é™ï¼ˆæºã‚‰ãã™ããªã„ã€åæŸã—ã™ããªã„ï¼‰
    return max(0.2, min(0.9, T))

# -------------------------
# ãŠã¿ãã˜ç”Ÿæˆ
# -------------------------
def picks_from_x(x: np.ndarray, use_hierarchical: bool = False, selected_god: Dict = None) -> List[str]:
    """é¸ã°ã‚ŒãŸæ ¼è¨€ã‚’è¿”ã™
    
    Args:
        x: è§£ãƒ™ã‚¯ãƒˆãƒ«
        use_hierarchical: å¤šå±¤ãƒã‚¤ãƒŠãƒªæ§‹é€ ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆTrue
        selected_god: æ—¢ã«é¸ã°ã‚ŒãŸç¥ã®æƒ…å ±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€éšå±¤æ§‹é€ ã®å ´åˆã«ä½¿ç”¨ï¼‰
    """
    if use_hierarchical:
        # éšå±¤æ§‹é€ ã®å ´åˆã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ•°ã‹ã‚‰é¸ã°ã‚ŒãŸç¥ã‚’å–å¾—
        # è§£ãƒ™ã‚¯ãƒˆãƒ«ã®ã‚µã‚¤ã‚ºã‚’ç¢ºèªï¼ˆ32ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ï¼‰
        if len(x) < 32:
            # ã‚µã‚¤ã‚ºãŒè¶³ã‚Šãªã„å ´åˆã€selected_godã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
            if selected_god and selected_god.get("maxim"):
                return [selected_god["maxim"]]
            return ["ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚"]
        
        c_start = 20
        selected_god_ids = [i - c_start for i in range(c_start, min(c_start + 12, len(x))) if i < len(x) and x[i] == 1]
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ•°ã‹ã‚‰é¸ã°ã‚ŒãŸç¥ã‚’å–å¾—
        if selected_god_ids and 0 <= selected_god_ids[0] < len(TWELVE_GODS):
            god = TWELVE_GODS[selected_god_ids[0]]
            if god.get("maxim"):
                return [god["maxim"]]
            elif god.get("description"):
                return [god["description"]]
            else:
                return ["ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚"]
        elif selected_god:
            # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ•°ã‹ã‚‰é¸ã°ã‚Œã¦ã„ãªã„å ´åˆã€selected_godã‹ã‚‰å–å¾—
            if selected_god.get("maxim"):
                return [selected_god["maxim"]]
            elif selected_god.get("description"):
                return [selected_god["description"]]
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ ¼è¨€ã‚’è¿”ã™
        return ["ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚"]
    else:
        # å¾“æ¥ã®æ§‹é€ ã®å ´åˆ
        max_idx = min(len(x), len(VARIABLES))
        p = [VARIABLES[i] for i in range(max_idx) if x[i] == 1]
        return p if p else ["ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚"]

def get_maxim_source(maxim: str) -> Dict:
    """æ ¼è¨€ã®å¼•ç”¨å…ƒæƒ…å ±ã‚’å–å¾—"""
    if maxim in MAXIM_SOURCES:
        return MAXIM_SOURCES[maxim]
    # æœ‰åå¼•ç”¨ï¼ˆFAMOUS_QUOTESï¼‰ã‚‚å‚ç…§
    try:
        for q in FAMOUS_QUOTES:
            if q.get("quote") == maxim:
                return {
                    "source": q.get("source", "å¼•ç”¨"),
                    "origin": q.get("origin", ""),
                    "reference": q.get("reference", ""),
                }
    except Exception:
        pass
    return {
        "source": "ä¼çµ±çš„ãªæ•™ãˆ",
        "origin": "å¤æ¥ã‚ˆã‚Šä¼ã‚ã‚‹æ™ºæ…§",
        "reference": "é•·ã„å¹´æœˆã‚’ã‹ã‘ã¦å—ã‘ç¶™ãŒã‚Œã¦ããŸçŸ¥æµ"
    }

def select_maxims_for_god(
    god: Dict,
    context_text: str,
    top_k: int = 2,
    include_famous_quote: bool = True,
    exclude_maxims: Optional[List[str]] = None,
    selected_vow_index: Optional[int] = None
) -> List[str]:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ï¼ˆcontext_textï¼‰ã¨QUBOã§é¸ã°ã‚ŒãŸèª“é¡˜ï¼ˆVOWï¼‰ã«å¿œã˜ã¦ã€ç¥ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ï¼‰ã®è¤‡æ•°æ ¼è¨€ã‚’é¸ã¶
    
    Args:
        god: ç¥ã®æƒ…å ±
        context_text: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        top_k: é¸æŠã™ã‚‹æ ¼è¨€ã®æ•°
        include_famous_quote: æœ‰ååè¨€ã‚’å«ã‚ã‚‹ã‹
        exclude_maxims: é™¤å¤–ã™ã‚‹æ ¼è¨€ã®ãƒªã‚¹ãƒˆï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
        selected_vow_index: QUBOã§é¸ã°ã‚ŒãŸèª“é¡˜ï¼ˆVOWï¼‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0-11ã€VOW_01ï½VOW_12ã«å¯¾å¿œï¼‰
    """
    if not god:
        return ["ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚"]

    exclude_set = set(exclude_maxims or [])
    ctx = (context_text or "").strip()
    keywords = extract_keywords_safe(ctx, top_n=8) if ctx else []  # ã‚ˆã‚Šå¤šãã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæŠ½å‡ºã•ã‚Œãªã„å ´åˆã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç›´æ¥å˜èªã‚’æŠ½å‡º
    if not keywords and ctx:
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’å˜èªã«åˆ†å‰²ã—ã¦ã€2æ–‡å­—ä»¥ä¸Šã®å˜èªã‚’æŠ½å‡º
        import re
        text_clean = re.sub(r'[0-9ï¼-ï¼™\W]+', ' ', ctx)
        words = text_clean.split()
        keywords = [w for w in words if len(w) >= 2][:8]

    # å€™è£œï¼ˆmaxims ãŒã‚ã‚Œã°ãã‚Œã‚’ã€ãªã‘ã‚Œã° maxim/descriptionï¼‰
    maxims = god.get("maxims") or []
    items: List[Dict[str, object]] = []
    for it in maxims:
        if isinstance(it, dict) and it.get("text"):
            text = str(it["text"]).strip()
            # é™¤å¤–ãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã¦ã„ãªã„å ´åˆã®ã¿è¿½åŠ 
            if text and text not in exclude_set:
                items.append({"text": text, "tags": it.get("tags") or []})

    if not items:
        base = (god.get("maxim") or "").strip()
        if base and base not in exclude_set:
            items = [{"text": base, "tags": []}]
        else:
            desc = (god.get("description") or "").strip()
            default_text = desc or "ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚"
            if default_text not in exclude_set:
                items = [{"text": default_text, "tags": []}]
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã€MAXIMS_DATABASEã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦æ ¼è¨€ã‚’è¿½åŠ 
    if keywords and MAXIMS_DATABASE:
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦MAXIMS_DATABASEã‹ã‚‰æ ¼è¨€ã‚’é¸æŠ
        db_maxims = select_maxims_from_database(keywords, top_k=5, exclude_maxims=list(exclude_set))
        for maxim in db_maxims:
            maxim_text = maxim.get("text", "")
            if maxim_text and maxim_text not in [it.get("text", "") for it in items]:
                items.append({"text": maxim_text, "tags": maxim.get("tags", [])})
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆã€æ ¼è¨€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚‚è¿½åŠ ã§å€™è£œã‚’å–å¾—ï¼ˆå¤šæ§˜æ€§ã‚’ç¢ºä¿ï¼‰
    if not keywords and MAXIMS_DATABASE:
        # ãƒ©ãƒ³ãƒ€ãƒ ã«ã„ãã¤ã‹ã®æ ¼è¨€ã‚’è¿½åŠ å€™è£œã¨ã—ã¦å–å¾—
        import time
        random.seed(int(time.time() * 1000) % 1000000)
        available_maxims = [m for m in MAXIMS_DATABASE if m.get("text") and m.get("text") not in exclude_set]
        random.shuffle(available_maxims)
        # æœ€å¤§3ã¤ã¾ã§è¿½åŠ 
        for maxim in available_maxims[:3]:
            maxim_text = maxim.get("text", "")
            if maxim_text and maxim_text not in [it.get("text", "") for it in items]:
                items.append({"text": maxim_text, "tags": maxim.get("tags", [])})

    def score_item(item: Dict[str, object], item_index: int) -> float:
        text = str(item.get("text", "") or "")
        tags = [str(t) for t in (item.get("tags") or [])]
        text_lower = text.lower()
        tags_lower = [str(t).lower() for t in tags]
        s = 0.0
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆæœ€å„ªå…ˆï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®åˆ†æçµæœï¼‰
        if keywords:
            matched_keywords = 0
            # ã‚¿ã‚°ä¸€è‡´ã‚’æœ€å„ªå…ˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®åˆ†æçµæœã‚’åæ˜ ï¼‰
            for kw in keywords:
                kw_lower = kw.lower()
                # ã‚¿ã‚°å®Œå…¨ä¸€è‡´
                if kw_lower in tags_lower:
                    s += 10.0  # ã‚¿ã‚°ä¸€è‡´ã¯æœ€é«˜ã‚¹ã‚³ã‚¢ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®åˆ†æçµæœã‚’æœ€å„ªå…ˆï¼‰
                    matched_keywords += 1
                # ã‚¿ã‚°éƒ¨åˆ†ä¸€è‡´
                elif any(kw_lower in tag_lower for tag_lower in tags_lower):
                    s += 8.0  # ã‚¿ã‚°éƒ¨åˆ†ä¸€è‡´ã‚‚é«˜ã‚¹ã‚³ã‚¢
                    matched_keywords += 1
                # ãƒ†ã‚­ã‚¹ãƒˆå®Œå…¨ä¸€è‡´ï¼ˆæœ€å„ªå…ˆï¼‰
                elif kw_lower in text_lower:
                    s += 15.0  # ãƒ†ã‚­ã‚¹ãƒˆå†…ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å®Œå…¨ä¸€è‡´ã¯æœ€é«˜ã‚¹ã‚³ã‚¢
                    matched_keywords += 1
                # ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ä¸€è‡´ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼š2æ–‡å­—ä»¥ä¸Šã®éƒ¨åˆ†ä¸€è‡´ï¼‰
                elif len(kw) >= 2 and kw[:2] in text_lower:
                    s += 8.0  # éƒ¨åˆ†ä¸€è‡´ã‚‚é«˜ã‚¹ã‚³ã‚¢
                    matched_keywords += 1
                # ã•ã‚‰ã«æŸ”è»Ÿãªãƒãƒƒãƒãƒ³ã‚°ï¼šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹
                elif any(c in text_lower for c in kw_lower if len(c) >= 1):
                    s += 3.0  # æ–‡å­—ãƒ¬ãƒ™ãƒ«ã§ã®ä¸€è‡´ã‚‚è€ƒæ…®ï¼ˆã‚¹ã‚³ã‚¢ã‚’ä¸Šã’ã‚‹ï¼‰
                    matched_keywords += 1
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¤‡æ•°ä¸€è‡´ã™ã‚‹å ´åˆã€å¤§å¹…ãªãƒœãƒ¼ãƒŠã‚¹ï¼ˆé‡è¦ï¼‰
            if matched_keywords >= 2:
                s += 10.0 * matched_keywords  # è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´ã¯å¤§å¹…ãªãƒœãƒ¼ãƒŠã‚¹
            elif matched_keywords == 1:
                s += 5.0  # å˜ä¸€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´ã§ã‚‚ãƒœãƒ¼ãƒŠã‚¹
        
        # QUBOã§é¸ã°ã‚ŒãŸèª“é¡˜ï¼ˆVOWï¼‰ã«åŸºã¥ãã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆã®è£œåŠ©ï¼‰
        if selected_vow_index is not None:
            # é¸ã°ã‚ŒãŸèª“é¡˜ã«å¯¾å¿œã™ã‚‹VOWå€¤ãŒé«˜ã„å ´åˆã€ãã®ç¥ã®æ ¼è¨€ã‚’å„ªå…ˆ
            vows = god.get("vows", {})
            vow_key = f"vow{selected_vow_index+1:02d}"
            if vow_key in vows:
                vow_value = float(vows[vow_key])
                # VOWå€¤ãŒè² ï¼ˆå¼·ã„é–¢é€£æ€§ï¼‰ã®å ´åˆã€ã‚¹ã‚³ã‚¢ã‚’ä¸Šã’ã‚‹ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆã®è£œåŠ©ï¼‰
                if vow_value < 0:
                    s += abs(vow_value) * 3.0  # VOWå€¤ã«åŸºã¥ãå„ªå…ˆåº¦ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆã®è£œåŠ©ï¼‰
                elif vow_value > 0:
                    s += vow_value * 1.0  # æ­£ã®å€¤ã§ã‚‚å°‘ã—å„ªå…ˆ
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚VOWã‚¹ã‚³ã‚¢ã‚‚ãªã„å ´åˆ
        if s == 0.0:
            # ãƒ©ãƒ³ãƒ€ãƒ è¦ç´ ã‚’è¿½åŠ ã—ã¦å¤šæ§˜æ€§ã‚’ç¢ºä¿
            import time
            random.seed(int(time.time() * 1000) % 1000000 + item_index)
            s = random.uniform(0.01, 0.5)  # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚¹ã‚³ã‚¢ã‚’è¨­å®š
        
        # æ–‡ç« ãŒçŸ­ã™ãã‚‹å ´åˆã¯å°‘ã—æ¸›ç‚¹
        if len(text) < 6:
            s -= 0.5
        return s

    scored = [(score_item(it, idx), it["text"]) for idx, it in enumerate(items) if it.get("text")]
    
    # ã‚¹ã‚³ã‚¢ãŒåŒç‚¹ãªã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«æºã‚‰ãï¼ˆå„å‘¼ã³å‡ºã—ã§ç•°ãªã‚‹çµæœã‚’å¾—ã‚‹ãŸã‚ï¼‰
    import time
    # é–¢æ•°ã®å‘¼ã³å‡ºã—ã”ã¨ã«ç•°ãªã‚‹ã‚·ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ï¼ˆgodã®IDã¨æ™‚é–“ã‚’çµ„ã¿åˆã‚ã›ï¼‰
    god_id = god.get("id", 0) if isinstance(god.get("id"), int) else hash(str(god.get("name", ""))) % 1000
    random.seed(int(time.time() * 1000) % 1000000 + god_id * 100 + len(items))
    random.shuffle(scored)
    scored.sort(key=lambda t: t[0], reverse=True)

    picks: List[str] = []
    for s, t in scored:
        if t and t not in picks and t not in exclude_set:
            picks.append(t)
        if len(picks) >= max(1, top_k):
            break

    # å…¨éƒ¨ã‚¹ã‚³ã‚¢ãŒä½ã„ï¼ˆ=ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«å¼•ã£ã‹ã‹ã‚‰ãªã„ï¼‰ãªã‚‰ã€ãƒ©ãƒ³ãƒ€ãƒ ã«è¤‡æ•°æç¤º
    # ãŸã ã—ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã¯ã€ã‚¹ã‚³ã‚¢ãŒä½ãã¦ã‚‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦é¸æŠ
    if scored:
        if keywords and scored[0][0] < 5.0:  # ã‚¹ã‚³ã‚¢ãŒä½ã„å ´åˆï¼ˆ5.0æœªæº€ï¼‰
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹ãŒã‚¹ã‚³ã‚¢ãŒä½ã„å ´åˆã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦å†ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
            # éƒ¨åˆ†ä¸€è‡´ã‚„é¡ä¼¼èªã‚‚è€ƒæ…®ã—ã¦ã€ã‚ˆã‚ŠæŸ”è»Ÿã«ãƒãƒƒãƒãƒ³ã‚°
            rescored = []
            for s, t in scored:
                text_lower = t.lower()
                new_score = s
                matched_kw_count = 0
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®éƒ¨åˆ†ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
                for kw in keywords:
                    kw_lower = kw.lower()
                    # å®Œå…¨ä¸€è‡´
                    if kw_lower in text_lower:
                        new_score += 10.0  # å®Œå…¨ä¸€è‡´ã¯å¤§å¹…ãªã‚¹ã‚³ã‚¢ã‚¢ãƒƒãƒ—
                        matched_kw_count += 1
                    # éƒ¨åˆ†ä¸€è‡´ï¼ˆ2æ–‡å­—ä»¥ä¸Šï¼‰
                    elif len(kw) >= 2 and kw[:2] in text_lower:
                        new_score += 5.0  # éƒ¨åˆ†ä¸€è‡´ã‚‚é«˜ã‚¹ã‚³ã‚¢
                        matched_kw_count += 1
                    # æ–‡å­—ãƒ¬ãƒ™ãƒ«ã§ã®ä¸€è‡´
                    elif any(c in text_lower for c in kw_lower if len(c) >= 1):
                        new_score += 2.0  # æ–‡å­—ãƒ¬ãƒ™ãƒ«ã§ã®ä¸€è‡´ã‚‚è€ƒæ…®
                        matched_kw_count += 1
                
                # è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´ã®ãƒœãƒ¼ãƒŠã‚¹
                if matched_kw_count >= 2:
                    new_score += matched_kw_count * 5.0
                
                rescored.append((new_score, t))
            rescored.sort(key=lambda t: t[0], reverse=True)
            scored = rescored
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã€ã‚¹ã‚³ã‚¢ãŒä½ãã¦ã‚‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦é¸æŠ
        if keywords and scored and scored[0][0] < 3.0:
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦å†é¸æŠï¼ˆMAXIMS_DATABASEã‹ã‚‰ã‚‚è¿½åŠ ã§å–å¾—ï¼‰
            if MAXIMS_DATABASE:
                db_maxims = select_maxims_from_database(keywords, top_k=top_k * 2, exclude_maxims=list(exclude_set))
                for maxim in db_maxims:
                    maxim_text = maxim.get("text", "")
                    if maxim_text and maxim_text not in picks and maxim_text not in exclude_set:
                        picks.append(maxim_text)
                        if len(picks) >= top_k:
                            break
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãªã„å ´åˆã€ã¾ãŸã¯ã‚¹ã‚³ã‚¢ãŒéå¸¸ã«ä½ã„å ´åˆã®ã¿ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
        if not keywords and scored and scored[0][0] < 1.0:
            all_texts = [t for _, t in scored if t and t not in exclude_set]
            # å†åº¦ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®šã—ã¦å¤šæ§˜æ€§ã‚’ç¢ºä¿
            random.seed(int(time.time() * 1000) % 1000000 + god_id * 200 + len(all_texts))
            random.shuffle(all_texts)
            picks = list(dict.fromkeys(all_texts))[:max(1, top_k)]

    # æœ‰ååè¨€ã‚‚1ã¤æ··ãœã‚‹ï¼ˆä»»æ„ï¼‰
    if include_famous_quote and keywords:
        famous = select_relevant_quote(keywords, exclude_quotes=exclude_set)
        if famous and famous not in picks and famous not in exclude_set:
            picks.append(famous)

    return picks if picks else ["ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚"]

def get_selected_vow_from_x(x: np.ndarray, use_hierarchical: bool = False) -> Optional[int]:
    """QUBOã®è§£ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰é¸ã°ã‚ŒãŸèª“é¡˜ï¼ˆVOWï¼‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    
    Args:
        x: è§£ãƒ™ã‚¯ãƒˆãƒ«
        use_hierarchical: å¤šå±¤ãƒã‚¤ãƒŠãƒªæ§‹é€ ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆTrue
    
    Returns:
        é¸ã°ã‚ŒãŸèª“é¡˜ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0-11ã€VOW_01ï½VOW_12ã«å¯¾å¿œï¼‰ã€é¸ã°ã‚Œã¦ã„ãªã„å ´åˆã¯None
    """
    if use_hierarchical:
        # å¤šå±¤ãƒã‚¤ãƒŠãƒªæ§‹é€ ã®å ´åˆ
        if len(x) < 32:
            return None
        
        # èª“é¡˜å¤‰æ•°ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: 8ï½19
        v_start = 8
        selected_vow_ids = [i - v_start for i in range(v_start, min(v_start + 12, len(x))) if i < len(x) and x[i] == 1]
        
        if selected_vow_ids:
            return selected_vow_ids[0]  # æœ€åˆã«é¸ã°ã‚ŒãŸèª“é¡˜ã‚’è¿”ã™
    else:
        # å¾“æ¥ã®æ§‹é€ ã§ã¯èª“é¡˜å¤‰æ•°ãŒãªã„
        return None
    
    return None

def get_selected_god_from_x(x: np.ndarray, mood: Mood = None, use_hierarchical: bool = False) -> Dict:
    """é¸ã°ã‚ŒãŸç¥ã‚’å–å¾—
    
    Args:
        x: è§£ãƒ™ã‚¯ãƒˆãƒ«
        mood: Moodã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        use_hierarchical: å¤šå±¤ãƒã‚¤ãƒŠãƒªæ§‹é€ ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆTrue
    """
    if use_hierarchical:
        # å¤šå±¤ãƒã‚¤ãƒŠãƒªæ§‹é€ ã®å ´åˆ
        # è§£ãƒ™ã‚¯ãƒˆãƒ«ã®ã‚µã‚¤ã‚ºã‚’ç¢ºèªï¼ˆ32ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ï¼‰
        if len(x) < 32:
            # ã‚µã‚¤ã‚ºãŒè¶³ã‚Šãªã„å ´åˆã€Moodã‹ã‚‰é¸æŠã™ã‚‹ã‹ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’è¿”ã™
            if mood is not None:
                return select_god_from_mood(mood)
            else:
                return TWELVE_GODS[0]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ•°ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: 20ï½31
        c_start = 20
        selected_god_ids = [i - c_start for i in range(c_start, min(c_start + 12, len(x))) if i < len(x) and x[i] == 1]
    else:
        # å¾“æ¥ã®æ§‹é€ ã®å ´åˆ
        max_idx = min(len(x), len(TWELVE_GODS))
        selected_god_ids = [i for i in range(max_idx) if x[i] == 1]
    
    if not selected_god_ids:
        # ä½•ã‚‚é¸ã°ã‚Œã¦ã„ãªã„å ´åˆã€Moodã‹ã‚‰æœ€ã‚‚é©ã—ãŸç¥ã‚’é¸æŠ
        if mood is not None:
            return select_god_from_mood(mood)
        else:
            return TWELVE_GODS[0]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    # é¸ã°ã‚ŒãŸç¥ã®ä¸­ã§ã€Moodã«æœ€ã‚‚è¿‘ã„ç¥ã‚’é¸æŠ
    if mood is not None:
        best_god = None
        best_score = -float('inf')
        for god_id in selected_god_ids:
            if 0 <= god_id < len(TWELVE_GODS):
                god = TWELVE_GODS[god_id]
                # æ–°ã—ã„èª“é¡˜æ§‹é€ ï¼ˆvow01ï½vow12ï¼‰ã§ã¯ã€Moodã¨ã®ç›´æ¥æ¯”è¼ƒãŒé›£ã—ã„ãŸã‚
                # å½¹å‰²å±æ€§ï¼ˆrolesï¼‰ã‚’ä½¿ç”¨ã—ã¦é¡ä¼¼åº¦ã‚’è¨ˆç®—
                score = 0.0
                # å½¹å‰²å±æ€§ã®é¡ä¼¼åº¦
                if mood.fatigue > 0.5:
                    score += abs(god["roles"]["stillness"]) * 0.25
                if mood.anxiety > 0.5:
                    score += abs(god["roles"]["flow"]) * 0.25
                if mood.curiosity > 0.5:
                    score += abs(god["roles"]["ma"]) * 0.25
                if mood.decisiveness > 0.5:
                    score += abs(god["roles"]["sincerity"]) * 0.25
                
                if score > best_score:
                    best_score = score
                    best_god = god
        return best_god if best_god else TWELVE_GODS[selected_god_ids[0]]
    else:
        # MoodãŒãªã„å ´åˆã€æœ€åˆã«é¸ã°ã‚ŒãŸç¥ã‚’è¿”ã™
        return TWELVE_GODS[selected_god_ids[0]] if selected_god_ids[0] < len(TWELVE_GODS) else TWELVE_GODS[0]

def oracle_card(
    e: float,
    x: np.ndarray,
    mood: Mood = None,
    use_hierarchical: bool = False,
    context_text: str = "",
    use_llm: bool = False,
    llm_type: str = "huggingface"
) -> Dict:
    """æ ¼è¨€ãƒ™ãƒ¼ã‚¹ã®ãŠã¿ãã˜ã‚«ãƒ¼ãƒ‰ã‚’ç”Ÿæˆï¼ˆMoodã«å¿œã˜ã¦å¤‰åŒ–ã€12ç¥å¯¾å¿œï¼‰
    
    Args:
        e: ã‚¨ãƒãƒ«ã‚®ãƒ¼å€¤
        x: è§£ãƒ™ã‚¯ãƒˆãƒ«
        mood: Moodã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        use_hierarchical: éšå±¤æ§‹é€ ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        context_text: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        use_llm: LLMã‚’ä½¿ç”¨ã™ã‚‹ã‹
        llm_type: LLMã®ç¨®é¡ï¼ˆ"ollama" or "huggingface"ï¼‰
    """
    # é¸ã°ã‚ŒãŸç¥ã‚’å–å¾—ï¼ˆå…ˆã«å–å¾—ã—ã¦ã€æ ¼è¨€ã‚‚å–å¾—ï¼‰
    selected_god = get_selected_god_from_x(x, mood, use_hierarchical=use_hierarchical)
    
    # QUBOã®è§£ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰é¸ã°ã‚ŒãŸèª“é¡˜ï¼ˆVOWï¼‰ã‚’å–å¾—
    selected_vow_index = None
    if use_hierarchical:
        selected_vow_index = get_selected_vow_from_x(x, use_hierarchical=use_hierarchical)
    
    # æœ€è¿‘ä½¿ç”¨ã—ãŸæ ¼è¨€ã‚’å–å¾—ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
    if 'recent_maxims' not in st.session_state:
        st.session_state.recent_maxims = []
    exclude_maxims = st.session_state.recent_maxims[-10:]  # ç›´è¿‘10ä»¶ã‚’é™¤å¤–
    
    # æ ¼è¨€ã‚’å–å¾—ï¼ˆéšå±¤æ§‹é€ ã®å ´åˆã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æ–‡é¢ã§è¤‡æ•°é¸ã¶ï¼‰
    # QUBOã§é¸ã°ã‚ŒãŸèª“é¡˜ï¼ˆVOWï¼‰ã®æƒ…å ±ã‚’ä½¿ç”¨
    # ã€ç¥è¨—å¯„ã‚Šã«ã‚·ãƒ•ãƒˆã€‘å„ªå…ˆé †ä½ã‚’å¤‰æ›´ï¼šVOWãƒ™ãƒ¼ã‚¹ã®æ ¼è¨€ç”Ÿæˆ > ç¥ã®æ ¼è¨€ > ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®æ ¼è¨€
    if use_hierarchical:
        picks = []
        
        # ã€æœ€å„ªå…ˆã€‘QUBOã§é¸ã°ã‚ŒãŸèª“é¡˜ï¼ˆVOWï¼‰ã®ãƒ™ã‚¯ãƒˆãƒ«ã«åŸºã¥ã„ã¦ã‚ªãƒªã‚¸ãƒŠãƒ«ãªæ ¼è¨€ã‚’ç”Ÿæˆï¼ˆç¥è¨—ã‚‰ã—ã„ï¼‰
        if selected_vow_index is not None:
            original_maxim = create_original_maxim_from_vow(
                selected_vow_index=selected_vow_index,
                god=selected_god,
                top_k=3
            )
            if original_maxim and original_maxim not in picks and original_maxim not in exclude_maxims:
                # ã‚ªãƒªã‚¸ãƒŠãƒ«ãªæ ¼è¨€ã‚’æœ€åˆã«è¿½åŠ ï¼ˆæœ€å„ªå…ˆè¡¨ç¤ºï¼šç¥è¨—ã‚‰ã—ã„ï¼‰
                picks.insert(0, original_maxim)
        
        # ã€ç¬¬2å„ªå…ˆã€‘é¸ã°ã‚ŒãŸç¥ã®æ ¼è¨€ã‚’å„ªå…ˆçš„ã«é¸æŠï¼ˆç¥è¨—ã®æ ¸å¿ƒï¼‰
        # ç¥ã®æ ¼è¨€ã¯å¸¸ã«å«ã‚ã‚‹ï¼ˆå…¥åŠ›ãŒãªã„å ´åˆã‚‚ç¥è¨—ã¨ã—ã¦æ©Ÿèƒ½ï¼‰
        top_k_for_selection = 4 if context_text else 3
        god_picks = select_maxims_for_god(
            selected_god, 
            context_text=context_text,  # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’ä½¿ç”¨ï¼ˆã‚ã‚Œã°ï¼‰
            top_k=top_k_for_selection, 
            include_famous_quote=False,  # æœ‰ååè¨€ã¯é™¤å¤–ï¼ˆç¥è¨—ã‚‰ã—ã•ã‚’å„ªå…ˆï¼‰
            exclude_maxims=exclude_maxims,
            selected_vow_index=selected_vow_index
        )
        for pick in god_picks:
            if pick and pick not in picks and pick not in exclude_maxims:
                picks.append(pick)
                if len(picks) >= 6:  # ç¥ã®æ ¼è¨€ã‚’å„ªå…ˆçš„ã«å¤šãé¸æŠ
                    break
        
        # ã€ç¬¬3å„ªå…ˆã€‘ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãŒã‚ã‚‹å ´åˆã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦æ ¼è¨€ã‚’é¸æŠï¼ˆè£œåŠ©çš„ï¼‰
        if context_text:
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆã‚ˆã‚Šå¤šãã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼‰
            keywords = extract_keywords_safe(context_text, top_n=12)
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦æ ¼è¨€ã‚’ç”Ÿæˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã«ç›´æ¥å¿œãˆã‚‹ï¼‰
            if keywords and len(picks) < 4:  # ç¥ã®æ ¼è¨€ãŒå°‘ãªã„å ´åˆã®ã¿
                generated_maxim = generate_maxim_from_keywords(keywords, context_text)
                if generated_maxim and generated_maxim not in picks and generated_maxim not in exclude_maxims:
                    picks.append(generated_maxim)  # ç”Ÿæˆã•ã‚ŒãŸæ ¼è¨€ã‚’è¿½åŠ ï¼ˆå„ªå…ˆåº¦ã¯ä½ã‚ï¼‰
            
            # MAXIMS_DATABASEã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦æ ¼è¨€ã‚’é¸æŠï¼ˆè£œåŠ©çš„ï¼‰
            if MAXIMS_DATABASE and keywords and len(picks) < 5:
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦æ ¼è¨€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é¸æŠ
                db_maxims = select_maxims_from_database(keywords, top_k=5, exclude_maxims=exclude_maxims)
                for db_maxim in db_maxims:
                    maxim_text = db_maxim.get("text", "")
                    if maxim_text and maxim_text not in picks and maxim_text not in exclude_maxims:
                        picks.append(maxim_text)
                        if len(picks) >= 6:  # æœ€å¤§6ã¤ã¾ã§
                            break
        
        # æœ€å¤§4ã¤ã¾ã§ã«åˆ¶é™ï¼ˆç¥è¨—ã‚‰ã—ã•ã‚’ä¿ã¤ãŸã‚ã€å¤šã™ããªã„ã‚ˆã†ã«ï¼‰
        if len(picks) > 4:
            picks = picks[:4]
    
    # é¸æŠã—ãŸæ ¼è¨€ã‚’å±¥æ­´ã«è¿½åŠ ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
    for pick in picks:
        if pick and pick not in st.session_state.recent_maxims:
            st.session_state.recent_maxims.append(pick)
            # å±¥æ­´ã¯æœ€å¤§20ä»¶ã«åˆ¶é™
            if len(st.session_state.recent_maxims) > 20:
                st.session_state.recent_maxims.pop(0)
    else:
        picks = picks_from_x(x, use_hierarchical=use_hierarchical, selected_god=selected_god)
    
    # æ ¼è¨€ãŒç©ºã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å ´åˆã€é¸ã°ã‚ŒãŸç¥ã®æ ¼è¨€ã‚’ä½¿ç”¨
    # ãŸã ã—ã€context_textãŒã‚ã‚‹å ´åˆã¯ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦å†è©¦è¡Œ
    if not picks or (len(picks) == 1 and picks[0] == "ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚"):
        # context_textãŒã‚ã‚‹å ´åˆã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦å†è©¦è¡Œ
        if context_text and MAXIMS_DATABASE:
            keywords = extract_keywords_safe(context_text, top_n=8)
            if keywords:
                db_maxims = select_maxims_from_database(keywords, top_k=3, exclude_maxims=exclude_maxims)
                if db_maxims:
                    picks = [m.get("text", "") for m in db_maxims if m.get("text")]
        
        # ãã‚Œã§ã‚‚æ ¼è¨€ãŒãªã„å ´åˆã€é¸ã°ã‚ŒãŸç¥ã®æ ¼è¨€ã‚’ä½¿ç”¨
        if not picks or (len(picks) == 1 and picks[0] == "ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚"):
            if selected_god and selected_god.get("maxim"):
                picks = [selected_god["maxim"]]
            elif selected_god and selected_god.get("description"):
                picks = [selected_god["description"]]
            else:
                picks = ["ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚"]
    
    season = random.choice(SEASONS)
    
    # LLMã‚’ä½¿ç”¨ã—ã¦ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸç¥è¨—ã‚’ç”Ÿæˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    llm_oracle = None
    if use_llm and context_text and mood:
        try:
            llm_oracle = generate_oracle_with_llm(
                user_text=context_text,
                selected_god=selected_god,
                selected_maxims=picks,
                mood=mood,
                llm_type=llm_type
            )
        except Exception as e:
            # LLMç”Ÿæˆã«å¤±æ•—ã—ãŸå ´åˆã€é€šå¸¸ã®æ ¼è¨€ã‚’ä½¿ç”¨
            pass
    
    # Moodã«å¿œã˜ã¦ã€Œæ¬¡ã®ä¸€æ­©ã€ã‚’é¸æŠ
    if mood is not None:
        # æœ€ã‚‚é«˜ã„Moodå€¤ã‚’åŸºæº–ã«é¸æŠ
        mood_scores = {
            "fatigue": mood.fatigue,
            "anxiety": mood.anxiety,
            "curiosity": mood.curiosity,
            "loneliness": mood.loneliness,
            "decisiveness": mood.decisiveness,
        }
        max_mood = max(mood_scores.items(), key=lambda x: x[1])
        
        if max_mood[1] > 0.3:  # 0.3ä»¥ä¸Šã®å ´åˆã®ã¿Moodã«å¿œã˜ãŸææ¡ˆ
            hints = NEXT_STEPS_BY_MOOD.get(max_mood[0], NEXT_STEPS_BY_MOOD["default"])
        else:
            hints = NEXT_STEPS_BY_MOOD["default"]
    else:
        hints = NEXT_STEPS_BY_MOOD["default"]
    
    hint = random.choice(hints)
    
    # é¸ã°ã‚ŒãŸæ ¼è¨€ã‚’ä¿³å¥é¢¨ã«è¡¨ç¾ï¼ˆç¥è¨—ã‚‰ã—ãã€å­£ç¯€ã¨æ ¼è¨€ã‚’çµ„ã¿åˆã‚ã›ã‚‹ï¼‰
    if len(picks) > 0:
        # ç¥è¨—ã‚‰ã—ã„è¡¨ç¾ï¼šå­£ç¯€ã¨æ ¼è¨€ã‚’çµ„ã¿åˆã‚ã›ã‚‹
        # æ ¼è¨€ãŒé•·ã™ãã‚‹å ´åˆã¯çŸ­ç¸®ã—ã¦ã€ç¥è¨—ã‚‰ã—ãã™ã‚‹
        maxim_text = picks[0]
        if len(maxim_text) > 30:
            # é•·ã„æ ¼è¨€ã¯æœ€åˆã®éƒ¨åˆ†ã‚’å–ã‚‹ã‹ã€è¦ç´„
            maxim_text = maxim_text[:30] + "..."
        poem = f"{season}ï¼{maxim_text}"
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ç¥è¨—
        poem = f"{season}ï¼ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«"
    
    return {
        "energy": e,
        "picks": picks,
        "poem": poem,
        "hint": hint,
        "god": selected_god,  # é¸ã°ã‚ŒãŸç¥ã®æƒ…å ±ã‚’è¿½åŠ 
        "llm_oracle": llm_oracle  # LLMç”Ÿæˆã®ç¥è¨—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    }

# -------------------------
# LLMçµ±åˆï¼ˆç„¡å„Ÿã§ä½¿ç”¨å¯èƒ½ï¼‰
# -------------------------
def generate_oracle_with_llm(
    user_text: str,
    selected_god: Dict,
    selected_maxims: List[str],
    mood: Mood,
    llm_type: str = "huggingface"  # "ollama" or "huggingface"
) -> str:
    """LLMã‚’ä½¿ç”¨ã—ã¦ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸç¥è¨—ã‚’ç”Ÿæˆ
    
    Args:
        user_text: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        selected_god: é¸ã°ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼
        selected_maxims: é¸ã°ã‚ŒãŸæ ¼è¨€ãƒªã‚¹ãƒˆ
        mood: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…çŠ¶æ…‹
        llm_type: LLMã®ç¨®é¡ï¼ˆ"ollama" or "huggingface"ï¼‰
    
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸç¥è¨—ãƒ†ã‚­ã‚¹ãƒˆ
    """
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
    god_name = selected_god.get("name", "ç¥")
    god_description = selected_god.get("description", "")
    maxims_text = "\n".join([f"- {m}" for m in selected_maxims[:3]])
    
    prompt = f"""ã‚ãªãŸã¯{god_name}ã§ã™ã€‚{god_description}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ‚©ã¿ã‚„æ°—æŒã¡ï¼š
ã€Œ{user_text}ã€

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…çŠ¶æ…‹ï¼š
- ç–²ã‚Œ: {mood.fatigue:.2f}
- ä¸å®‰/ç„¦ã‚Š: {mood.anxiety:.2f}
- å¥½å¥‡å¿ƒ: {mood.curiosity:.2f}
- å­¤ç‹¬: {mood.loneliness:.2f}
- æ±ºæ–­åŠ›: {mood.decisiveness:.2f}

é–¢é€£ã™ã‚‹æ ¼è¨€ï¼š
{maxims_text}

ä¸Šè¨˜ã®æƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯„ã‚Šæ·»ã†æ¸©ã‹ã¿ã®ã‚ã‚‹ç¥è¨—ï¼ˆ50-100æ–‡å­—ç¨‹åº¦ï¼‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
æ—¥æœ¬ã®ä¼çµ±çš„ãªã€ŒãŠã¿ãã˜ã€ã®ã‚¹ã‚¿ã‚¤ãƒ«ã§ã€å¸Œæœ›ã¨åŠ±ã¾ã—ã‚’å«ã‚€å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚
"""
    
    if llm_type == "ollama":
        return generate_with_ollama(prompt)
    elif llm_type == "huggingface":
        return generate_with_huggingface(prompt)
    else:
        # LLMãŒä½¿ç”¨ã§ããªã„å ´åˆã€æ ¼è¨€ãƒ™ãƒ¼ã‚¹ã®ç¥è¨—ã‚’è¿”ã™
        return f"{maxims_text}\n\nã‚ãªãŸã®è¦³æ¸¬ãŒã€ã“ã®ä¸–ç•Œç·šã‚’ç¢ºå®šã•ã›ã¾ã—ãŸã€‚"

def generate_with_ollama(prompt: str, model: str = "llama3.2") -> str:
    """Ollamaã‚’ä½¿ç”¨ã—ã¦LLMã§ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œï¼‰
    
    Args:
        prompt: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: llama3.2ï¼‰
    
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    try:
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "max_tokens": 200
                }
            },
            timeout=30
        )
        if response.status_code == 200:
            result = response.json()
            return result.get("response", "").strip()
        else:
            return ""
    except Exception as e:
        # OllamaãŒèµ·å‹•ã—ã¦ã„ãªã„å ´åˆãªã©
        return ""

def extract_keywords_with_llm(text: str, llm_type: str = "huggingface") -> List[str]:
    """LLMã‚’ä½¿ç”¨ã—ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨æ„å›³ã‚’æŠ½å‡ºï¼ˆä¸­æœŸçš„æ”¹å–„ï¼‰
    
    Args:
        text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        llm_type: LLMã®ç¨®é¡ï¼ˆ"ollama" or "huggingface"ï¼‰
    
    Returns:
        æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
    """
    prompt = f"""ä»¥ä¸‹ã®æ—¥æœ¬èªã®æ–‡ç« ã‹ã‚‰ã€é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

æ–‡ç« ï¼šã€Œ{text}ã€

ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
- é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆåè©ã‚„é‡è¦ãªæ¦‚å¿µï¼‰ã‚’3-5å€‹ã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ï¼ˆé¡˜ã„ã€æ‚©ã¿ã€å¸Œæœ›ãªã©ï¼‰ã‚’1ã¤

ä¾‹ï¼š
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: å¤«å©¦, ç”Ÿæ´», å††æº€, å®¶æ—
æ„å›³: å®¶æ—ã®å¹¸ã›ã‚’é¡˜ã†

å›ç­”ï¼š"""
    
    try:
        if llm_type == "ollama":
            response = generate_with_ollama(prompt, model="llama3.2")
        elif llm_type == "huggingface":
            response = generate_with_huggingface(prompt, model="microsoft/DialoGPT-medium")
        else:
            return []
        
        if not response:
            return []
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        keywords = []
        lines = response.strip().split('\n')
        for line in lines:
            if 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰' in line or 'keyword' in line.lower():
                # ã€Œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: å¤«å©¦, ç”Ÿæ´», å††æº€ã€ã®ã‚ˆã†ãªå½¢å¼ã‹ã‚‰æŠ½å‡º
                parts = line.split(':')
                if len(parts) >= 2:
                    kw_text = parts[1].strip()
                    # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§åˆ†å‰²
                    kw_list = [kw.strip() for kw in kw_text.split(',')]
                    keywords.extend(kw_list)
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‹ã‚‰æŠ½å‡ºã‚’è©¦ã¿ã‚‹
        if not keywords:
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æ—¥æœ¬èªã®å˜èªã‚’æŠ½å‡ºï¼ˆ2æ–‡å­—ä»¥ä¸Šï¼‰
            import re
            japanese_words = re.findall(r'[ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠä¸€-é¾ ]{2,}', response)
            keywords = [w for w in japanese_words if len(w) <= 8][:5]
        
        return keywords
    except Exception as e:
        # LLMãŒä½¿ç”¨ã§ããªã„å ´åˆã€ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
        return []

def generate_with_huggingface(prompt: str, model: str = "microsoft/DialoGPT-medium") -> str:
    """Hugging Face Inference APIã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆï¼ˆç„¡æ–™æ ï¼‰
    
    Args:
        prompt: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Mistral-7B-Instructï¼‰
    
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    try:
        # Hugging Face Inference APIï¼ˆç„¡æ–™æ ï¼‰
        # æ³¨æ„: å®Ÿéš›ã®ä½¿ç”¨æ™‚ã¯ã€Hugging Faceã®APIã‚­ãƒ¼ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™
        # ç„¡æ–™æ ã§ã¯ã€å…¬é–‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã§ãã¾ã™
        
        # Hugging Face Inference APIã‚’ä½¿ç”¨ï¼ˆç„¡æ–™æ ï¼‰
        # APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ä½¿ç”¨ã€ãªã‘ã‚Œã°å…¬é–‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨
        api_key = os.getenv("HUGGINGFACE_API_KEY", "")
        
        headers = {}
        if api_key:
            headers["Authorization"] = f"Bearer {api_key}"
        
        # ç„¡æ–™ã§ä½¿ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ï¼‰
        # æ³¨æ„: ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ã¯APIã‚­ãƒ¼ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™
        api_url = f"https://api-inference.huggingface.co/models/{model}"
        
        payload = {
            "inputs": prompt,
            "parameters": {
                "max_new_tokens": 150,
                "temperature": 0.7,
                "top_p": 0.9,
                "return_full_text": False
            }
        }
        
        response = requests.post(api_url, headers=headers, json=payload, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã«å¿œã˜ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
            if isinstance(result, list) and len(result) > 0:
                if "generated_text" in result[0]:
                    return result[0]["generated_text"].strip()
                elif "text" in result[0]:
                    return result[0]["text"].strip()
            elif isinstance(result, dict):
                if "generated_text" in result:
                    return result["generated_text"].strip()
                elif "text" in result:
                    return result["text"].strip()
        
        # APIã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ç©ºæ–‡å­—ã‚’è¿”ã™ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        return ""
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€ç©ºæ–‡å­—ã‚’è¿”ã™ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        return ""

def select_maxims_from_database(
    keywords: List[str], 
    top_k: int = 3,
    exclude_maxims: Optional[List[str]] = None
) -> List[Dict]:
    """æ ¼è¨€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦æ ¼è¨€ã‚’é¸æŠ
    
    Args:
        keywords: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        top_k: é¸æŠã™ã‚‹æ ¼è¨€ã®æ•°
        exclude_maxims: é™¤å¤–ã™ã‚‹æ ¼è¨€ã®ãƒªã‚¹ãƒˆï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
    
    Returns:
        é¸æŠã•ã‚ŒãŸæ ¼è¨€ã®ãƒªã‚¹ãƒˆ
    """
    global MAXIMS_DATABASE
    if not MAXIMS_DATABASE:
        return []
    
    exclude_set = set(exclude_maxims or [])
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    scored_maxims = []
    keyword_set = set([kw.lower() for kw in keywords])
    
    for maxim in MAXIMS_DATABASE:
        maxim_text = maxim.get("text", "")
        # é™¤å¤–ãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if maxim_text in exclude_set:
            continue
            
        score = 0.0
        maxim_text_lower = maxim_text.lower()
        maxim_tags = [tag.lower() for tag in maxim.get("tags", [])]
        
        # ã‚¿ã‚°ä¸€è‡´ã‚’å„ªå…ˆï¼ˆå®Œå…¨ä¸€è‡´ï¼‰
        for tag in maxim_tags:
            if tag in keyword_set:
                score += 5.0  # ã‚¿ã‚°ä¸€è‡´ã¯é«˜ã‚¹ã‚³ã‚¢
            # ã‚¿ã‚°éƒ¨åˆ†ä¸€è‡´ã‚‚è€ƒæ…®
            elif any(kw in tag for kw in keyword_set):
                score += 3.0
        
        # ãƒ†ã‚­ã‚¹ãƒˆå†…ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼šéƒ¨åˆ†ä¸€è‡´ã‚‚è€ƒæ…®ï¼‰
        matched_count = 0
        for kw in keyword_set:
            # å®Œå…¨ä¸€è‡´ï¼ˆæœ€å„ªå…ˆï¼‰
            if kw in maxim_text_lower:
                score += 10.0  # ãƒ†ã‚­ã‚¹ãƒˆå†…ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å®Œå…¨ä¸€è‡´ã¯æœ€é«˜ã‚¹ã‚³ã‚¢
                matched_count += 1
            # éƒ¨åˆ†ä¸€è‡´ï¼ˆæ—¥æœ¬èªã®å ´åˆã€å˜èªã®å¢ƒç•ŒãŒæ˜ç¢ºã§ãªã„ãŸã‚ï¼‰
            elif len(kw) >= 2 and kw[:2] in maxim_text_lower:
                score += 5.0  # éƒ¨åˆ†ä¸€è‡´ã‚‚é«˜ã‚¹ã‚³ã‚¢
                matched_count += 1
            # æ–‡å­—ãƒ¬ãƒ™ãƒ«ã§ã®ä¸€è‡´
            elif any(c in maxim_text_lower for c in kw if len(c) >= 1):
                score += 2.0  # æ–‡å­—ãƒ¬ãƒ™ãƒ«ã§ã®ä¸€è‡´ã‚‚è€ƒæ…®
                matched_count += 1
        
        # è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´ã®ãƒœãƒ¼ãƒŠã‚¹ï¼ˆé‡è¦ï¼‰
        if matched_count >= 2:
            score += matched_count * 5.0  # è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´ã¯å¤§å¹…ãªãƒœãƒ¼ãƒŠã‚¹
        elif matched_count == 1:
            score += 3.0  # å˜ä¸€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´ã§ã‚‚ãƒœãƒ¼ãƒŠã‚¹
        
        if score > 0:
            scored_maxims.append((score, maxim))
    
    # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
    scored_maxims.sort(key=lambda x: x[0], reverse=True)
    
    # ä¸Šä½kå€‹ã‚’é¸æŠï¼ˆãƒ©ãƒ³ãƒ€ãƒ è¦ç´ ã‚’è¿½åŠ ã—ã¦å¤šæ§˜æ€§ã‚’ç¢ºä¿ï¼‰
    if scored_maxims:
        # ä¸Šä½10å€‹ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
        top_candidates = scored_maxims[:min(10, len(scored_maxims))]
        random.shuffle(top_candidates)
        selected = []
        for _, maxim in top_candidates:
            if len(selected) >= top_k:
                break
            if maxim.get("text") not in exclude_set:
                selected.append(maxim)
        return selected
    
    return []

def generate_maxim_from_keywords(keywords: List[str], context_text: str) -> Optional[str]:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦æ ¼è¨€ã‚’ç”Ÿæˆ
    
    Args:
        keywords: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        context_text: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
    
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸæ ¼è¨€ï¼ˆæ–‡å­—åˆ—ï¼‰ã€ç”Ÿæˆã§ããªã„å ´åˆã¯None
    """
    if not keywords or not context_text:
        return None
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰æ„å‘³ã‚’æ¨æ¸¬ã—ã¦æ ¼è¨€ã‚’ç”Ÿæˆ
    # ä¾‹ï¼šã€Œç–²ã‚Œã€ã€Œæ±ºæ–­ã€â†’ã€Œç–²ã‚Œã¦ã„ã¦ã‚‚ã€æ±ºæ–­ã™ã‚‹å‹‡æ°—ã‚’æŒã¦ã€‚ä¸€æ­©ãšã¤é€²ã‚ã°é“ã¯é–‹ã‘ã‚‹ã€‚ã€
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ„å‘³ã«åŸºã¥ããƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    maxim_templates = {
        "å¥åº·": ["å¥åº·ã¯æœ€å¤§ã®è²¡ç”£ã€‚æ—¥ã€…ã®ç©ã¿é‡ã­ãŒã€æœªæ¥ã®è‡ªåˆ†ã‚’å‰µã‚‹ã€‚", "å¥åº·ãªä½“ã«ã€å¥åº·ãªå¿ƒãŒå®¿ã‚‹ã€‚è‡ªåˆ†ã‚’å¤§åˆ‡ã«ã€ä»Šæ—¥ã‚‚ä¸€æ­©ãšã¤ã€‚", "å¥åº·ã¯è´ˆã‚Šç‰©ã€‚æ„Ÿè¬ã—ã¦ã€å¤§åˆ‡ã«å®ˆã£ã¦ã„ã“ã†ã€‚"],
        "ç–²": ["ç–²ã‚Œã¦ã„ã¦ã‚‚ã€ä¸€æ­©ãšã¤é€²ã‚ã°é“ã¯é–‹ã‘ã‚‹ã€‚", "ç–²ã‚Œã¯ä¼‘æ¯ã®åˆå›³ã€‚ç„¡ç†ã‚’ã›ãšã€ä»Šã‚’å¤§åˆ‡ã«ã€‚", "ç–²ã‚ŒãŸæ™‚ã“ãã€è‡ªåˆ†ã‚’åŠ´ã‚ã‚‹æ™‚ã€‚ä¼‘æ¯ã‚‚æˆé•·ã®ä¸€éƒ¨ã€‚"],
        "æ±ºæ–­": ["æ±ºæ–­ã¯å‹‡æ°—ã€‚è¿·ã†æ™‚é–“ã‚‚ã€é¸æŠã®ä¸€éƒ¨ã€‚", "æ±ºæ–­ã§ããªã„æ™‚ã¯ã€æ™‚é–“ã‚’ã‹ã‘ã¦è€ƒãˆã¦ã‚‚ã‚ˆã„ã€‚", "æ±ºæ–­ã¯ä¸€ç¬ã€ãã®çµæœã¯ä¸€ç”Ÿã€‚æ…é‡ã«ã€ã—ã‹ã—æã‚Œãšã«ã€‚"],
        "ä¸å®‰": ["ä¸å®‰ã¯æœªæ¥ã¸ã®æº–å‚™ã€‚ä»Šã§ãã‚‹ã“ã¨ã‚’å¤§åˆ‡ã«ã€‚", "ä¸å®‰ã¯æˆé•·ã®è¨¼ã€‚ä¸€æ­©ãšã¤é€²ã‚ã°ã€é“ã¯è¦‹ãˆã¦ãã‚‹ã€‚", "ä¸å®‰ãŒã‚ã£ã¦ã‚‚ã€å‰ã«é€²ã‚€å‹‡æ°—ã‚’æŒã¦ã€‚"],
        "è¿·": ["è¿·ã†ã“ã¨ã¯ã€çœŸå‰£ã«è€ƒãˆã¦ã„ã‚‹è¨¼ã€‚æ™‚é–“ã‚’ã‹ã‘ã¦ç­”ãˆã‚’è¦‹ã¤ã‘ã‚ˆã†ã€‚", "è¿·ã„ã¯é¸æŠã®ä½™åœ°ãŒã‚ã‚‹è¨¼ã€‚ç„¦ã‚‰ãšã€è‡ªåˆ†ã‚’ä¿¡ã˜ã¦ã€‚", "è¿·ã†æ™‚ã¯ã€å¿ƒã«å•ã„ã‹ã‘ã¦ã¿ã‚ˆã†ã€‚ç­”ãˆã¯å¿…ãšè¦‹ã¤ã‹ã‚‹ã€‚"],
        "å­¤ç‹¬": ["å­¤ç‹¬ã¯è‡ªåˆ†ã¨å‘ãåˆã†æ™‚é–“ã€‚å¤§åˆ‡ãªæ°—ã¥ããŒç”Ÿã¾ã‚Œã‚‹ã€‚", "ä¸€äººã®æ™‚é–“ã‚‚ã€æˆé•·ã®ç³§ã€‚è‡ªåˆ†ã‚’å¤§åˆ‡ã«ã€‚", "å­¤ç‹¬ã¯ä¸€æ™‚çš„ãªã‚‚ã®ã€‚å¿…ãšã¤ãªãŒã‚Šã¯è¦‹ã¤ã‹ã‚‹ã€‚"],
        "æŒ‘æˆ¦": ["æŒ‘æˆ¦ã¯æˆé•·ã®ç¨®ã€‚å¤±æ•—ã‚’æã‚Œãšã€ä¸€æ­©ã‚’è¸ã¿å‡ºãã†ã€‚", "æŒ‘æˆ¦ã™ã‚‹å‹‡æ°—ãŒã€æ–°ã—ã„é“ã‚’é–‹ãã€‚", "æŒ‘æˆ¦ã¯è‡ªåˆ†ã‚’å¤‰ãˆã‚‹åŠ›ã€‚æã‚Œãšã«é€²ã‚‚ã†ã€‚"],
        "ä»•äº‹": ["ä»•äº‹ã¯äººç”Ÿã®ä¸€éƒ¨ã€‚ãƒãƒ©ãƒ³ã‚¹ã‚’ä¿ã¡ãªãŒã‚‰ã€ä¸€æ­©ãšã¤é€²ã‚‚ã†ã€‚", "ä»•äº‹ã‚’é€šã˜ã¦ã€è‡ªåˆ†ã‚’æˆé•·ã•ã›ã‚ˆã†ã€‚", "ä»•äº‹ã¯è²¢çŒ®ã®å½¢ã€‚èª å®Ÿã«ã€ä¸å¯§ã«å–ã‚Šçµ„ã‚‚ã†ã€‚"],
        "å®¶æ—": ["å®¶æ—ã¯çµ†ã€‚å¤§åˆ‡ãªäººã‚’æ€ã„ã‚„ã‚Šã€å…±ã«æ­©ã‚‚ã†ã€‚", "å®¶æ—ã®å¹¸ã›ã¯ã€è‡ªåˆ†ã®å¹¸ã›ã€‚å…±ã«ç¬‘ã„ã€å…±ã«æ”¯ãˆåˆãŠã†ã€‚", "å®¶æ—ã¯å®ç‰©ã€‚æ„Ÿè¬ã®æ°—æŒã¡ã‚’å¿˜ã‚Œãšã«ã€‚"],
        "å¹¸ã›": ["å¹¸ã›ã¯ä»Šã“ã®ç¬é–“ã«ã‚ã‚‹ã€‚å°ã•ãªå–œã³ã‚’å¤§åˆ‡ã«ã€‚", "å¹¸ã›ã¯è‡ªåˆ†ã§å‰µã‚‹ã‚‚ã®ã€‚æ„Ÿè¬ã®å¿ƒã‚’æŒã£ã¦ã€ä¸€æ­©ãšã¤ã€‚", "å¹¸ã›ã¯åˆ†ã‹ã¡åˆã†ã‚‚ã®ã€‚å‘¨ã‚Šã®äººã¨å…±ã«å–œã³ã‚’ã€‚"],
    }
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’é¸æŠ
    selected_template = None
    for kw in keywords:
        kw_lower = kw.lower()
        for key, templates in maxim_templates.items():
            if key in kw_lower or kw_lower in key:
                import random
                selected_template = random.choice(templates)
                break
        if selected_template:
            break
    
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒãªã„å ´åˆã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ç›´æ¥ç”Ÿæˆ
    if not selected_template:
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’çµ„ã¿åˆã‚ã›ã¦æ ¼è¨€ã‚’ç”Ÿæˆ
        if len(keywords) >= 2:
            # ä¾‹ï¼šã€Œç–²ã‚Œã€ã€Œæ±ºæ–­ã€â†’ã€Œç–²ã‚Œã¦ã„ã¦ã‚‚ã€æ±ºæ–­ã™ã‚‹å‹‡æ°—ã‚’æŒã¦ã€‚ã€
            key_phrases = {
                "å¥åº·": "å¥åº·ã‚’å¤§åˆ‡ã«",
                "ç–²": "ç–²ã‚Œã¦ã„ã¦ã‚‚",
                "æ±ºæ–­": "æ±ºæ–­ã™ã‚‹å‹‡æ°—ã‚’æŒã¦",
                "ä¸å®‰": "ä¸å®‰ãŒã‚ã£ã¦ã‚‚",
                "è¿·": "è¿·ã†æ™‚ã¯",
                "å­¤ç‹¬": "ä¸€äººã§ã‚‚",
                "æŒ‘æˆ¦": "æŒ‘æˆ¦ã™ã‚‹å‹‡æ°—ãŒ",
                "ä»•äº‹": "ä»•äº‹ã«èª å®Ÿã«",
                "å®¶æ—": "å®¶æ—ã‚’å¤§åˆ‡ã«",
                "å¹¸ã›": "å¹¸ã›ã‚’é¡˜ã£ã¦",
            }
            
            phrases = []
            for kw in keywords[:3]:  # æœ€å¤§3ã¤ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
                kw_lower = kw.lower()
                for key, phrase in key_phrases.items():
                    if key in kw_lower or kw_lower in key:
                        phrases.append(phrase)
                        break
            
            if phrases:
                if len(phrases) >= 2:
                    selected_template = f"{phrases[0]}ã€{phrases[1]}ã€‚ä¸€æ­©ãšã¤é€²ã‚ã°é“ã¯é–‹ã‘ã‚‹ã€‚"
                else:
                    selected_template = f"{phrases[0]}ã€‚ä»Šã‚’å¤§åˆ‡ã«ã€ä¸€æ­©ãšã¤é€²ã‚‚ã†ã€‚"
    
    # ãã‚Œã§ã‚‚ç”Ÿæˆã§ããªã„å ´åˆã€æ±ç”¨çš„ãªæ ¼è¨€ã‚’ç”Ÿæˆ
    if not selected_template:
        if "å¥åº·" in context_text or "ä½“" in context_text or "èº«ä½“" in context_text:
            selected_template = "å¥åº·ã¯æœ€å¤§ã®è²¡ç”£ã€‚æ—¥ã€…ã®ç©ã¿é‡ã­ãŒã€æœªæ¥ã®è‡ªåˆ†ã‚’å‰µã‚‹ã€‚"
        elif "ç–²" in context_text or "ã ã‚‹" in context_text:
            selected_template = "ç–²ã‚Œã¦ã„ã¦ã‚‚ã€ä¸€æ­©ãšã¤é€²ã‚ã°é“ã¯é–‹ã‘ã‚‹ã€‚ä¼‘æ¯ã‚‚å¤§åˆ‡ãªé¸æŠã€‚"
        elif "æ±ºæ–­" in context_text or "æ±ºã‚" in context_text:
            selected_template = "æ±ºæ–­ã¯å‹‡æ°—ã€‚è¿·ã†æ™‚é–“ã‚‚ã€é¸æŠã®ä¸€éƒ¨ã€‚ç„¦ã‚‰ãšã€è‡ªåˆ†ã‚’ä¿¡ã˜ã¦ã€‚"
        elif "ä¸å®‰" in context_text or "å¿ƒé…" in context_text:
            selected_template = "ä¸å®‰ã¯æœªæ¥ã¸ã®æº–å‚™ã€‚ä»Šã§ãã‚‹ã“ã¨ã‚’å¤§åˆ‡ã«ã€ä¸€æ­©ãšã¤é€²ã‚‚ã†ã€‚"
        elif "ä»•äº‹" in context_text:
            selected_template = "ä»•äº‹ã¯äººç”Ÿã®ä¸€éƒ¨ã€‚ãƒãƒ©ãƒ³ã‚¹ã‚’ä¿ã¡ãªãŒã‚‰ã€ä¸€æ­©ãšã¤é€²ã‚‚ã†ã€‚"
        elif "å®¶æ—" in context_text:
            selected_template = "å®¶æ—ã¯çµ†ã€‚å¤§åˆ‡ãªäººã‚’æ€ã„ã‚„ã‚Šã€å…±ã«æ­©ã‚‚ã†ã€‚"
        elif "å¹¸ã›" in context_text or "å¹¸ç¦" in context_text:
            selected_template = "å¹¸ã›ã¯ä»Šã“ã®ç¬é–“ã«ã‚ã‚‹ã€‚å°ã•ãªå–œã³ã‚’å¤§åˆ‡ã«ã€‚"
        else:
            # æ±ç”¨çš„ãªæ ¼è¨€ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ï¼‰
            if keywords:
                selected_template = f"{keywords[0]}ã‚’å¤§åˆ‡ã«ã€‚ä¸€æ­©ãšã¤é€²ã‚ã°é“ã¯é–‹ã‘ã‚‹ã€‚"
            else:
                selected_template = "ä»Šã‚’å¤§åˆ‡ã«ã€‚ä¸€æ­©ãšã¤é€²ã‚ã°é“ã¯é–‹ã‘ã‚‹ã€‚"
    
    return selected_template

def create_original_maxim_from_vow(
    selected_vow_index: Optional[int],
    god: Dict,
    top_k: int = 3
) -> Optional[str]:
    """é¸ã°ã‚ŒãŸèª“é¡˜ï¼ˆVOWï¼‰ã®ãƒ™ã‚¯ãƒˆãƒ«ã«åŸºã¥ã„ã¦ã€æ ¼è¨€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰éƒ¨åˆ†çš„ã«çµ„ã¿åˆã‚ã›ã¦ã‚ªãƒªã‚¸ãƒŠãƒ«ãªæ ¼è¨€ã‚’ç”Ÿæˆ
    
    Args:
        selected_vow_index: é¸ã°ã‚ŒãŸèª“é¡˜ï¼ˆVOWï¼‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ0-11ã€Noneã®å ´åˆã¯ç”Ÿæˆã—ãªã„ï¼‰
        god: é¸ã°ã‚ŒãŸç¥ã®æƒ…å ±
        top_k: çµ„ã¿åˆã‚ã›ã«ä½¿ç”¨ã™ã‚‹æ ¼è¨€ã®æ•°
    
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸã‚ªãƒªã‚¸ãƒŠãƒ«ãªæ ¼è¨€ï¼ˆç”Ÿæˆã§ããªã„å ´åˆã¯Noneï¼‰
    """
    global MAXIMS_DATABASE
    if not MAXIMS_DATABASE or selected_vow_index is None:
        return None
    
    # é¸ã°ã‚ŒãŸèª“é¡˜ã«å¯¾å¿œã™ã‚‹VOWå€¤ã‚’å–å¾—
    vows = god.get("vows", {})
    vow_key = f"vow{selected_vow_index+1:02d}"
    selected_vow_value = vows.get(vow_key, 0.0) if vow_key in vows else 0.0
    
    # VOWå€¤ãŒéå¸¸ã«å°ã•ã„ï¼ˆé–¢é€£æ€§ãŒå¼±ã„ï¼‰å ´åˆã¯ã€ã‚ªãƒªã‚¸ãƒŠãƒ«æ ¼è¨€ã‚’ç”Ÿæˆã—ãªã„
    if abs(selected_vow_value) < 0.1:
        return None
    
    # ç¥ã®VOWå€¤ã‹ã‚‰é–¢é€£ã™ã‚‹èª“é¡˜ã‚’å–å¾—ï¼ˆVOWå€¤ã®çµ¶å¯¾å€¤ãŒå¤§ãã„é †ï¼‰
    vow_scores = []
    for i in range(12):
        v_key = f"vow{i+1:02d}"
        if v_key in vows:
            vow_scores.append((i, float(vows[v_key])))
    vow_scores.sort(key=lambda x: abs(x[1]), reverse=True)
    
    # æ ¼è¨€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã€é¸ã°ã‚ŒãŸèª“é¡˜ã¨é–¢é€£ã™ã‚‹èª“é¡˜ã«å¯¾å¿œã™ã‚‹æ ¼è¨€ã‚’é¸æŠ
    selected_maxims = []
    
    # é¸ã°ã‚ŒãŸèª“é¡˜ã«å¯¾å¿œã™ã‚‹æ ¼è¨€ã‚’å„ªå…ˆçš„ã«é¸æŠ
    # VOWå€¤ãŒè² ï¼ˆå¼·ã„é–¢é€£æ€§ï¼‰ã®å ´åˆã€ã‚ˆã‚Šå¤šãã®æ ¼è¨€ã‚’é¸æŠ
    num_maxims_to_select = max(2, min(top_k + 1, int(abs(selected_vow_value) * 5) + 2))
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã«æ ¼è¨€ã‚’é¸æŠï¼ˆå¤šæ§˜æ€§ã‚’ç¢ºä¿ï¼‰
    import time
    random.seed(int(time.time() * 1000) % 1000000)
    available_maxims = [m for m in MAXIMS_DATABASE if m.get("text")]
    random.shuffle(available_maxims)
    
    # é¸ã°ã‚ŒãŸèª“é¡˜ã«é–¢é€£ã™ã‚‹æ ¼è¨€ã‚’é¸æŠ
    for maxim in available_maxims:
        if len(selected_maxims) >= num_maxims_to_select:
            break
        maxim_text = maxim.get("text", "")
        if maxim_text and maxim_text not in [m.get("text", "") for m in selected_maxims]:
            selected_maxims.append(maxim)
    
    # æ ¼è¨€ãŒå°‘ãªã„å ´åˆã€ç¥ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ ¼è¨€ã‚’è¿½åŠ 
    if len(selected_maxims) < 2:
        god_maxim = god.get("maxim", "")
        if god_maxim and god_maxim not in [m.get("text", "") for m in selected_maxims]:
            selected_maxims.append({"text": god_maxim, "source": god.get("name", "ç¥è¨—"), "tags": []})
    
    # æ ¼è¨€ã‚’éƒ¨åˆ†çš„ã«çµ„ã¿åˆã‚ã›ã¦ã‚ªãƒªã‚¸ãƒŠãƒ«ãªæ ¼è¨€ã‚’ç”Ÿæˆ
    if len(selected_maxims) >= 2:
        # è¤‡æ•°ã®æ ¼è¨€ã‹ã‚‰é‡è¦ãªãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æŠ½å‡ºã—ã¦çµ„ã¿åˆã‚ã›
        phrases = []
        for maxim in selected_maxims[:min(3, len(selected_maxims))]:  # æœ€å¤§3ã¤ã®æ ¼è¨€ã‚’ä½¿ç”¨
            text = maxim.get("text", "")
            if text:
                # å¥ç‚¹ã‚„èª­ç‚¹ã§åˆ†å‰²
                parts = re.split(r'[ã€‚ã€ï¼Œ]', text)
                # ç©ºã§ãªã„éƒ¨åˆ†ã‚’è¿½åŠ ï¼ˆ3æ–‡å­—ä»¥ä¸Šï¼‰
                phrases.extend([p.strip() for p in parts if p.strip() and len(p.strip()) >= 3])
        
        if len(phrases) >= 2:
            # ãƒ©ãƒ³ãƒ€ãƒ ã«2-3ã¤ã®ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’é¸æŠã—ã¦çµ„ã¿åˆã‚ã›
            random.shuffle(phrases)
            selected_phrases = phrases[:min(3, len(phrases))]
            
            # ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’çµ„ã¿åˆã‚ã›ï¼ˆå¥ç‚¹ã§åŒºåˆ‡ã‚‹ï¼‰
            combined = "ã€‚".join(selected_phrases)
            if not combined.endswith("ã€‚"):
                combined += "ã€‚"
            
            # é•·ã™ãã‚‹å ´åˆã¯çŸ­ç¸®
            if len(combined) > 100:
                combined = combined[:100] + "..."
            
            return combined
    
    # çµ„ã¿åˆã‚ã›ãŒã§ããªã„å ´åˆã€Noneã‚’è¿”ã™ï¼ˆé€šå¸¸ã®æ ¼è¨€é¸æŠã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    return None

# -------------------------
# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰ï¼ˆCell 4ç”¨ï¼‰
# -------------------------
def extract_keywords(text: str, top_n: int = 5, use_llm: bool = False, llm_type: str = "huggingface") -> List[str]:
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆæ”¹å–„ç‰ˆï¼šæ—¥æœ¬èªå¯¾å¿œå¼·åŒ– + LLMã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    Args:
        text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        top_n: æŠ½å‡ºã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æœ€å¤§æ•°
        use_llm: LLMã‚’ä½¿ç”¨ã—ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã‚’è¡Œã†ã‹
        llm_type: LLMã®ç¨®é¡ï¼ˆ"ollama" or "huggingface"ï¼‰
    """
    if not text or not text.strip():
        return []
    
    # ã€ä¸­æœŸçš„æ”¹å–„ã€‘LLMã‚’ä½¿ç”¨ã—ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã‚’è¡Œã†å ´åˆ
    if use_llm:
        llm_keywords = extract_keywords_with_llm(text, llm_type=llm_type)
        if llm_keywords:
            return llm_keywords[:top_n]
    
    found_keywords = []
    text_original = text.strip()
    text_lower = text_original.lower()
    
    # ã€çŸ­æœŸçš„æ”¹å–„ã€‘æ–‡è„ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡ºï¼ˆé¡˜ã„ãƒ»ç¥ˆã‚Šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    context_patterns = {
        "wish": [
            r"ã§ã‚ã‚Šã¾ã™ã‚ˆã†ã«", r"ã‚ˆã†ã«", r"ã§ã‚ã‚Šã¾ã™", r"ã‚ã‚Šã¾ã™ã‚ˆã†ã«",
            r"ã§ãã¾ã™ã‚ˆã†ã«", r"ãªã‚Šã¾ã™ã‚ˆã†ã«", r"éã”ã›ã¾ã™ã‚ˆã†ã«",
            r"é¡˜ã„", r"ç¥ˆã‚Š", r"å¸Œæœ›", r"é¡˜ã†", r"ç¥ˆã‚‹", r"æœ›ã‚€"
        ],
        "family": [
            r"å®¶æ—", r"å¤«å©¦", r"è¦ª", r"å­", r"å®¶åº­", r"ç”Ÿæ´»", r"å††æº€"
        ],
        "health": [
            r"å¥åº·", r"ä½“èª¿", r"èº«ä½“", r"éã”ã—ãŸã„", r"éã”ã›ã¾ã™ã‚ˆã†ã«"
        ]
    }
    
    # æ–‡è„ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ã„ã¦ã‚«ãƒ†ã‚´ãƒªã‚’æ¤œå‡º
    detected_categories = []
    for category, patterns in context_patterns.items():
        for pattern in patterns:
            if re.search(pattern, text_original):
                detected_categories.append(category)
                # ã‚«ãƒ†ã‚´ãƒªã«å¯¾å¿œã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ 
                if category in KEYWORDS:
                    for kw in KEYWORDS[category]:
                        if kw not in found_keywords:
                            found_keywords.append(kw)
                break
    
    # 1. KEYWORDSè¾æ›¸ã‹ã‚‰é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆæœ€å„ªå…ˆï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®åˆ†æï¼‰
    # ä¾‹ï¼šã€Œç–²ã‚Œã¦ã„ã¦æ±ºæ–­ãŒå‡ºæ¥ãªã„ã€â†’ã€Œç–²ã€ã€Œæ±ºæ–­ã€ã‚’æŠ½å‡º
    for category, keywords in KEYWORDS.items():
        for kw in keywords:
            # éƒ¨åˆ†ä¸€è‡´ã§æ¤œç´¢ï¼ˆã€Œç–²ã‚Œã€ã«ã€Œç–²ã€ãŒå«ã¾ã‚Œã‚‹ï¼‰
            if kw in text_lower or text_lower in kw:
                if kw not in found_keywords:
                    found_keywords.append(kw)
            # ã‚ˆã‚ŠæŸ”è»Ÿãªãƒãƒƒãƒãƒ³ã‚°ï¼šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹
            elif any(c in text_lower for c in kw if len(c) >= 1):
                # ã€Œç–²ã‚Œã€ã«ã€Œç–²ã€ãŒå«ã¾ã‚Œã‚‹å ´åˆ
                if len(kw) >= 2 and kw[:2] in text_lower:
                    if kw not in found_keywords:
                        found_keywords.append(kw)
    
    # 2. GLOBAL_WORDS_DATABASEã‹ã‚‰ä¸€è‡´ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    for word in GLOBAL_WORDS_DATABASE:
        if word in text_original or word in text_lower:
            if word not in found_keywords:
                found_keywords.append(word)
    
    # 3. æ—¥æœ¬èªã®å½¢æ…‹ç´ è§£æçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼šæ–‡å­—åˆ—ã‹ã‚‰æ„å‘³ã®ã‚ã‚‹å˜èªã‚’æŠ½å‡º
    # ã€Œä¸–ç•Œå¹³å’Œã«è²¢çŒ®ã§ãã‚‹äººé–“ã«ãªã‚‹ã€â†’ã€Œä¸–ç•Œå¹³å’Œã€ã€Œè²¢çŒ®ã€ã€Œäººé–“ã€ã‚’æŠ½å‡º
    import re
    # ã¾ãšã€GLOBAL_WORDS_DATABASEã«å«ã¾ã‚Œã‚‹é•·ã„å˜èªã‹ã‚‰æŠ½å‡ºï¼ˆå„ªå…ˆï¼‰
    # é•·ã„å˜èªã‹ã‚‰é †ã«ãƒã‚§ãƒƒã‚¯ï¼ˆã€Œä¸–ç•Œå¹³å’Œã€ãŒã€Œä¸–ç•Œã€ã‚„ã€Œå¹³å’Œã€ã‚ˆã‚Šå„ªå…ˆã•ã‚Œã‚‹ï¼‰
    text_for_extraction = text_original  # æŠ½å‡ºç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã¯ä¿æŒï¼‰
    for word in sorted(GLOBAL_WORDS_DATABASE, key=len, reverse=True):
        if word in text_for_extraction and word not in found_keywords:
            found_keywords.append(word)
            # æŠ½å‡ºã—ãŸå˜èªã‚’ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å‰Šé™¤ï¼ˆé‡è¤‡æŠ½å‡ºã‚’é¿ã‘ã‚‹ï¼‰
            text_for_extraction = text_for_extraction.replace(word, " ", 1)
    
    # åŠ©è©ãƒ»åŠ©å‹•è©ã§æ–‡ç« ã‚’åˆ†å‰²ã—ã¦ã‹ã‚‰ã€å€‹åˆ¥ã®å˜èªã‚’æŠ½å‡º
    # ã€Œå¤«å©¦ç”Ÿæ´»ãŒå††æº€ã§ã‚ã‚Šã¾ã™ã‚ˆã†ã«ã€â†’ã€Œå¤«å©¦ç”Ÿæ´»ã€ã€Œå††æº€ã€ã‚’æŠ½å‡º
    import re
    
    # åŠ©è©ãƒ»åŠ©å‹•è©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆåˆ†å‰²ç”¨ï¼šã‚ˆã‚ŠåŒ…æ‹¬çš„ï¼‰
    # åŠ©è©ï¼šãŒã€ã‚’ã€ã«ã€ã§ã€ã¨ã€ã‹ã‚‰ã€ã¾ã§ã€ã‚ˆã‚Šã€ã®ã§ã€ã®ã«ã€ã§ã‚‚ã€ãªã©ã€ã¨ã‹ã€ã ã‘ã€ã°ã‹ã‚Šã€ãã‚‰ã„ã€ã»ã©ã€ã—ã‹
    # åŠ©å‹•è©ï¼šã§ã‚ã‚‹ã€ã§ã™ã€ã¾ã™ã€ã‚Œã‚‹ã€ã‚‰ã‚Œã‚‹ã€ã›ã‚‹ã€ã•ã›ã‚‹ã€ãªã„ã€ã¬ã€ã‚“ã€ã†ã€ã‚ˆã†ã€ã¾ã„
    # ãã®ä»–ï¼šã¦ã€ã§ã€ãŸã€ã ã€ã‚ã‚Šã¾ã™ã€ã‚ˆã†ã«ã€ã§ã‚ã‚Šã¾ã™
    particle_pattern = r'[ãŒã‚’ã«ã§ã¨ã‹ã‚‰ã¾ã§ã‚ˆã‚Šã®ã§ã®ã«ã§ã‚‚ãªã©ã¨ã‹ã ã‘ã°ã‹ã‚Šãã‚‰ã„ã»ã©ã—ã‹ã¦ã§ãŸã ã§ã‚ã‚‹ã§ã™ã¾ã™ã‚Œã‚‹ã‚‰ã‚Œã‚‹ã›ã‚‹ã•ã›ã‚‹ãªã„ã¬ã‚“ã†ã‚ˆã†ã¾ã„ã‚ã‚Šã¾ã™ã‚ˆã†ã«]|ã§ã‚ã‚Šã¾ã™|ã‚ã‚Šã¾ã™ã‚ˆã†ã«'
    
    # åŠ©è©ãƒ»åŠ©å‹•è©ã§åˆ†å‰²
    # ä¾‹ï¼šã€Œå¤«å©¦ç”Ÿæ´»ãŒå††æº€ã§ã‚ã‚Šã¾ã™ã‚ˆã†ã«ã€â†’ã€Œå¤«å©¦ç”Ÿæ´»ã€ã€Œå††æº€ã€ã«åˆ†å‰²
    split_text = re.split(particle_pattern, text_for_extraction)
    
    # åˆ†å‰²å¾Œã®å„å˜èªã‚’æŠ½å‡º
    japanese_words = []
    for segment in split_text:
        segment = segment.strip()
        if not segment:
            continue
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå…¨ä½“ã‚’å˜èªã¨ã—ã¦è¿½åŠ ï¼ˆè¤‡åˆèªã®å ´åˆï¼šä¾‹ã€Œå¤«å©¦ç”Ÿæ´»ã€ï¼‰
        # ãŸã ã—ã€é•·ã™ãã‚‹å ´åˆã¯é™¤å¤–
        if len(segment) >= 2 and len(segment) <= 8:
            # åŠ©è©ãƒ»åŠ©å‹•è©ã‚’å«ã¾ãªã„å ´åˆã®ã¿è¿½åŠ 
            if not re.search(particle_pattern, segment):
                if segment not in japanese_words:
                    japanese_words.append(segment)
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰å€‹åˆ¥ã®å˜èªã‚‚æŠ½å‡ºï¼ˆä¾‹ï¼šã€Œå¤«å©¦ç”Ÿæ´»ã€â†’ã€Œå¤«å©¦ã€ã€Œç”Ÿæ´»ã€ï¼‰
        # æ¼¢å­—ãƒ»ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠã®é€£ç¶šã‚’æŠ½å‡ºï¼ˆ2æ–‡å­—ä»¥ä¸Šã€æœ€å¤§6æ–‡å­—ã¾ã§ï¼‰
        words_in_segment = re.findall(r'[ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠä¸€-é¾ ]{2,6}', segment)
        for word in words_in_segment:
            if len(word) >= 2 and len(word) <= 8 and word not in japanese_words:
                # åŠ©è©ãƒ»åŠ©å‹•è©ã‚’å«ã¾ãªã„å ´åˆã®ã¿è¿½åŠ 
                if not re.search(particle_pattern, word):
                    japanese_words.append(word)
    
    # åŠ©è©ãƒ»åŠ©å‹•è©ã®ãƒªã‚¹ãƒˆï¼ˆé™¤å¤–ç”¨ï¼‰
    stop_words = [
        'ã“ã¨', 'ã‚‚ã®', 'ã¨ã', 'ãŸã‚', 'ã‹ã‚‰', 'ã¾ã§', 'ã‚ˆã‚Š', 'ã®ã§', 'ã®ã«', 
        'ã§ã‚‚', 'ãªã©', 'ã¨ã‹', 'ã ã‘', 'ã°ã‹ã‚Š', 'ãã‚‰ã„', 'ã»ã©', 'ã—ã‹',
        'ã¦ã„ã¦', 'ãŒ', 'ã‚’', 'ã«', 'ã§', 'ã¨', 'ã‹ã‚‰', 'ã¾ã§', 'ã‚ˆã‚Š', 'ã®ã§',
        'å‡ºæ¥ãªã„', 'ã§ããªã„', 'å‡ºæ¥ã‚‹', 'ã§ãã‚‹', 'ã§ã‚ã‚‹', 'ã§ã™', 'ã¾ã™',
        'ãªã‚‹', 'ã™ã‚‹', 'ã‚Œã‚‹', 'ã‚‰ã‚Œã‚‹', 'ã•ã›ã‚‹', 'ã•ã›ã‚‰ã‚Œã‚‹', 'ã¦', 'ã§', 'ãŸ', 'ã ',
        'ã‚Œã‚‹', 'ã‚‰ã‚Œã‚‹', 'ã›ã‚‹', 'ã•ã›ã‚‹', 'ãªã„', 'ã¬', 'ã‚“', 'ã†', 'ã‚ˆã†', 'ã¾ã„',
        'ã‚ã‚Šã¾ã™', 'ã‚ˆã†ã«', 'ã§ã‚ã‚Šã¾ã™', 'ã§ã‚ã‚Šã¾ã™ã‚ˆã†ã«'
    ]
    
    for word in japanese_words:
        # é•·ã™ãã‚‹å˜èªï¼ˆæ–‡ç« å…¨ä½“ï¼‰ã‚’é™¤å¤–ï¼ˆæœ€å¤§8æ–‡å­—ã¾ã§ï¼‰
        if len(word) > 8:
            continue
        
        if len(word) >= 2 and word not in found_keywords:
            # åŠ©è©ã‚„åŠ©å‹•è©ã‚’é™¤å¤–ï¼ˆå®Œå…¨ä¸€è‡´ã¨éƒ¨åˆ†ä¸€è‡´ã®ä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯ï¼‰
            is_stop_word = word in stop_words or any(sw in word for sw in stop_words if len(sw) >= 2)
            if not is_stop_word:
                # æ—¢å­˜ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä¸€éƒ¨ã§ãªã„ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆé•·ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å„ªå…ˆï¼‰
                is_substring = any(word in kw for kw in found_keywords if len(kw) > len(word))
                if not is_substring:
                    # çŸ­ã™ãã‚‹å˜èªï¼ˆ1-2æ–‡å­—ï¼‰ã¯é™¤å¤–ï¼ˆãŸã ã—ã€GLOBAL_WORDS_DATABASEã«å«ã¾ã‚Œã‚‹å ´åˆã¯OKï¼‰
                    if len(word) >= 2 or word in GLOBAL_WORDS_DATABASE:
                        found_keywords.append(word)
    
    # ã€é•·æœŸçš„æ”¹å–„ã€‘Janomeã‚’ä½¿ç”¨ã—ãŸå½¢æ…‹ç´ è§£æï¼ˆã‚ˆã‚Šæ­£ç¢ºãªåˆ†å‰²ï¼‰
    if JANOME_AVAILABLE:
        try:
            tokenizer = Tokenizer()
            tokens = tokenizer.tokenize(text_original)
            for token in tokens:
                # åè©ã€å‹•è©ã€å½¢å®¹è©ã®ã¿ã‚’æŠ½å‡º
                pos = token.part_of_speech.split(',')[0]
                if pos in ['åè©', 'å‹•è©', 'å½¢å®¹è©']:
                    surface = token.surface
                    # é•·ã™ãã‚‹å˜èªã‚’é™¤å¤–
                    if 2 <= len(surface) <= 8 and surface not in found_keywords:
                        # åŠ©è©ãƒ»åŠ©å‹•è©ã‚’é™¤å¤–
                        stop_words_list = [
                            'ã“ã¨', 'ã‚‚ã®', 'ã¨ã', 'ãŸã‚', 'ã‹ã‚‰', 'ã¾ã§', 'ã‚ˆã‚Š', 'ã®ã§', 'ã®ã«', 
                            'ã§ã‚‚', 'ãªã©', 'ã¨ã‹', 'ã ã‘', 'ã°ã‹ã‚Š', 'ãã‚‰ã„', 'ã»ã©', 'ã—ã‹',
                            'ãŒ', 'ã‚’', 'ã«', 'ã§', 'ã¨', 'ã¦', 'ãŸ', 'ã '
                        ]
                        if surface not in stop_words_list:
                            found_keywords.append(surface)
        except Exception:
            # JanomeãŒä½¿ç”¨ã§ããªã„å ´åˆã€å¾“æ¥ã®æ–¹æ³•ã‚’ä½¿ç”¨
            pass
    
    # 4. ãƒ†ã‚­ã‚¹ãƒˆã‚’å˜èªã«åˆ†å‰²ã—ã¦ã€2æ–‡å­—ä»¥ä¸Šã®å˜èªã‚’æŠ½å‡ºï¼ˆè‹±èªã‚„ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã®å ´åˆï¼‰
    text_clean = re.sub(r'[0-9ï¼-ï¼™\W]+', ' ', text_original)
    words = text_clean.split()
    for word in words:
        # é•·ã™ãã‚‹å˜èªï¼ˆæ–‡ç« å…¨ä½“ï¼‰ã‚’é™¤å¤–ï¼ˆæœ€å¤§8æ–‡å­—ã¾ã§ï¼‰
        if len(word) > 8:
            continue
        
        if len(word) >= 2 and word not in found_keywords:
            if word not in ['ã“ã¨', 'ã‚‚ã®', 'ã¨ã', 'ãŸã‚', 'ã‹ã‚‰', 'ã¾ã§', 'ã‚ˆã‚Š', 'ã®ã§', 'ã®ã«', 
                           'ã§ã‚‚', 'ã§ã‚‚', 'ãªã©', 'ã¨ã‹', 'ã ã‘', 'ã°ã‹ã‚Š', 'ãã‚‰ã„', 'ã»ã©', 'ã—ã‹']:
                found_keywords.append(word)
    
    # 5. é‡è¤‡ã‚’é™¤å»ã—ã€ä¸Šä½Nå€‹ã‚’è¿”ã™ï¼ˆå„ªå…ˆé †ä½ï¼šGLOBAL_WORDS_DATABASE > KEYWORDSè¾æ›¸ > ãã®ä»–ï¼‰
    unique_keywords = list(dict.fromkeys(found_keywords))  # é †åºã‚’ä¿æŒã—ãªãŒã‚‰é‡è¤‡é™¤å»
    
    # æ–‡ç« å…¨ä½“ï¼ˆé•·ã™ãã‚‹å˜èªï¼‰ã‚’é™¤å¤–ï¼ˆæœ€å¤§8æ–‡å­—ã¾ã§ï¼‰
    filtered_keywords = [kw for kw in unique_keywords if len(kw) <= 8]
    
    # å„ªå…ˆé †ä½ã§ã‚½ãƒ¼ãƒˆï¼š
    # 1. GLOBAL_WORDS_DATABASEã«å«ã¾ã‚Œã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé•·ã„é †ï¼‰
    # 2. KEYWORDSè¾æ›¸ã‹ã‚‰ã®æŠ½å‡º
    # 3. ãã®ä»–ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé•·ã„é †ï¼‰
    keywords_from_global = [kw for kw in filtered_keywords if kw in GLOBAL_WORDS_DATABASE]
    keywords_from_global.sort(key=lambda x: (GLOBAL_WORDS_DATABASE.index(x) if x in GLOBAL_WORDS_DATABASE else 999, -len(x)))
    
    keywords_from_dict = [kw for kw in filtered_keywords if kw not in keywords_from_global and any(kw in kws or any(k in kw for k in kws) for kws in KEYWORDS.values() for k in kws)]
    
    other_keywords = [kw for kw in filtered_keywords if kw not in keywords_from_global and kw not in keywords_from_dict]
    other_keywords.sort(key=lambda x: -len(x))  # é•·ã„é †
    
    sorted_keywords = keywords_from_global + keywords_from_dict + other_keywords
    
    return sorted_keywords[:top_n]

def calculate_energy_between_words(
    word1: str, 
    word2: str,
    selected_character: Optional[str] = None,
    selected_attribute: Optional[str] = None,
    char_master: Optional[pd.DataFrame] = None
) -> float:
    energy = 0.0
    common_chars = set(word1) & set(word2)
    if common_chars:
        energy -= len(common_chars) * 0.3
    
    categories = {
        "é¡˜ã„": ["ä¸–ç•Œå¹³å’Œ", "è²¢çŒ®", "æˆé•·", "å¤¢", "å¸Œæœ›"],
        "æ„Ÿæƒ…": ["æ„Ÿè¬", "æ„›", "å¹¸ã›", "å–œã³", "å®‰å¿ƒ"],
        "è¡Œå‹•": ["åŠªåŠ›", "ç¶™ç¶š", "å¿è€", "èª å®Ÿ", "æ­£ç›´"],
        "å“²å­¦": ["èª¿å’Œ", "ãƒãƒ©ãƒ³ã‚¹", "è‡ªç„¶", "ç¾", "é“"],
        "é–¢ä¿‚": ["çµ†", "ã¤ãªãŒã‚Š", "å®¶æ—", "å‹äºº", "ä¿¡é ¼"],
        "å†…çš„": ["é™ã‘ã•", "é›†ä¸­", "è¦šæ‚Ÿ", "æ±ºæ„", "å‹‡æ°—"],
    }
    
    for category, words in categories.items():
        if word1 in words and word2 in words:
            energy -= 0.5
    
    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é¸æŠã‚’åæ˜ 
    if selected_character and char_master is not None:
        try:
            # é¸æŠã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®è¡Œã‚’å–å¾—
            char_row = None
            if "å…¬å¼ã‚­ãƒ£ãƒ©å" in char_master.columns:
                char_row = char_master[char_master["å…¬å¼ã‚­ãƒ£ãƒ©å"] == selected_character]
            elif "CHAR_ID" in char_master.columns:
                char_row = char_master[char_master["CHAR_ID"] == selected_character]
            
            if char_row is not None and not char_row.empty:
                # VOWå€¤ãŒé«˜ã„å˜èªã‚’å„ªå…ˆï¼ˆå˜èªã¨VOWã®å¯¾å¿œã¯ç°¡æ˜“çš„ã«å®Ÿè£…ï¼‰
                # å˜èªãŒã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ç‰¹å¾´ã¨é–¢é€£ã™ã‚‹å ´åˆã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸‹ã’ã‚‹ï¼ˆè¿‘ã¥ã‘ã‚‹ï¼‰
                vow_values = []
                for i in range(1, 13):
                    vow_col = f"VOW_{i:02d}"
                    if vow_col in char_row.columns:
                        vow_val = char_row[vow_col].iloc[0]
                        if pd.notna(vow_val):
                            vow_values.append(float(vow_val))
                
                if vow_values:
                    avg_vow = np.mean(vow_values)
                    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ç‰¹å¾´ãŒå¼·ã„å ´åˆã€å˜èªé–“ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸‹ã’ã‚‹ï¼ˆè¿‘ã¥ã‘ã‚‹ï¼‰
                    energy -= avg_vow * 0.2
                
                # å±æ€§é¸æŠã‚’åæ˜ 
                if selected_attribute and "å±æ€§" in char_row.columns:
                    char_attribute = char_row["å±æ€§"].iloc[0]
                    if pd.notna(char_attribute) and str(char_attribute) == selected_attribute:
                        # å±æ€§ãŒä¸€è‡´ã™ã‚‹å ´åˆã€ã•ã‚‰ã«ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä¸‹ã’ã‚‹
                        energy -= 0.3
        except Exception:
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ç„¡è¦–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®è¨ˆç®—ã‚’ç¶šè¡Œï¼‰
            pass
    
    # æ¯å›ç•°ãªã‚‹çµæœã‚’å¾—ã‚‹ãŸã‚ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ™ãƒ¼ã‚¹ã®ãƒ©ãƒ³ãƒ€ãƒ è¦ç´ ã‚’è¿½åŠ 
    energy += np.random.normal(0, 0.15)
    return energy

def build_word_network(
    center_words: List[str], 
    database: List[str], 
    n_neighbors: int = 15,
    selected_character: Optional[str] = None,
    selected_attribute: Optional[str] = None,
    char_master: Optional[pd.DataFrame] = None
) -> Dict:
    """å˜èªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ï¼ˆæ¯å›ç•°ãªã‚‹çµæœã‚’å¾—ã‚‹ãŸã‚ã€ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’è¿½åŠ ï¼‰
    
    Args:
        center_words: ä¸­å¿ƒã¨ãªã‚‹å˜èªã®ãƒªã‚¹ãƒˆ
        database: å˜èªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
        n_neighbors: é¸æŠã™ã‚‹è¿‘å‚å˜èªã®æ•°
        selected_character: é¸æŠã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ï¼ˆå…¬å¼ã‚­ãƒ£ãƒ©åï¼‰
        selected_attribute: é¸æŠã•ã‚ŒãŸå±æ€§
        char_master: CHAR_MASTERã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿
    """
    # æ¯å›ç•°ãªã‚‹çµæœã‚’å¾—ã‚‹ãŸã‚ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ™ãƒ¼ã‚¹ã®ã‚·ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
    import time
    random_seed = int(time.time() * 1000) % 1000000
    np.random.seed(random_seed)
    random.seed(random_seed)
    
    all_words = list(set(center_words + database))
    word_energies = {}
    for word in all_words:
        if word in center_words:
            energy = -2.0
        else:
            # ãƒ©ãƒ³ãƒ€ãƒ è¦ç´ ã‚’è¿½åŠ ã—ã¦æ¯å›ç•°ãªã‚‹çµæœã‚’å¾—ã‚‹
            energies = [
                calculate_energy_between_words(
                    cw, word, 
                    selected_character=selected_character,
                    selected_attribute=selected_attribute,
                    char_master=char_master
                ) 
                for cw in center_words
            ]
            energy = np.mean(energies) + np.random.normal(0, 0.1)  # ãƒ©ãƒ³ãƒ€ãƒ è¦ç´ ã‚’è¿½åŠ 
        word_energies[word] = energy
    
    sorted_words = sorted(word_energies.items(), key=lambda x: (x[1], np.random.random()))  # åŒç‚¹ã®å ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ 
    selected_words = center_words.copy()
    for word, energy in sorted_words:
        if word not in center_words and len(selected_words) < n_neighbors:
            selected_words.append(word)
    
    network = {
        'words': selected_words,
        'energies': {word: word_energies.get(word, 0) for word in selected_words},
        'edges': []
    }
    
    for i, word1 in enumerate(selected_words):
        for j, word2 in enumerate(selected_words[i+1:], start=i+1):
            energy = calculate_energy_between_words(
                word1, word2,
                selected_character=selected_character,
                selected_attribute=selected_attribute,
                char_master=char_master
            )
            # é–¾å€¤ã‚’å°‘ã—ç·©å’Œã—ã¦ã€ã‚ˆã‚Šå¤šãã®ã‚¨ãƒƒã‚¸ã‚’è¡¨ç¤º
            if energy < -0.25:
                network['edges'].append((i, j, energy))
    
    return network

def place_words_on_sphere(n_words: int, center_indices: List[int]) -> np.ndarray:
    positions = np.zeros((n_words, 3))
    golden_angle = np.pi * (3 - np.sqrt(5))
    
    for i in range(n_words):
        if i in center_indices:
            r = 0.3 + np.random.rand() * 0.2
        else:
            r = 0.8 + np.random.rand() * 0.4
        
        theta = golden_angle * i
        y = 1 - (i / float(n_words - 1)) * 2
        radius_at_y = np.sqrt(1 - y * y)
        
        x = np.cos(theta) * radius_at_y * r
        z = np.sin(theta) * radius_at_y * r
        
        positions[i] = [x, y, z]
    
    return positions

def select_relevant_quote(
    keywords: List[str],
    exclude_quotes: Optional[set] = None
) -> str:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦é–¢é€£ã™ã‚‹æ ¼è¨€ã‚’é¸æŠï¼ˆæ¯å›ç•°ãªã‚‹çµæœã‚’å¾—ã‚‹ãŸã‚ã€ãƒ©ãƒ³ãƒ€ãƒ è¦ç´ ã‚’è¿½åŠ ï¼‰
    
    Args:
        keywords: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        exclude_quotes: é™¤å¤–ã™ã‚‹æ ¼è¨€ã®ã‚»ãƒƒãƒˆï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
    """
    # æ¯å›ç•°ãªã‚‹çµæœã‚’å¾—ã‚‹ãŸã‚ã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ™ãƒ¼ã‚¹ã®ã‚·ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
    import time
    random.seed(int(time.time() * 1000) % 1000000)
    
    exclude_set = exclude_quotes or set()
    keyword_set = set(keywords)
    scored_quotes = []
    
    for quote_data in FAMOUS_QUOTES:
        quote_text = quote_data["quote"]
        # é™¤å¤–ãƒªã‚¹ãƒˆã«å«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if quote_text in exclude_set:
            continue
            
        quote_keywords = set(quote_data["keywords"])
        score = len(keyword_set & quote_keywords)
        # ã‚¹ã‚³ã‚¢ã«å°ã•ãªãƒ©ãƒ³ãƒ€ãƒ è¦ç´ ã‚’è¿½åŠ ã—ã¦ã€æ¯å›ç•°ãªã‚‹çµæœã‚’å¾—ã‚‹
        score += random.uniform(-0.3, 0.3)
        scored_quotes.append((score, quote_text))
    
    # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
    scored_quotes.sort(key=lambda x: x[0], reverse=True)
    
    # ä¸Šä½10å€‹ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠï¼ˆå¤šæ§˜æ€§ã‚’ç¢ºä¿ï¼‰
    if scored_quotes:
        top_quotes = [q for _, q in scored_quotes[:min(10, len(scored_quotes))]]
        if top_quotes:
            return random.choice(top_quotes)
    
    return "ã‚ãªãŸã®è¦³æ¸¬ãŒã€ã“ã®ä¸–ç•Œç·šã‚’ç¢ºå®šã•ã›ã¾ã—ãŸã€‚"

# -------------------------
# ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¡¨ç¤º
# -------------------------
def get_character_image_path(god: Dict, gods_list: Optional[List[Dict]] = None) -> Optional[str]:
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç”»åƒã®ãƒ‘ã‚¹ã‚’å–å¾—"""
    # IMAGE_FILEã‹ã‚‰å–å¾—ï¼ˆå®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½¿ç”¨ï¼‰
    image_file = god.get("image_file")
    if image_file:
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆCHAR_p1.pngãªã©ï¼‰
        if image_file.endswith(".png"):
            image_path = f"assets/images/characters/{image_file}"
            if os.path.exists(image_path):
                return image_path
        # CHAR_p1.pngå½¢å¼ã®å ´åˆ
        if image_file.startswith("CHAR_p"):
            image_path = f"assets/images/characters/{image_file}"
            if os.path.exists(image_path):
                return image_path
    
    # CHAR_IDã‹ã‚‰å–å¾—
    char_id = god.get("char_id")
    if char_id and char_id.startswith("CHAR_"):
        try:
            char_num = int(char_id.replace("CHAR_", ""))
            # CHAR_01 â†’ CHAR_p1.png
            image_path = f"assets/images/characters/CHAR_p{char_num}.png"
            if os.path.exists(image_path):
                return image_path
        except:
            pass
    
    # IDã‹ã‚‰å–å¾—ï¼ˆCHAR_p1.pngå½¢å¼ã‚’è©¦ã™ï¼‰
    god_id = god.get("id", 0)
    image_path = f"assets/images/characters/CHAR_p{god_id+1}.png"
    if os.path.exists(image_path):
        return image_path
    
    # character_01.pngå½¢å¼ã‚‚è©¦ã™ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
    image_path = f"assets/images/characters/character_{god_id+1:02d}.png"
    if os.path.exists(image_path):
        return image_path
    
    return None

def render_god_character(god: Dict, gods_list: Optional[List[Dict]] = None) -> str:
    """é¸ã°ã‚ŒãŸç¥ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’HTMLã§è¡¨ç¤º"""
    god_name = god["name"]
    god_emoji = god["emoji"]
    god_description = god["description"]
    
    # ç”»åƒãƒ‘ã‚¹ã‚’å–å¾—
    image_path = get_character_image_path(god, gods_list)
    image_html = ""
    if image_path and os.path.exists(image_path):
        try:
            import base64
            with open(image_path, "rb") as img_file:
                img_data = base64.b64encode(img_file.read()).decode()
                image_html = f'<img src="data:image/png;base64,{img_data}" style="max-width: 300px; max-height: 300px; border-radius: 10px; margin-bottom: 20px;" />'
        except Exception:
            pass
    
    # f-stringã‚’ä½¿ã‚ãšã€é€šå¸¸ã®æ–‡å­—åˆ—ã§HTMLã‚’ç”Ÿæˆï¼ˆCSSã®{}ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã™ã‚‹å¿…è¦ãŒãªã„ï¼‰
    character_html = """
    <div id="god-character-container" style="
        position: relative;
        width: 100%;
        height: 400px;
        background: linear-gradient(180deg, #0a0a1a 0%, #1a1a2e 50%, #0a0a1a 100%);
        border-radius: 15px;
        overflow: hidden;
        margin: 20px 0;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        box-shadow: 0 0 30px rgba(255, 215, 0, 0.3);
    ">
        <style>
            @keyframes fadeIn {
                from { opacity: 0; transform: translateY(30px) scale(0.9); }
                to { opacity: 1; transform: translateY(0) scale(1); }
            }
            
            @keyframes float {
                0%, 100% { transform: translateY(0px) rotate(0deg); }
                25% { transform: translateY(-15px) rotate(-2deg); }
                50% { transform: translateY(-25px) rotate(0deg); }
                75% { transform: translateY(-15px) rotate(2deg); }
            }
            
            @keyframes glow {
                0%, 100% { 
                    text-shadow: 0 0 10px rgba(255, 215, 0, 0.5), 
                                0 0 20px rgba(255, 215, 0, 0.3),
                                0 0 30px rgba(255, 215, 0, 0.1); 
                }
                50% { 
                    text-shadow: 0 0 20px rgba(255, 215, 0, 0.8), 
                                0 0 30px rgba(255, 215, 0, 0.5),
                                0 0 40px rgba(255, 215, 0, 0.3); 
                }
            }
            
            @keyframes sparkle {
                0%, 100% { opacity: 0; transform: scale(0) rotate(0deg); }
                50% { opacity: 1; transform: scale(1.2) rotate(180deg); }
            }
            
            .god-emoji {
                animation: fadeIn 2s ease-out, float 4s ease-in-out infinite;
                font-size: 120px;
                text-align: center;
                filter: drop-shadow(0 0 20px rgba(255, 255, 255, 0.4));
                display: inline-block;
            }
            
            .god-name {
                animation: fadeIn 2s ease-out 0.5s both, glow 3s ease-in-out infinite;
                font-size: 32px;
                color: #ffd700;
                text-align: center;
                margin-top: 20px;
                font-weight: bold;
                font-family: 'Yu Gothic', 'Meiryo', 'MS Gothic', sans-serif;
                letter-spacing: 2px;
            }
            
            .god-description {
                animation: fadeIn 2s ease-out 1s both;
                color: #ffffff;
                margin-top: 15px;
                font-size: 18px;
                font-family: 'Yu Gothic', 'Meiryo', 'MS Gothic', sans-serif;
                text-align: center;
                padding: 0 20px;
            }
            
            .sparkle {
                position: absolute;
                color: #ffd700;
                font-size: 24px;
                animation: sparkle 2s ease-in-out infinite;
                pointer-events: none;
            }
        </style>
        
        <div style="position: relative; text-align: center; z-index: 1;">
            """ + (image_html if image_html else f'<div class="god-emoji">{god_emoji}</div>') + """
            <div class="god-name">""" + god_name + """</div>
            <div class="god-description">""" + god_description + """</div>
        </div>
        
        <div class="sparkle" style="top: 15%; left: 15%; animation-delay: 0s;">âœ¨</div>
        <div class="sparkle" style="top: 25%; right: 20%; animation-delay: 0.7s;">âœ¨</div>
        <div class="sparkle" style="bottom: 30%; left: 25%; animation-delay: 1.4s;">âœ¨</div>
        <div class="sparkle" style="bottom: 40%; right: 15%; animation-delay: 2.1s;">âœ¨</div>
        <div class="sparkle" style="top: 50%; left: 10%; animation-delay: 0.3s;">âœ¨</div>
        <div class="sparkle" style="top: 60%; right: 10%; animation-delay: 1.0s;">âœ¨</div>
    </div>
    """
    return character_html

# -------------------------
# Plotly 3Då¯è¦–åŒ–
# -------------------------
def create_3d_network_plot(network: Dict, positions: np.ndarray, center_indices: List[int]) -> go.Figure:
    fig = go.Figure()
    
    # ã‚¨ãƒƒã‚¸ã‚’æç”»
    for i, j, energy in network['edges']:
        x_coords = [positions[i, 0], positions[j, 0]]
        y_coords = [positions[i, 1], positions[j, 1]]
        z_coords = [positions[i, 2], positions[j, 2]]
        
        alpha = 0.2 + abs(energy) * 0.3
        linewidth = 0.5 + abs(energy) * 1.5
        color = '#4a9eff' if energy < -0.5 else '#ff6b6b'
        
        fig.add_trace(go.Scatter3d(
            x=x_coords, y=y_coords, z=z_coords,
            mode='lines',
            line=dict(color=color, width=linewidth),
            showlegend=False,
            hoverinfo='skip'
        ))
    
    # ãƒãƒ¼ãƒ‰ã‚’æç”»
    for i, word in enumerate(network['words']):
        x, y, z = positions[i]
        is_center = i in center_indices
        
        if is_center:
            size = 15
            color = '#ffd700'
        else:
            size = 8
            color = '#ffffff'
        
        fig.add_trace(go.Scatter3d(
            x=[x], y=[y], z=[z],
            mode='markers+text',
            marker=dict(
                size=size, 
                color=color, 
                line=dict(width=2, color='white'),
                opacity=0.6 if not is_center else 0.9
            ),
            text=[word],
            textposition="middle center",
            textfont=dict(
                size=20 if is_center else 16, 
                color='#ffd700' if is_center else '#ffffff',  # ä¸­å¿ƒèªã¯é‡‘è‰²ã€ãã®ä»–ã¯ç™½è‰²
                family='Arial, sans-serif',
                weight='bold'  # ã™ã¹ã¦å¤ªå­—ã§è¦‹ã‚„ã™ã
            ),
            name=word,
            hovertemplate=f'<b>{word}</b><br>ã‚¨ãƒãƒ«ã‚®ãƒ¼: {network["energies"].get(word, 0):.2f}<extra></extra>'
        ))
    
    fig.update_layout(
        title=dict(
            text='é‡å­ç¥è¨— - Quantum Oracle',
            font=dict(size=20, color='#ffffff', family='Arial, sans-serif'),
            x=0.5,
            xanchor='center'
        ),
        scene=dict(
            xaxis=dict(backgroundcolor='#0a0a1a', showgrid=False, showticklabels=False, title=''),
            yaxis=dict(backgroundcolor='#0a0a1a', showgrid=False, showticklabels=False, title=''),
            zaxis=dict(backgroundcolor='#0a0a1a', showgrid=False, showticklabels=False, title=''),
            bgcolor='#0a0a1a',
            camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))
        ),
        plot_bgcolor='#0a0a1a',
        paper_bgcolor='#0a0a1a',
        margin=dict(l=0, r=0, t=50, b=0),
        height=700
    )
    
    return fig

# -------------------------
# Streamlit UI
# -------------------------
def main():
    st.title("ğŸ”® Q-Quest é‡å­ç¥è¨—")
    st.markdown("### Human-Centric Quantum Philosophy")
    st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.title("æ©Ÿèƒ½é¸æŠ")
    
    # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“Š è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«")
    
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ–¹æ³•ã‚’é¸æŠ
    upload_mode = st.sidebar.radio(
        "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ–¹æ³•",
        ["5ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ¨å¥¨ï¼‰", "1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ3ã‚·ãƒ¼ãƒˆï¼‰", "4ã¤ã®åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«"],
        help="5ã¤ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã¾ã¨ã‚ã¦èª­ã¿è¾¼ã‚€ã‹ã€å€‹åˆ¥ã«èª­ã¿è¾¼ã‚€ã‹ã‚’é¸æŠ"
    )
    
    if upload_mode == "5ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ¨å¥¨ï¼‰":
        st.sidebar.markdown("**5ã¤ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰:**")
        
        character_file = st.sidebar.file_uploader(
            "1. 12ç¥åŸºæœ¬æƒ…å ± (akiba12_character_list.xlsx)",
            type=['xlsx', 'xls'],
            key="char_file_all",
            help="12ç¥ã®åŸºæœ¬æƒ…å ±ï¼ˆIDã€åå‰ã€å±æ€§ã€çµµæ–‡å­—ã€èª¬æ˜ã€æ ¼è¨€ï¼‰"
        )
        
        maxim_file = st.sidebar.file_uploader(
            "2. æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ« (æ ¼è¨€.xlsx)",
            type=['xlsx', 'xls'],
            key="maxim_file_all",
            help="æ ¼è¨€ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"
        )
        
        sense_to_vow_file = st.sidebar.file_uploader(
            "3. sense_to_vowè¡Œåˆ— (sense_to_vow_initial_filled_from_user.xlsx)",
            type=['xlsx', 'xls'],
            key="sense_to_vow_file_all",
            help="æ„Ÿè¦š Ã— èª“é¡˜ï¼ˆ8x12ã®è¡Œåˆ—ï¼‰"
        )
        
        k_matrix_file = st.sidebar.file_uploader(
            "4. kè¡Œåˆ— (akiba12_character_to_vow_K.xlsx)",
            type=['xlsx', 'xls'],
            key="k_matrix_file_all",
            help="ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ Ã— èª“é¡˜ï¼ˆ12x12ã®è¡Œåˆ—ï¼‰"
        )
        
        l_matrix_file = st.sidebar.file_uploader(
            "5. lè¡Œåˆ— (akiba12_character_to_axis_L.xlsx)",
            type=['xlsx', 'xls'],
            key="l_matrix_file_all",
            help="ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ Ã— ä¸–ç•Œè¦³è»¸ï¼ˆ12x4ã®è¡Œåˆ—ï¼‰"
        )
        
        if k_matrix_file is not None and l_matrix_file is not None:
            if load_all_excel_files(
                character_file=character_file,
                maxim_file=maxim_file,
                k_matrix_file=k_matrix_file,
                l_matrix_file=l_matrix_file,
                sense_to_vow_file=sense_to_vow_file
            ):
                st.sidebar.success("âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                if LOADED_GODS:
                    st.sidebar.info(f"èª­ã¿è¾¼ã¾ã‚ŒãŸç¥ã®æ•°: {len(LOADED_GODS)}")
                    with st.sidebar.expander("ğŸ“‹ èª­ã¿è¾¼ã‚“ã è¨­å®šã®è©³ç´°"):
                        st.write("**12ç¥ã®ãƒªã‚¹ãƒˆ:**")
                        for god in LOADED_GODS[:3]:
                            st.write(f"- {god['emoji']} {god['name']}")
                        if len(LOADED_GODS) > 3:
                            st.write(f"... ä»– {len(LOADED_GODS) - 3} ç¥")
                        
                        if SENSE_TO_VOW_MATRIX is not None:
                            st.write(f"**sense_to_vowè¡Œåˆ—ã‚µã‚¤ã‚º:** {SENSE_TO_VOW_MATRIX.shape}")
                        if K_MATRIX is not None:
                            st.write(f"**kè¡Œåˆ—ã‚µã‚¤ã‚º:** {K_MATRIX.shape}")
                        if L_MATRIX is not None:
                            st.write(f"**lè¡Œåˆ—ã‚µã‚¤ã‚º:** {L_MATRIX.shape}")
            else:
                st.sidebar.error("âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        elif k_matrix_file is not None or l_matrix_file is not None:
            st.sidebar.warning("âš ï¸ kè¡Œåˆ—ã¨lè¡Œåˆ—ã®ä¸¡æ–¹ãŒå¿…è¦ã§ã™")
        else:
            st.sidebar.info("ğŸ’¡ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ä¸­")
    
    elif upload_mode == "1ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ3ã‚·ãƒ¼ãƒˆï¼‰":
        uploaded_file = st.sidebar.file_uploader(
            "Excelè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['xlsx', 'xls'],
            help="12ç¥ã®è¨­å®šã€kè¡Œåˆ—ã€lè¡Œåˆ—ã‚’å«ã‚€Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ3ã¤ã®ã‚·ãƒ¼ãƒˆï¼‰"
        )
        
        # æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        maxim_file = st.sidebar.file_uploader(
            "æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ« (æ ¼è¨€.xlsx) - ã‚ªãƒ—ã‚·ãƒ§ãƒ³",
            type=['xlsx', 'xls'],
            key="maxim_file_single",
            help="æ ¼è¨€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆæ ¼è¨€ã€å‡ºå…¸ã€ã‚¿ã‚°ã‚’å«ã‚€Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼‰"
        )
        
        if uploaded_file is not None:
            if load_excel_config(excel_file=uploaded_file):
                st.sidebar.success("âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                
                # æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                if maxim_file is not None:
                    maxims = load_maxims_from_excel(maxim_file)
                    if maxims:
                        st.sidebar.success(f"âœ… æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{len(maxims)}ä»¶ï¼‰")
                if LOADED_GODS:
                    st.sidebar.info(f"èª­ã¿è¾¼ã¾ã‚ŒãŸç¥ã®æ•°: {len(LOADED_GODS)}")
                    # èª­ã¿è¾¼ã‚“ã è¨­å®šã®è©³ç´°ã‚’è¡¨ç¤ºï¼ˆå±•é–‹å¯èƒ½ï¼‰
                    with st.sidebar.expander("ğŸ“‹ èª­ã¿è¾¼ã‚“ã è¨­å®šã®è©³ç´°"):
                        st.write("**12ç¥ã®ãƒªã‚¹ãƒˆ:**")
                        for god in LOADED_GODS[:3]:  # æœ€åˆã®3ã¤ã ã‘è¡¨ç¤º
                            st.write(f"- {god['emoji']} {god['name']}")
                        if len(LOADED_GODS) > 3:
                            st.write(f"... ä»– {len(LOADED_GODS) - 3} ç¥")
                        
                        if K_MATRIX is not None:
                            st.write(f"**kè¡Œåˆ—ã‚µã‚¤ã‚º:** {K_MATRIX.shape}")
                        if L_MATRIX is not None:
                            st.write(f"**lè¡Œåˆ—ã‚µã‚¤ã‚º:** {L_MATRIX.shape}")
            else:
                st.sidebar.error("âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        else:
            st.sidebar.info("ğŸ’¡ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ä¸­")
    
    else:  # 4ã¤ã®åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«
        st.sidebar.markdown("**4ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰:**")
        
        character_file = st.sidebar.file_uploader(
            "1. 12ç¥åŸºæœ¬æƒ…å ± (akiba12_character_list.xlsx)",
            type=['xlsx', 'xls'],
            key="character_file",
            help="12ç¥ã®åŸºæœ¬æƒ…å ±ï¼ˆIDã€åå‰ã€å±æ€§ã€çµµæ–‡å­—ã€èª¬æ˜ã€æ ¼è¨€ï¼‰"
        )
        
        sense_to_vow_file = st.sidebar.file_uploader(
            "2. sense_to_vowè¡Œåˆ— (sense_to_vow_initial_filled_from_user.xlsx)",
            type=['xlsx', 'xls'],
            key="sense_to_vow_file",
            help="æ„Ÿè¦š Ã— èª“é¡˜ï¼ˆ8x12ã®è¡Œåˆ—ï¼šè¿·ã„/ç„¦ã‚Š/é™ã‘ã•/å†…çœ/è¡Œå‹•/ã¤ãªãŒã‚Š/æŒ‘æˆ¦/å¾…ã¤ â†’ 12èª“é¡˜ï¼‰"
        )
        
        k_matrix_file = st.sidebar.file_uploader(
            "3. kè¡Œåˆ— (akiba12_character_to_vow_K.xlsx)",
            type=['xlsx', 'xls'],
            key="k_matrix_file",
            help="ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ Ã— èª“é¡˜ï¼ˆ12x12ã®è¡Œåˆ—ï¼‰"
        )
        
        l_matrix_file = st.sidebar.file_uploader(
            "4. lè¡Œåˆ— (akiba12_character_to_axis_L.xlsx)",
            type=['xlsx', 'xls'],
            key="l_matrix_file",
            help="ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ Ã— ä¸–ç•Œè¦³è»¸ï¼ˆ12x4ã®è¡Œåˆ—ï¼šé™ã€æµã€é–“ã€èª ï¼‰"
        )
        
        # æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        maxim_file = st.sidebar.file_uploader(
            "5. æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ« (æ ¼è¨€.xlsx) - ã‚ªãƒ—ã‚·ãƒ§ãƒ³",
            type=['xlsx', 'xls'],
            key="maxim_file_separate",
            help="æ ¼è¨€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆæ ¼è¨€ã€å‡ºå…¸ã€ã‚¿ã‚°ã‚’å«ã‚€Excelãƒ•ã‚¡ã‚¤ãƒ«ï¼‰"
        )
        
        if k_matrix_file is not None and l_matrix_file is not None:
            if load_excel_config(
                character_file=character_file,
                sense_to_vow_file=sense_to_vow_file,
                k_matrix_file=k_matrix_file,
                l_matrix_file=l_matrix_file
            ):
                st.sidebar.success("âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                
                # æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                if maxim_file is not None:
                    maxims = load_maxims_from_excel(maxim_file)
                    if maxims:
                        st.sidebar.success(f"âœ… æ ¼è¨€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{len(maxims)}ä»¶ï¼‰")
                if LOADED_GODS:
                    st.sidebar.info(f"èª­ã¿è¾¼ã¾ã‚ŒãŸç¥ã®æ•°: {len(LOADED_GODS)}")
                    # èª­ã¿è¾¼ã‚“ã è¨­å®šã®è©³ç´°ã‚’è¡¨ç¤ºï¼ˆå±•é–‹å¯èƒ½ï¼‰
                    with st.sidebar.expander("ğŸ“‹ èª­ã¿è¾¼ã‚“ã è¨­å®šã®è©³ç´°"):
                        st.write("**12ç¥ã®ãƒªã‚¹ãƒˆ:**")
                        for god in LOADED_GODS[:3]:  # æœ€åˆã®3ã¤ã ã‘è¡¨ç¤º
                            st.write(f"- {god['emoji']} {god['name']}")
                        if len(LOADED_GODS) > 3:
                            st.write(f"... ä»– {len(LOADED_GODS) - 3} ç¥")
                        
                        if K_MATRIX is not None:
                            st.write(f"**kè¡Œåˆ—ã‚µã‚¤ã‚º:** {K_MATRIX.shape}")
                        if L_MATRIX is not None:
                            st.write(f"**lè¡Œåˆ—ã‚µã‚¤ã‚º:** {L_MATRIX.shape}")
            else:
                st.sidebar.error("âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        elif k_matrix_file is not None or l_matrix_file is not None:
            st.sidebar.warning("âš ï¸ kè¡Œåˆ—ã¨lè¡Œåˆ—ã®ä¸¡æ–¹ãŒå¿…è¦ã§ã™")
        else:
            st.sidebar.info("ğŸ’¡ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ä¸­")
    
    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨å±æ€§ã®é¸æŠï¼ˆé‡å­é‡ã­ã®åŠ¹æœã‚’å‡ºã™ãŸã‚ï¼‰
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ­ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é¸æŠï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰")
    
    global SELECTED_ATTRIBUTE, SELECTED_CHARACTER, CHAR_MASTER
    
    # å±æ€§ã®é¸æŠ
    if LOADED_GODS:
        # å±æ€§ã®ä¸€è¦§ã‚’å–å¾—
        attributes = set()
        for god in LOADED_GODS:
            attr = god.get("attribute", "")
            if attr:
                attributes.add(attr)
        
        if attributes:
            selected_attribute = st.sidebar.selectbox(
                "å±æ€§ã‚’é¸æŠï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
                ["é¸æŠã—ãªã„"] + sorted(list(attributes)),
                help="å±æ€§ã‚’é¸æŠã™ã‚‹ã¨ã€ãã®å±æ€§ã‚’æŒã¤ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸ã°ã‚Œã‚„ã™ããªã‚Šã¾ã™ï¼ˆé‡å­é‡ã­ã®åŠ¹æœï¼‰"
            )
            SELECTED_ATTRIBUTE = selected_attribute if selected_attribute != "é¸æŠã—ãªã„" else None
            
            # é¸æŠã•ã‚ŒãŸå±æ€§ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’è¡¨ç¤º
            if SELECTED_ATTRIBUTE:
                matching_gods = [god for god in LOADED_GODS if god.get("attribute") == SELECTED_ATTRIBUTE]
                if matching_gods:
                    st.sidebar.info(f"**{SELECTED_ATTRIBUTE}**å±æ€§ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: {len(matching_gods)}ä½“")
                    with st.sidebar.expander(f"ğŸ“‹ {SELECTED_ATTRIBUTE}å±æ€§ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸€è¦§"):
                        for god in matching_gods:
                            st.write(f"- {god.get('emoji', 'ğŸ”®')} {god.get('name', '')}")
        
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ç›´æ¥é¸æŠ
        character_names = [god.get("name", "") for god in LOADED_GODS if god.get("name")]
        if character_names:
            selected_character = st.sidebar.selectbox(
                "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’ç›´æ¥é¸æŠï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
                ["é¸æŠã—ãªã„"] + character_names,
                help="ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’ç›´æ¥é¸æŠã™ã‚‹ã¨ã€ãã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸ã°ã‚Œã‚„ã™ããªã‚Šã¾ã™ï¼ˆé‡å­é‡ã­ã®åŠ¹æœï¼‰"
            )
            SELECTED_CHARACTER = selected_character if selected_character != "é¸æŠã—ãªã„" else None
    
    st.sidebar.markdown("---")
    app_mode = st.sidebar.selectbox(
        "å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ",
        ["åŸºæœ¬ãƒ‡ãƒ¢", "å¯¾è©±å‹é‡å­ç¥è¨—", "è¨€è‘‰ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼çƒä½“è¦–è¦šåŒ–", "çµµé¦¬ç´ã‚"]
    )
    
    if app_mode == "åŸºæœ¬ãƒ‡ãƒ¢":
        st.header("QUBO Ã— ç¸ï¼šåŸºæœ¬ãƒ‡ãƒ¢")
        st.markdown("åŸºæœ¬çš„ãªQUBOãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸã€Œç¸ã€ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        
        # åŸºæœ¬ãƒ‡ãƒ¢ã§ã‚‚ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é¸æŠã‚’åæ˜ 
        st.info("ğŸ’¡ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚„å±æ€§ã‚’é¸æŠã™ã‚‹ã¨ã€QUBOã«åæ˜ ã•ã‚Œã¾ã™")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã‚‹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        user_input_basic = st.text_area(
            "ä»Šæ—¥ã®æ‚©ã¿ãƒ»æ°—æŒã¡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
            placeholder="ä¾‹ï¼šç–²ã‚Œã¦ã„ã¦æ±ºæ–­ãŒã§ããªã„â€¦",
            height=100,
            help="å…¥åŠ›ã—ãŸæ–‡é¢ã‚’åˆ†æã—ã¦ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒè¿‘ã„æ ¼è¨€ã‚’é¸æŠã—ã¾ã™"
        )
        
        if st.button("å®Ÿè¡Œ"):
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‹ã‚‰Moodã‚’æ¨å®šï¼ˆå…¥åŠ›ãŒã‚ã‚‹å ´åˆï¼‰
            if user_input_basic and user_input_basic.strip():
                user_mood = infer_mood(user_input_basic.strip())
                context_text_for_basic = user_input_basic.strip()
            else:
                # å…¥åŠ›ãŒãªã„å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®Moodã‚’ä½¿ç”¨
                user_mood = Mood(
                    fatigue=0.5,
                    anxiety=0.5,
                    curiosity=0.5,
                    loneliness=0.5,
                    decisiveness=0.5
                )
                context_text_for_basic = ""
            
            # é¸æŠã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼/å±æ€§ã‚’åæ˜ ã—ãŸQUBOã‚’ç”Ÿæˆ
            Q = build_qubo_from_mood(
                user_mood,
                selected_attribute=SELECTED_ATTRIBUTE,
                selected_character=SELECTED_CHARACTER,
                char_master=CHAR_MASTER
            )
            
            # éšå±¤æ§‹é€ ã‚’ä½¿ç”¨
            sols = solve_all(Q, use_hierarchical=True)
            
            # çµæœè¡¨ç¤º
            st.subheader("ä½ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¸Šä½ï¼ˆé¸ã°ã‚ŒãŸæ ¼è¨€ã®é‡ãªã‚Šï¼‰")
            if context_text_for_basic:
                st.caption(f"ğŸ“ å…¥åŠ›æ–‡é¢: ã€Œ{context_text_for_basic}ã€")
                # æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¡¨ç¤º
                keywords_basic = extract_keywords_safe(context_text_for_basic, top_n=8)
                if keywords_basic:
                    st.caption(f"ğŸ”‘ æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(keywords_basic)}")
                else:
                    st.warning("âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚ˆã‚Šè©³ã—ã„æ–‡é¢ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            
            displayed_maxims_basic = []  # æ—¢ã«è¡¨ç¤ºã—ãŸæ ¼è¨€ã‚’è¨˜éŒ²ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
            for rank, (e, x) in enumerate(sols[:8], start=1):
                # éšå±¤æ§‹é€ ã®å ´åˆã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨æ ¼è¨€ã‚’å–å¾—
                if len(x) >= 32:
                    selected_god = get_selected_god_from_x(x, user_mood, use_hierarchical=True)
                    selected_vow_idx = get_selected_vow_from_x(x, use_hierarchical=True)
                    
                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›æ–‡é¢ã‚’åˆ†æã—ã¦ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒè¿‘ã„æ ¼è¨€ã‚’é¸æŠ
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’äº‹å‰ã«æŠ½å‡ºã—ã¦ã€ã‚ˆã‚ŠåŠ¹æœçš„ãªé¸æŠã‚’è¡Œã†
                    context_for_selection = context_text_for_basic if context_text_for_basic else ""
                    picks = select_maxims_for_god(
                        selected_god, 
                        context_text=context_for_selection,  # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’ä½¿ç”¨
                        top_k=8,  # ã‚ˆã‚Šå¤šãã®å€™è£œã‹ã‚‰é¸æŠï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦çµã‚Šè¾¼ã‚€ï¼‰
                        include_famous_quote=False,
                        selected_vow_index=selected_vow_idx,
                        exclude_maxims=displayed_maxims_basic  # æ—¢ã«è¡¨ç¤ºã—ãŸæ ¼è¨€ã‚’é™¤å¤–
                    )
                    
                    # æ—¢ã«è¡¨ç¤ºã—ãŸæ ¼è¨€ã‚’é™¤å¤–ã—ã¦ã€æ–°ã—ã„æ ¼è¨€ã®ã¿ã‚’è¡¨ç¤º
                    new_picks = [p for p in picks if p not in displayed_maxims_basic]
                    if not new_picks and picks:
                        # æ–°ã—ã„æ ¼è¨€ãŒãªã„å ´åˆã€æœ€åˆã®æ ¼è¨€ã‚’ä½¿ç”¨ï¼ˆé‡è¤‡ã‚’è¨±å®¹ï¼‰
                        new_picks = picks[:1]
                    
                    # è¡¨ç¤ºã™ã‚‹æ ¼è¨€ã‚’è¨˜éŒ²
                    for pick in new_picks:
                        if pick not in displayed_maxims_basic:
                            displayed_maxims_basic.append(pick)
                    
                    if new_picks:
                        picks_str = " | ".join(new_picks[:2])
                    else:
                        picks_str = selected_god.get("maxim", "ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«")
                else:
                    picks = [VARIABLES[i] for i,v in enumerate(x) if v==1]
                    if picks:
                        picks_str = " | ".join(picks[:2])  # é•·ã„ã®ã§æœ€å¤§2ã¤ã¾ã§
                        if len(picks) > 2:
                            picks_str += f" ...ï¼ˆä»–{len(picks)-2}ã¤ï¼‰"
                    else:
                        picks_str = "ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«"
                
                st.write(f"{rank}. E={e:>6.3f}")
                st.caption(f"   æ ¼è¨€: {picks_str}")
            
            # ã‚¨ãƒãƒ«ã‚®ãƒ¼åœ°å½¢ã®å¯è¦–åŒ–ï¼ˆç°¡ç•¥ç‰ˆï¼‰
            if len(sols) > 0:
                energies = [e for e, _ in sols[:20]]  # ä¸Šä½20å€‹ã®ã¿è¡¨ç¤º
                labels = [f"è§£{i+1}" for i in range(len(energies))]
                
                fig_bar = px.bar(
                    x=labels,
                    y=energies,
                    labels={'x': 'è§£', 'y': 'ã‚¨ãƒãƒ«ã‚®ãƒ¼'},
                    title="Energy landscapeï¼ˆä½ã„ã»ã©ã€Œç¸ãŒçµã°ã‚Œã‚„ã™ã„å€™è£œã€ï¼‰"
                )
                fig_bar.update_xaxes(tickangle=-90)
                st.plotly_chart(fig_bar, use_container_width=True)
            
            # ãŠã¿ãã˜ï¼ˆåŸºæœ¬ãƒ‡ãƒ¢ã§ã‚‚éšå±¤æ§‹é€ ã‚’ä½¿ç”¨ï¼‰
            # ã‚ˆã‚Šå¤šãã®å€™è£œã‹ã‚‰é¸æŠï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãŒã‚ã‚‹å ´åˆã€ã‚ˆã‚Šå¤šæ§˜ãªçµæœã‚’å¾—ã‚‹ãŸã‚ï¼‰
            pool_size = 10 if context_text_for_basic else 6
            oracle_pool = sols[:pool_size]
            
            # æ¯å›ç•°ãªã‚‹çµæœã‚’å¾—ã‚‹ãŸã‚ã€ãƒ©ãƒ³ãƒ€ãƒ è¦ç´ ã‚’è¿½åŠ 
            import time
            random.seed(int(time.time() * 1000) % 1000000)
            # ãƒ—ãƒ¼ãƒ«ã‚’å°‘ã—ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¦å¤šæ§˜æ€§ã‚’ç¢ºä¿
            if len(oracle_pool) > 1:
                shuffled_pool = list(oracle_pool)
                random.shuffle(shuffled_pool[:min(5, len(shuffled_pool))])
                oracle_pool = shuffled_pool
            
            T = temperature_from_mood(user_mood, SELECTED_CHARACTER)
            e_pick, x_pick = boltzmann_sample(oracle_pool, T=T)
            card = oracle_card(e_pick, x_pick, mood=user_mood, use_hierarchical=True, context_text=context_text_for_basic)
            
            st.markdown("---")
            st.subheader("é‡å­ãŠã¿ãã˜ï¼ˆQuantum Oracleï¼‰")
            
            # é¸ã°ã‚ŒãŸç¥ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’è¡¨ç¤º
            # ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ã§é¸æŠã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’å„ªå…ˆ
            display_god = None
            if SELECTED_CHARACTER and LOADED_GODS:
                # é¸æŠã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’LOADED_GODSã‹ã‚‰æ¤œç´¢
                for god in LOADED_GODS:
                    god_official_name = god.get("å…¬å¼ã‚­ãƒ£ãƒ©å", "")
                    god_name = god.get("name", "")
                    if SELECTED_CHARACTER == god_official_name or SELECTED_CHARACTER == god_name:
                        display_god = god
                        break
            
            # é¸æŠã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€QUBOã®çµæœã‹ã‚‰é¸ã°ã‚ŒãŸç¥ã‚’ä½¿ç”¨
            if display_god is None and 'god' in card and card['god']:
                display_god = card['god']
            
            # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’è¡¨ç¤º
            if display_god:
                character_html = render_god_character(display_god, LOADED_GODS)
                st.components.v1.html(character_html, height=400)
            
            st.write(f"**ã‚¨ãƒãƒ«ã‚®ãƒ¼**: {card['energy']:.3f}")
            
            # é¸ã°ã‚ŒãŸæ ¼è¨€ã¨å¼•ç”¨å…ƒã‚’è¡¨ç¤º
            picks_display = []
            if card.get('picks') and len(card['picks']) > 0:
                for pick in card['picks']:
                    source_info = get_maxim_source(pick)
                    picks_display.append(f"{pick} *ï¼ˆ{source_info['source']}ï¼‰*")
            else:
                # æ ¼è¨€ãŒç©ºã®å ´åˆã€é¸ã°ã‚ŒãŸç¥ã®æ ¼è¨€ã‚’ä½¿ç”¨
                selected_god_from_card = card.get('god')
                if selected_god_from_card:
                    if selected_god_from_card.get("maxim"):
                        maxim = selected_god_from_card["maxim"]
                        source_info = get_maxim_source(maxim)
                        picks_display.append(f"{maxim} *ï¼ˆ{source_info['source']}ï¼‰*")
                    elif selected_god_from_card.get("description"):
                        desc = selected_god_from_card["description"]
                        picks_display.append(f"{desc} *ï¼ˆ{selected_god_from_card.get('name', 'ç¥è¨—')}ï¼‰*")
            
            if not picks_display:
                picks_display.append("ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚ *ï¼ˆä¼çµ±çš„ãªæ•™ãˆï¼‰*")
            
            st.write(f"**é¸ã°ã‚ŒãŸç¸**:")
            for pick_text in picks_display:
                st.markdown(f"   - {pick_text}")
            
            st.write(f"**ã“ã¨ã°**: ã€Œ{card.get('poem', 'ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚')}ã€")
            st.write(f"**æ¬¡ã®ä¸€æ­©**: {card.get('hint', 'ä¸€æ­©ãšã¤é€²ã‚“ã§ã„ãã¾ã—ã‚‡ã†ã€‚')}")
    
    elif app_mode == "å¯¾è©±å‹é‡å­ç¥è¨—":
        st.header("å¯¾è©±å‹é‡å­ç¥è¨—")
        st.markdown("ã‚ãªãŸã®æ‚©ã¿ãƒ»æ°—æŒã¡ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸã€Œç¸ã€ã‚’æç¤ºã—ã¾ã™")
        
        # LLMä½¿ç”¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        col1, col2 = st.columns(2)
        with col1:
            use_llm = st.checkbox(
                "ğŸ¤– LLMã§ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸç¥è¨—ã‚’ç”Ÿæˆ",
                value=False,
                help="LLMã‚’ä½¿ç”¨ã—ã¦ã€ã‚ˆã‚Šãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸç¥è¨—ã‚’ç”Ÿæˆã—ã¾ã™ï¼ˆç„¡å„Ÿã§ä½¿ç”¨å¯èƒ½ï¼‰"
            )
        with col2:
            if use_llm:
                llm_type = st.selectbox(
                    "LLMã®ç¨®é¡",
                    ["huggingface", "ollama"],
                    help="Hugging Face: ç„¡æ–™APIï¼ˆæ¨å¥¨ï¼‰ / Ollama: ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œï¼ˆè¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰"
                )
            else:
                llm_type = "huggingface"
        
        user_text = st.text_area(
            "ä»Šæ—¥ã®æ‚©ã¿ãƒ»æ°—æŒã¡ã‚’ä¸€æ–‡ã§ã©ã†ã",
            placeholder="ä¾‹ï¼šç–²ã‚Œã¦ã„ã¦æ±ºæ–­ãŒã§ããªã„â€¦",
            height=100
        )
        
        if st.button("ç¥è¨—ã‚’æ±‚ã‚ã‚‹"):
            if not user_text.strip():
                st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            else:
                m = infer_mood(user_text)
                Q_today = build_qubo_from_mood(m)
                
                # Optunaã‚’ä½¿ã£ãŸæœ€é©åŒ–ï¼ˆé€²æ—è¡¨ç¤ºä»˜ãï¼‰
                optuna_container = st.empty()
                sols, study = solve_all_with_optuna(Q_today, use_hierarchical=True, 
                                                     progress_container=optuna_container, n_trials=50)
                
                # Optunaã®å¯è¦–åŒ–ï¼ˆå…¨ã¦ã®å¯è¦–åŒ–ã‚’è¡¨ç¤ºï¼‰
                if study is not None and OPTUNA_AVAILABLE:
                    with st.expander("ğŸ“Š QUBOæœ€é©åŒ–ã®è©³ç´°", expanded=False):
                        # ã‚¿ãƒ–ã§å¯è¦–åŒ–ã‚’æ•´ç†
                        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
                            "ğŸ“ˆ æœ€é©åŒ–å±¥æ­´", 
                            "ğŸ¯ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é‡è¦åº¦", 
                            "ğŸ”„ ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ãƒˆ",
                            "ğŸ—ºï¸ ç­‰é«˜ç·š",
                            "ğŸ“Š ã‚¹ãƒ©ã‚¤ã‚¹",
                            "â±ï¸ ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³"
                        ])
                        
                        with tab1:
                            try:
                                fig_history = plot_optimization_history(study)
                                st.plotly_chart(fig_history, use_container_width=True)
                                st.caption("æœ€é©åŒ–ã®é€²è¡ŒçŠ¶æ³ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                            except Exception as e:
                                st.write(f"æœ€é©åŒ–å±¥æ­´ã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                        
                        with tab2:
                            try:
                                fig_importance = plot_param_importances(study)
                                st.plotly_chart(fig_importance, use_container_width=True)
                                st.caption("å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é‡è¦åº¦ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                            except Exception as e:
                                st.write(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é‡è¦åº¦ã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                        
                        with tab3:
                            try:
                                if len(study.trials) > 0:
                                    fig_parallel = plot_parallel_coordinate(study)
                                    st.plotly_chart(fig_parallel, use_container_width=True)
                                    st.caption("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é–“ã®é–¢ä¿‚ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚")
                                else:
                                    st.info("ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ãƒˆã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€è¤‡æ•°ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ãŒå¿…è¦ã§ã™ã€‚")
                            except Exception as e:
                                st.write(f"ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ãƒˆã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                        
                        with tab4:
                            try:
                                if len(study.trials) > 0:
                                    # æœ€åˆã®2ã¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç­‰é«˜ç·šã‚’è¡¨ç¤º
                                    params = list(study.trials[0].params.keys()) if study.trials else []
                                    if len(params) >= 2:
                                        fig_contour = plot_contour(study, params=[params[0], params[1]])
                                        st.plotly_chart(fig_contour, use_container_width=True)
                                        st.caption(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€Œ{params[0]}ã€ã¨ã€Œ{params[1]}ã€ã®é–¢ä¿‚ã‚’ç­‰é«˜ç·šã§è¡¨ç¤ºã—ã¾ã™ã€‚")
                                    else:
                                        st.info("ç­‰é«˜ç·šã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€å°‘ãªãã¨ã‚‚2ã¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚")
                                else:
                                    st.info("ç­‰é«˜ç·šã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€è¤‡æ•°ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ãŒå¿…è¦ã§ã™ã€‚")
                            except Exception as e:
                                st.write(f"ç­‰é«˜ç·šã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                        
                        with tab5:
                            try:
                                if len(study.trials) > 0:
                                    fig_slice = plot_slice(study)
                                    st.plotly_chart(fig_slice, use_container_width=True)
                                    st.caption("å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚¹ãƒ©ã‚¤ã‚¹ãƒ—ãƒ­ãƒƒãƒˆã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                                else:
                                    st.info("ã‚¹ãƒ©ã‚¤ã‚¹ãƒ—ãƒ­ãƒƒãƒˆã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€è¤‡æ•°ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ãŒå¿…è¦ã§ã™ã€‚")
                            except Exception as e:
                                st.write(f"ã‚¹ãƒ©ã‚¤ã‚¹ãƒ—ãƒ­ãƒƒãƒˆã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                        
                        with tab6:
                            try:
                                if len(study.trials) > 0:
                                    fig_timeline = plot_timeline(study)
                                    st.plotly_chart(fig_timeline, use_container_width=True)
                                    st.caption("æœ€é©åŒ–ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                                else:
                                    st.info("ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€è¤‡æ•°ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ãŒå¿…è¦ã§ã™ã€‚")
                            except Exception as e:
                                st.write(f"ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                
                # å¿ƒã®å‚¾ãã‚’è¡¨ç¤º
                col1, col2, col3, col4, col5 = st.columns(5)
                with col1:
                    st.metric("ç–²ã‚Œ", f"{m.fatigue:.2f}")
                with col2:
                    st.metric("ä¸å®‰/ç„¦ã‚Š", f"{m.anxiety:.2f}")
                with col3:
                    st.metric("å¥½å¥‡å¿ƒ", f"{m.curiosity:.2f}")
                with col4:
                    st.metric("å­¤ç‹¬", f"{m.loneliness:.2f}")
                with col5:
                    st.metric("æ±ºæ–­", f"{m.decisiveness:.2f}")
                
                # å€™è£œTop3
                st.subheader("ä½ã‚¨ãƒãƒ«ã‚®ãƒ¼å€™è£œï¼ˆé¸ã°ã‚ŒãŸæ ¼è¨€ã®é‡ã­åˆã‚ã›ï¼‰Top3")
                displayed_maxims = []  # æ—¢ã«è¡¨ç¤ºã—ãŸæ ¼è¨€ã‚’è¨˜éŒ²ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
                for rank, (e, x) in enumerate(sols[:3], start=1):
                    god_for_candidate = get_selected_god_from_x(x, m, use_hierarchical=True)
                    selected_vow_idx = get_selected_vow_from_x(x, use_hierarchical=True)
                    
                    # æ—¢ã«è¡¨ç¤ºã—ãŸæ ¼è¨€ã‚’é™¤å¤–
                    picks = select_maxims_for_god(
                        god_for_candidate, 
                        context_text=user_text, 
                        top_k=3,  # ã‚ˆã‚Šå¤šãã®å€™è£œã‹ã‚‰é¸æŠ
                        include_famous_quote=False,
                        selected_vow_index=selected_vow_idx,
                        exclude_maxims=displayed_maxims  # æ—¢ã«è¡¨ç¤ºã—ãŸæ ¼è¨€ã‚’é™¤å¤–
                    )
                    
                    # æ—¢ã«è¡¨ç¤ºã—ãŸæ ¼è¨€ã‚’é™¤å¤–ã—ã¦ã€æ–°ã—ã„æ ¼è¨€ã®ã¿ã‚’è¡¨ç¤º
                    new_picks = [p for p in picks if p not in displayed_maxims]
                    if not new_picks and picks:
                        # æ–°ã—ã„æ ¼è¨€ãŒãªã„å ´åˆã€æœ€åˆã®æ ¼è¨€ã‚’ä½¿ç”¨ï¼ˆé‡è¤‡ã‚’è¨±å®¹ï¼‰
                        new_picks = picks[:1]
                    
                    # è¡¨ç¤ºã™ã‚‹æ ¼è¨€ã‚’è¨˜éŒ²
                    for pick in new_picks:
                        if pick not in displayed_maxims:
                            displayed_maxims.append(pick)
                    
                    st.write(f"**{rank}. E={e:.3f}**")
                    for pick in new_picks[:2]:  # æœ€å¤§2ã¤ã¾ã§è¡¨ç¤º
                        source_info = get_maxim_source(pick)
                        st.write(f"   â€¢ {pick}")
                        st.caption(f"     *å‡ºå…¸: {source_info['source']} - {source_info['origin']}*")
                
                # ãŠã¿ãã˜ï¼ˆMoodã«å¿œã˜ã¦å¤‰åŒ–ï¼‰
                pool = sols[:6]
                T = temperature_from_mood(m, SELECTED_CHARACTER)
                e_pick, x_pick = boltzmann_sample(pool, T=T)
                
                # ãƒ‡ãƒãƒƒã‚°: è§£ãƒ™ã‚¯ãƒˆãƒ«ã®å†…å®¹ã‚’ç¢ºèª
                if len(x_pick) >= 32:
                    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ•°ï¼ˆ20ã€œ31ï¼‰ãŒé¸ã°ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
                    c_start = 20
                    selected_char_indices = [i for i in range(c_start, min(c_start + 12, len(x_pick))) if i < len(x_pick) and x_pick[i] == 1]
                    if not selected_char_indices:
                        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸ã°ã‚Œã¦ã„ãªã„å ´åˆã€Moodã‹ã‚‰é¸æŠ
                        st.warning("âš ï¸ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ•°ãŒé¸ã°ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Moodã‹ã‚‰é¸æŠã—ã¾ã™ã€‚")
                
                card = oracle_card(e_pick, x_pick, mood=m, use_hierarchical=True, context_text=user_text, use_llm=use_llm, llm_type=llm_type)  # Moodã‚’æ¸¡ã™
                
                st.markdown("---")
                st.subheader("é‡å­ãŠã¿ãã˜ï¼ˆQuantum Oracleï¼‰")
                
                # é¸ã°ã‚ŒãŸç¥ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’è¡¨ç¤º
                if 'god' in card and card['god']:
                    selected_god = card['god']
                    character_html = render_god_character(selected_god, LOADED_GODS)
                    st.components.v1.html(character_html, height=400)
                
                # é¸ã°ã‚ŒãŸæ ¼è¨€ã®å¼•ç”¨å…ƒæƒ…å ±ã‚’åé›†
                sources_text = []
                if card.get('picks') and len(card['picks']) > 0:
                    for pick in card['picks']:
                        source_info = get_maxim_source(pick)
                        sources_text.append(f"- {pick}\n  *å‡ºå…¸: {source_info['source']} - {source_info['origin']}*")
                else:
                    # æ ¼è¨€ãŒç©ºã®å ´åˆã€é¸ã°ã‚ŒãŸç¥ã®æ ¼è¨€ã‚’ä½¿ç”¨
                    selected_god_from_card = card.get('god')
                    if selected_god_from_card and selected_god_from_card.get("maxim"):
                        maxim = selected_god_from_card["maxim"]
                        source_info = get_maxim_source(maxim)
                        sources_text.append(f"- {maxim}\n  *å‡ºå…¸: {source_info['source']} - {source_info['origin']}*")
                    elif selected_god_from_card and selected_god_from_card.get("description"):
                        desc = selected_god_from_card["description"]
                        sources_text.append(f"- {desc}\n  *å‡ºå…¸: {selected_god_from_card.get('name', 'ç¥è¨—')}*")
                    else:
                        sources_text.append("- ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚\n  *å‡ºå…¸: ä¼çµ±çš„ãªæ•™ãˆ*")
                
                            # LLMç”Ÿæˆã®ç¥è¨—ã‚’ã€Œé¸ã°ã‚ŒãŸç¸ã€ã«çµ±åˆ
                if card.get('llm_oracle') and use_llm and card['llm_oracle'].strip():
                    # LLMç”Ÿæˆã®ç¥è¨—ã‚’æœ€åˆã«è¿½åŠ 
                    llm_text = card['llm_oracle'].strip()
                    sources_text.insert(0, f"ğŸ¤– {llm_text}\n  *å‡ºå…¸: LLMç”Ÿæˆ - ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸç¥è¨—*")
                elif use_llm:
                    # LLMç”Ÿæˆã«å¤±æ•—ã—ãŸå ´åˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                    sources_text.insert(0, f"ğŸ’­ LLMç”Ÿæˆã¯ç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚æ ¼è¨€ãƒ™ãƒ¼ã‚¹ã®ç¥è¨—ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚\n  *å‡ºå…¸: ä¼çµ±çš„ãªæ•™ãˆ*")
                
                st.info(f"""
**ã‚¨ãƒãƒ«ã‚®ãƒ¼**: {card['energy']:.3f}

**é¸ã°ã‚ŒãŸç¸**:
{chr(10).join(sources_text) if sources_text else "- ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚"}

**ã“ã¨ã°**:
ã€Œ{card.get('poem', 'ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚')}ã€

**æ¬¡ã®ä¸€æ­©**:
{card.get('hint', 'ä¸€æ­©ãšã¤é€²ã‚“ã§ã„ãã¾ã—ã‚‡ã†ã€‚')}
""")
                st.caption(f"â€»æºã‚‰ã(T)={T:.2f}ï¼ˆå¤§ãã„ã»ã©å¶ç„¶æ€§ãŒå¢—ãˆã¾ã™ï¼‰")
                
                # === ã‚¨ãƒãƒ«ã‚®ãƒ¼çƒä½“è¦–è¦šåŒ–ã‚’çµ±åˆ ===
                st.markdown("---")
                st.subheader("è¨€è‘‰ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼çƒä½“è¦–è¦šåŒ–")
                st.markdown("å…¥åŠ›ã—ãŸè¨€è‘‰ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã€ãã‚Œã«é–¢é€£ã™ã‚‹è¨€è‘‰ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼é–¢ä¿‚ã‚’å¯è¦–åŒ–ã—ã¾ã™")
                
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆåŒã˜ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ï¼‰
                keywords = extract_keywords(user_text)
                if keywords:
                    st.write(f"**æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {', '.join(keywords)}")
                    
                    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰
                    network = build_word_network(keywords, GLOBAL_WORDS_DATABASE, n_neighbors=20)
                    
                    # 3Dé…ç½®
                    center_indices = [i for i, word in enumerate(network['words']) if word in keywords]
                    positions = place_words_on_sphere(len(network['words']), center_indices)
                    
                    # 3Då¯è¦–åŒ–
                    fig = create_3d_network_plot(network, positions, center_indices)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # é¸ã°ã‚ŒãŸæ ¼è¨€ã¨é–¢é€£ã™ã‚‹æ ¼è¨€ã‚’è¡¨ç¤º
                    st.markdown("---")
                    st.subheader("é–¢é€£ã™ã‚‹æ ¼è¨€")
                    
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦æ ¼è¨€ã‚’é¸æŠï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
                    if 'recent_maxims' not in st.session_state:
                        st.session_state.recent_maxims = []
                    exclude_quotes = set(st.session_state.recent_maxims[-10:])
                    quote_text = select_relevant_quote(keywords, exclude_quotes=exclude_quotes)
                    
                    # é¸æŠã—ãŸæ ¼è¨€ã‚’å±¥æ­´ã«è¿½åŠ 
                    if quote_text and quote_text not in st.session_state.recent_maxims:
                        st.session_state.recent_maxims.append(quote_text)
                        if len(st.session_state.recent_maxims) > 20:
                            st.session_state.recent_maxims.pop(0)
                    
                    st.success(f"ã€Œ{quote_text}ã€")
                    
                    # å¼•ç”¨å…ƒã‚’è¡¨ç¤º
                    quote_obj = None
                    for q in FAMOUS_QUOTES:
                        if q['quote'] == quote_text:
                            quote_obj = q
                            break
                    
                    if quote_obj:
                        st.caption(f"*å‡ºå…¸: {quote_obj['source']} - {quote_obj['origin']}*")
                        with st.expander("è©³ç´°ãªå¼•ç”¨æƒ…å ±"):
                            st.write(f"**å‡ºå…¸**: {quote_obj['source']}")
                            st.write(f"**ç”±æ¥**: {quote_obj['origin']}")
                            st.write(f"**å‚è€ƒ**: {quote_obj['reference']}")
                else:
                    st.info("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ†ã‚­ã‚¹ãƒˆã‚’è©³ã—ãå…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    
    elif app_mode == "è¨€è‘‰ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼çƒä½“è¦–è¦šåŒ–":
        st.header("è¨€è‘‰ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã§ç¹‹ãŒã‚‹çƒä½“è¦–è¦šåŒ–")
        st.markdown("å…¥åŠ›ã—ãŸè¨€è‘‰ã‚’ä¸­å¿ƒã«ã€QUBOã‚¨ãƒãƒ«ã‚®ãƒ¼ã§é–¢é€£ã™ã‚‹è¨€è‘‰ãŒç¹‹ãŒã‚Šã¾ã™")
        
        user_input = st.text_input(
            "é¡˜ã„ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder="ä¾‹ï¼šä¸–ç•Œå¹³å’Œã«è²¢çŒ®ã§ãã‚‹äººé–“ã«ãªã‚‹",
            value="ä¸–ç•Œå¹³å’Œã«è²¢çŒ®ã§ãã‚‹äººé–“ã«ãªã‚‹"
        )
        
        if st.button("å¯è¦–åŒ–"):
            if not user_input.strip():
                st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            else:
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
                keywords = extract_keywords(user_input)
                st.write(f"**æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {', '.join(keywords)}")
                
                # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é¸æŠã‚’åæ˜ ï¼‰
                network = build_word_network(
                    keywords, 
                    GLOBAL_WORDS_DATABASE, 
                    n_neighbors=20,
                    selected_character=SELECTED_CHARACTER,
                    selected_attribute=SELECTED_ATTRIBUTE,
                    char_master=CHAR_MASTER
                )
                
                # 3Dé…ç½®
                center_indices = [i for i, word in enumerate(network['words']) if word in keywords]
                positions = place_words_on_sphere(len(network['words']), center_indices)
                
                # 3Då¯è¦–åŒ–
                fig = create_3d_network_plot(network, positions, center_indices)
                st.plotly_chart(fig, use_container_width=True)
                
                # æ ¼è¨€ã‚’è¡¨ç¤ºï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ï¼‰
                if 'recent_maxims' not in st.session_state:
                    st.session_state.recent_maxims = []
                exclude_quotes = set(st.session_state.recent_maxims[-10:])
                quote_text = select_relevant_quote(keywords, exclude_quotes=exclude_quotes)
                
                # é¸æŠã—ãŸæ ¼è¨€ã‚’å±¥æ­´ã«è¿½åŠ 
                if quote_text and quote_text not in st.session_state.recent_maxims:
                    st.session_state.recent_maxims.append(quote_text)
                    if len(st.session_state.recent_maxims) > 20:
                        st.session_state.recent_maxims.pop(0)
                
                st.markdown("---")
                st.subheader("ç¥è¨—ï¼ˆOracleï¼‰")
                st.success(f"ã€Œ{quote_text}ã€")
                
                # å¼•ç”¨å…ƒã‚’è¡¨ç¤º
                quote_obj = None
                for q in FAMOUS_QUOTES:
                    if q['quote'] == quote_text:
                        quote_obj = q
                        break
                
                if quote_obj:
                    st.caption(f"*å‡ºå…¸: {quote_obj['source']} - {quote_obj['origin']}*")
                    with st.expander("è©³ç´°ãªå¼•ç”¨æƒ…å ±"):
                        st.write(f"**å‡ºå…¸**: {quote_obj['source']}")
                        st.write(f"**ç”±æ¥**: {quote_obj['origin']}")
                        st.write(f"**å‚è€ƒ**: {quote_obj['reference']}")
                
                st.markdown("**ã‚ãªãŸã®è¦³æ¸¬ãŒã€ã“ã®ä¸–ç•Œç·šã‚’ç¢ºå®šã•ã›ã¾ã—ãŸã€‚**")
    
    elif app_mode == "çµµé¦¬ç´ã‚":
        st.header("ğŸ‹ çµµé¦¬ç´ã‚")
        st.markdown("é¡˜ã„ã‚’çµµé¦¬ã«æ›¸ã„ã¦ç´ã‚ã‚‹ã¨ã€ç§‹è‘‰ä¸‰å°ºåŠå¤§æ¨©ç¾ãŒç¾ã‚Œã¦ç¥è¨—ã‚’æˆã‘ã¦ãã ã•ã„ã¾ã™")
        
        # çµµé¦¬ã®èª¬æ˜
        st.info("""
        **çµµé¦¬ã¨ã¯**: ç¥ç¤¾ã‚„å¯ºé™¢ã«é¡˜ã„äº‹ã‚’æ›¸ã„ã¦å¥‰ç´ã™ã‚‹æœ¨ã®æ¿ã§ã™ã€‚
        é¡˜ã„ã‚’æ›¸ã„ã¦ç´ã‚ã‚‹ã“ã¨ã§ã€ç¥æ§˜ã«é¡˜ã„ãŒå±Šãã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
        """)
        
        # çµµé¦¬å…¥åŠ›
        ema_text = st.text_area(
            "çµµé¦¬ã«é¡˜ã„ã‚’æ›¸ã„ã¦ãã ã•ã„",
            placeholder="ä¾‹ï¼šå¥åº·ã§éã”ã›ã¾ã™ã‚ˆã†ã«ã€ä»•äº‹ãŒã†ã¾ãã„ãã¾ã™ã‚ˆã†ã«ã€å®¶æ—ãŒå¹¸ã›ã§ã‚ã‚Šã¾ã™ã‚ˆã†ã«...",
            height=150,
            help="ã‚ãªãŸã®é¡˜ã„ã‚„æ‚©ã¿ã‚’è‡ªç”±ã«æ›¸ã„ã¦ãã ã•ã„"
        )
        
        # LLMä½¿ç”¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        col1, col2 = st.columns(2)
        with col1:
            use_llm_ema = st.checkbox(
                "ğŸ¤– LLMã§ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸç¥è¨—ã‚’ç”Ÿæˆ",
                value=False,
                help="LLMã‚’ä½¿ç”¨ã—ã¦ã€ã‚ˆã‚Šãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸç¥è¨—ã‚’ç”Ÿæˆã—ã¾ã™ï¼ˆç„¡å„Ÿã§ä½¿ç”¨å¯èƒ½ï¼‰"
            )
        with col2:
            if use_llm_ema:
                llm_type_ema = st.selectbox(
                    "LLMã®ç¨®é¡",
                    ["huggingface", "ollama"],
                    index=0,
                    help="Hugging Faceï¼ˆç„¡å„Ÿï¼‰ã¾ãŸã¯Ollamaï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰ã‚’é¸æŠ"
                )
            else:
                llm_type_ema = "huggingface"
        
        if st.button("ğŸ‹ çµµé¦¬ã‚’ç´ã‚ã‚‹", type="primary", use_container_width=True):
            if not ema_text.strip():
                st.warning("é¡˜ã„ã‚’æ›¸ã„ã¦ã‹ã‚‰ç´ã‚ã¦ãã ã•ã„")
            else:
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡
                if 'show_character' not in st.session_state:
                    st.session_state.show_character = False
                
                st.session_state.show_character = True
                
                # çµµé¦¬ãŒç´ã‚ã‚‰ã‚Œã‚‹æ¼”å‡º
                st.success("âœ¨ çµµé¦¬ãŒç´ã‚ã‚‰ã‚Œã¾ã—ãŸ...")
                
                # é¡˜ã„ã‚’åˆ†æã—ã¦ç¥è¨—ã‚’ç”Ÿæˆ
                m = infer_mood(ema_text)
                Q_today = build_qubo_from_mood(m)
                
                # Optunaã‚’ä½¿ã£ãŸæœ€é©åŒ–ï¼ˆé€²æ—è¡¨ç¤ºä»˜ãï¼‰
                optuna_container = st.empty()
                sols, study = solve_all_with_optuna(Q_today, use_hierarchical=True, 
                                                     progress_container=optuna_container, n_trials=50)
                
                # Optunaã®å¯è¦–åŒ–ï¼ˆå…¨ã¦ã®å¯è¦–åŒ–ã‚’è¡¨ç¤ºï¼‰
                if study is not None and OPTUNA_AVAILABLE:
                    with st.expander("ğŸ“Š QUBOæœ€é©åŒ–ã®è©³ç´°", expanded=False):
                        # ã‚¿ãƒ–ã§å¯è¦–åŒ–ã‚’æ•´ç†
                        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
                            "ğŸ“ˆ æœ€é©åŒ–å±¥æ­´", 
                            "ğŸ¯ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é‡è¦åº¦", 
                            "ğŸ”„ ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ãƒˆ",
                            "ğŸ—ºï¸ ç­‰é«˜ç·š",
                            "ğŸ“Š ã‚¹ãƒ©ã‚¤ã‚¹",
                            "â±ï¸ ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³"
                        ])
                        
                        with tab1:
                            try:
                                fig_history = plot_optimization_history(study)
                                st.plotly_chart(fig_history, use_container_width=True)
                                st.caption("æœ€é©åŒ–ã®é€²è¡ŒçŠ¶æ³ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                            except Exception as e:
                                st.write(f"æœ€é©åŒ–å±¥æ­´ã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                        
                        with tab2:
                            try:
                                fig_importance = plot_param_importances(study)
                                st.plotly_chart(fig_importance, use_container_width=True)
                                st.caption("å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é‡è¦åº¦ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                            except Exception as e:
                                st.write(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é‡è¦åº¦ã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                        
                        with tab3:
                            try:
                                if len(study.trials) > 0:
                                    fig_parallel = plot_parallel_coordinate(study)
                                    st.plotly_chart(fig_parallel, use_container_width=True)
                                    st.caption("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é–“ã®é–¢ä¿‚ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚")
                                else:
                                    st.info("ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ãƒˆã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€è¤‡æ•°ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ãŒå¿…è¦ã§ã™ã€‚")
                            except Exception as e:
                                st.write(f"ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ãƒˆã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                        
                        with tab4:
                            try:
                                if len(study.trials) > 0:
                                    # æœ€åˆã®2ã¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç­‰é«˜ç·šã‚’è¡¨ç¤º
                                    params = list(study.trials[0].params.keys()) if study.trials else []
                                    if len(params) >= 2:
                                        fig_contour = plot_contour(study, params=[params[0], params[1]])
                                        st.plotly_chart(fig_contour, use_container_width=True)
                                        st.caption(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€Œ{params[0]}ã€ã¨ã€Œ{params[1]}ã€ã®é–¢ä¿‚ã‚’ç­‰é«˜ç·šã§è¡¨ç¤ºã—ã¾ã™ã€‚")
                                    else:
                                        st.info("ç­‰é«˜ç·šã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€å°‘ãªãã¨ã‚‚2ã¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚")
                                else:
                                    st.info("ç­‰é«˜ç·šã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€è¤‡æ•°ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ãŒå¿…è¦ã§ã™ã€‚")
                            except Exception as e:
                                st.write(f"ç­‰é«˜ç·šã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                        
                        with tab5:
                            try:
                                if len(study.trials) > 0:
                                    fig_slice = plot_slice(study)
                                    st.plotly_chart(fig_slice, use_container_width=True)
                                    st.caption("å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚¹ãƒ©ã‚¤ã‚¹ãƒ—ãƒ­ãƒƒãƒˆã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                                else:
                                    st.info("ã‚¹ãƒ©ã‚¤ã‚¹ãƒ—ãƒ­ãƒƒãƒˆã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€è¤‡æ•°ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ãŒå¿…è¦ã§ã™ã€‚")
                            except Exception as e:
                                st.write(f"ã‚¹ãƒ©ã‚¤ã‚¹ãƒ—ãƒ­ãƒƒãƒˆã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                        
                        with tab6:
                            try:
                                if len(study.trials) > 0:
                                    fig_timeline = plot_timeline(study)
                                    st.plotly_chart(fig_timeline, use_container_width=True)
                                    st.caption("æœ€é©åŒ–ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                                else:
                                    st.info("ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€è¤‡æ•°ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ãŒå¿…è¦ã§ã™ã€‚")
                            except Exception as e:
                                st.write(f"ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã®å¯è¦–åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                
                # ãŠã¿ãã˜ï¼ˆMoodã«å¿œã˜ã¦å¤‰åŒ–ï¼‰
                pool = sols[:6]
                T = temperature_from_mood(m, SELECTED_CHARACTER)
                e_pick, x_pick = boltzmann_sample(pool, T=T)
                
                # ãƒ‡ãƒãƒƒã‚°: è§£ãƒ™ã‚¯ãƒˆãƒ«ã®å†…å®¹ã‚’ç¢ºèª
                if len(x_pick) >= 32:
                    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ•°ï¼ˆ20ã€œ31ï¼‰ãŒé¸ã°ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
                    c_start = 20
                    selected_char_indices = [i for i in range(c_start, min(c_start + 12, len(x_pick))) if i < len(x_pick) and x_pick[i] == 1]
                    if not selected_char_indices:
                        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒé¸ã°ã‚Œã¦ã„ãªã„å ´åˆã€Moodã‹ã‚‰é¸æŠ
                        st.warning("âš ï¸ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¤‰æ•°ãŒé¸ã°ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Moodã‹ã‚‰é¸æŠã—ã¾ã™ã€‚")
                
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã®çµæœã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                keywords_ema = extract_keywords_safe(ema_text, top_n=10)
                if keywords_ema:
                    with st.expander("ğŸ”‘ æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", expanded=False):
                        st.write(f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {', '.join(keywords_ema)}")
                
                card = oracle_card(e_pick, x_pick, mood=m, use_hierarchical=True, context_text=ema_text, use_llm=use_llm_ema, llm_type=llm_type_ema)
                
                # é¸ã°ã‚ŒãŸç¥ã‚’å–å¾—
                selected_god = card['god'] if 'god' in card else select_god_from_mood(m)
                
                # å¾…æ©Ÿæ¼”å‡ºï¼ˆStreamlitã§ã¯time.sleep()ã¯éæ¨å¥¨ã®ãŸã‚ã€spinnerã®ã¿ä½¿ç”¨ï¼‰
                # time.sleep()ã¯å‰Šé™¤ï¼ˆStreamlitã®éåŒæœŸå‡¦ç†ã¨ç«¶åˆã™ã‚‹ãŸã‚ï¼‰
                
                # é¸ã°ã‚ŒãŸç¥ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’è¡¨ç¤º
                character_html = render_god_character(selected_god, LOADED_GODS)
                st.components.v1.html(character_html, height=400)
                
                st.markdown("---")
                st.subheader(f"ğŸ”® {selected_god['name']}ã‹ã‚‰ã®ç¥è¨—")
                
                # é¸ã°ã‚ŒãŸæ ¼è¨€ã®å¼•ç”¨å…ƒæƒ…å ±ã‚’åé›†
                sources_text = []
                if card.get('picks') and len(card['picks']) > 0:
                    for pick in card['picks']:
                        source_info = get_maxim_source(pick)
                        sources_text.append(f"- {pick}\n  *å‡ºå…¸: {source_info['source']} - {source_info['origin']}*")
                else:
                    # æ ¼è¨€ãŒç©ºã®å ´åˆã€é¸ã°ã‚ŒãŸç¥ã®æ ¼è¨€ã‚’ä½¿ç”¨
                    if selected_god and selected_god.get("maxim"):
                        maxim = selected_god["maxim"]
                        source_info = get_maxim_source(maxim)
                        sources_text.append(f"- {maxim}\n  *å‡ºå…¸: {source_info['source']} - {source_info['origin']}*")
                    elif selected_god and selected_god.get("description"):
                        desc = selected_god["description"]
                        sources_text.append(f"- {desc}\n  *å‡ºå…¸: {selected_god.get('name', 'ç¥è¨—')}*")
                    else:
                        sources_text.append("- ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚\n  *å‡ºå…¸: ä¼çµ±çš„ãªæ•™ãˆ*")
                
                # LLMç”Ÿæˆã®ç¥è¨—ã‚’ã€Œé¸ã°ã‚ŒãŸç¸ã€ã«çµ±åˆ
                if card.get('llm_oracle') and use_llm_ema and card['llm_oracle'].strip():
                    # LLMç”Ÿæˆã®ç¥è¨—ã‚’æœ€åˆã«è¿½åŠ 
                    llm_text = card['llm_oracle'].strip()
                    sources_text.insert(0, f"ğŸ¤– {llm_text}\n  *å‡ºå…¸: LLMç”Ÿæˆ - ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸç¥è¨—*")
                elif use_llm_ema:
                    # LLMç”Ÿæˆã«å¤±æ•—ã—ãŸå ´åˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                    sources_text.insert(0, f"ğŸ’­ LLMç”Ÿæˆã¯ç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚æ ¼è¨€ãƒ™ãƒ¼ã‚¹ã®ç¥è¨—ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚\n  *å‡ºå…¸: ä¼çµ±çš„ãªæ•™ãˆ*")
                
                # ç¥è¨—ã‚«ãƒ¼ãƒ‰ã‚’ç¾ã—ãè¡¨ç¤º
                st.info(f"""
**ã‚¨ãƒãƒ«ã‚®ãƒ¼**: {card['energy']:.3f}

**é¸ã°ã‚ŒãŸç¸**:
{chr(10).join(sources_text) if sources_text else "- ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚"}

**ã“ã¨ã°**:
ã€Œ{card.get('poem', 'ä»Šã“ã®ç¬é–“ã‚’å¤§åˆ‡ã«ã€‚ã™ã¹ã¦ã¯ç¸ã§ç¹‹ãŒã£ã¦ã„ã‚‹ã€‚')}ã€

**æ¬¡ã®ä¸€æ­©**:
{card.get('hint', 'ä¸€æ­©ãšã¤é€²ã‚“ã§ã„ãã¾ã—ã‚‡ã†ã€‚')}
""")
                
                st.caption(f"â€»æºã‚‰ã(T)={T:.2f}ï¼ˆå¤§ãã„ã»ã©å¶ç„¶æ€§ãŒå¢—ãˆã¾ã™ï¼‰")
                
                # å¿ƒã®å‚¾ãã‚’è¡¨ç¤º
                st.markdown("---")
                st.subheader("ğŸ“Š ã‚ãªãŸã®å¿ƒã®å‚¾ã")
                col1, col2, col3, col4, col5 = st.columns(5)
                with col1:
                    st.metric("ç–²ã‚Œ", f"{m.fatigue:.2f}")
                with col2:
                    st.metric("ä¸å®‰/ç„¦ã‚Š", f"{m.anxiety:.2f}")
                with col3:
                    st.metric("å¥½å¥‡å¿ƒ", f"{m.curiosity:.2f}")
                with col4:
                    st.metric("å­¤ç‹¬", f"{m.loneliness:.2f}")
                with col5:
                    st.metric("æ±ºæ–­", f"{m.decisiveness:.2f}")
                
                # æ„Ÿè¬ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                st.markdown("---")
                st.success("""
                **ğŸ‹ çµµé¦¬ãŒç´ã‚ã‚‰ã‚Œã¾ã—ãŸ**
                
                ç§‹è‘‰ä¸‰å°ºåŠå¤§æ¨©ç¾ãŒã‚ãªãŸã®é¡˜ã„ã‚’èãå±Šã‘ã€ç¥è¨—ã‚’æˆã‘ã¾ã—ãŸã€‚
                ã“ã®ç¥è¨—ã‚’èƒ¸ã«ã€ä¸€æ­©ãšã¤é€²ã‚“ã§ã„ãã¾ã—ã‚‡ã†ã€‚
                """)

if __name__ == "__main__":
    main()
