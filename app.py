# app09.py
# Q-Quest é‡å­ç¥è¨—ï¼ˆapp08ãƒ™ãƒ¼ã‚¹ + STAGE(å­£ç¯€Ã—æ™‚é–“) + QUOTESç¥è¨—ï¼‰
# - Excel(pack) 1æšã§å®Œçµ: VOW/CHAR/AXIS/STAGE/QUOTES
# - ãƒ†ã‚­ã‚¹ãƒˆâ†’èª“é¡˜ãƒ™ã‚¯ãƒˆãƒ«è‡ªå‹•ç”Ÿæˆï¼ˆchar n-gramï¼‰
# - QUBOé¢¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆä½ã„ã»ã©é¸ã°ã‚Œã‚„ã™ã„ï¼‰â†’ æ¸©åº¦(beta)ã§è¦³æ¸¬
# - QUOTESã‚’ã€Œã‚¨ãƒãƒ«ã‚®ãƒ¼çš„ã«è¿‘ã„ã€ã‚‚ã®ã¨ã—ã¦æ¸©åº¦ä»˜ãã§é¸æŠ

import os
import re
import math
import random
from dataclasses import dataclass
from typing import Dict, Tuple, List, Optional

import numpy as np
import pandas as pd
import streamlit as st
from PIL import Image

# ----------------------------
# UI
# ----------------------------
st.set_page_config(page_title="Q-Quest é‡å­ç¥è¨— app09", layout="wide")

APP_TITLE = "ğŸ”® Q-Quest é‡å­ç¥è¨—ï¼ˆapp09ï¼šSTAGEÃ—QUOTESç¥è¨—ï¼‰"

# ----------------------------
# Utility
# ----------------------------
def _safe_float(x, default=0.0) -> float:
    try:
        if pd.isna(x):
            return default
        return float(x)
    except Exception:
        return default

def softmax(x: np.ndarray, temperature: float = 1.0) -> np.ndarray:
    # temperature > 0, larger => flatter
    t = max(1e-9, float(temperature))
    z = (x - np.max(x)) / t
    e = np.exp(z)
    s = e / (np.sum(e) + 1e-12)
    return s

def ensure_cols(df: pd.DataFrame, required: List[str], sheet_name: str):
    miss = [c for c in required if c not in df.columns]
    if miss:
        raise ValueError(f"{sheet_name} ã®åˆ—ãŒä¸è¶³: {miss}\næ¤œå‡ºåˆ—={df.columns.tolist()}")

def vow_key_to_num(v: str) -> int:
    # "VOW_01" -> 1
    m = re.search(r"VOW_(\d+)", str(v))
    return int(m.group(1)) if m else -1

def pick_one_by_prob(items: List, p: np.ndarray):
    idx = np.random.choice(len(items), p=p)
    return items[idx], idx

def normalize01(x: np.ndarray) -> np.ndarray:
    mn, mx = float(np.min(x)), float(np.max(x))
    if mx - mn < 1e-12:
        return np.zeros_like(x)
    return (x - mn) / (mx - mn)

# ----------------------------
# Data model
# ----------------------------
@dataclass
class Pack:
    vow_dict: pd.DataFrame
    axis_dict: pd.DataFrame
    char_master: pd.DataFrame
    char_to_vow: pd.DataFrame
    stage_dict: pd.DataFrame
    stage_to_axis: pd.DataFrame
    quotes: pd.DataFrame

# ----------------------------
# Excel loader (pickle-safe)
# ----------------------------
@st.cache_data(show_spinner=False)
def load_pack_excel_bytes(xlsx_bytes: bytes) -> Pack:
    # é‡è¦: st.cache_data ã§ pickle å¯èƒ½ãªæˆ»ã‚Šå€¤ã«ã™ã‚‹ï¼ˆpandas DF ã¯OKï¼‰
    xls = pd.ExcelFile(xlsx_bytes)

    required_sheets = [
        "VOW_DICT", "AXIS_DICT", "CHAR_MASTER", "CHAR_TO_VOW",
        "STAGE_DICT", "STAGE_TO_AXIS", "QUOTES"
    ]
    for s in required_sheets:
        if s not in xls.sheet_names:
            raise ValueError(f"çµ±åˆExcelã«å¿…è¦ãªã‚·ãƒ¼ãƒˆ '{s}' ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ¤œå‡º={xls.sheet_names}")

    vow_dict = pd.read_excel(xls, "VOW_DICT")
    axis_dict = pd.read_excel(xls, "AXIS_DICT")
    char_master = pd.read_excel(xls, "CHAR_MASTER")
    char_to_vow = pd.read_excel(xls, "CHAR_TO_VOW")
    stage_dict = pd.read_excel(xls, "STAGE_DICT")
    stage_to_axis = pd.read_excel(xls, "STAGE_TO_AXIS")
    quotes = pd.read_excel(xls, "QUOTES")

    # validate columns (ã‚ãªãŸã®Excelä»•æ§˜ã«åˆã‚ã›ã‚‹)
    ensure_cols(vow_dict, ["VOW_ID", "TITLE"], "VOW_DICT")
    ensure_cols(char_master, ["CHAR_ID", "å…¬å¼ã‚­ãƒ£ãƒ©å", "AXIS_SEI", "AXIS_RYU", "AXIS_MA", "AXIS_MAKOTO"], "CHAR_MASTER")
    ensure_cols(char_to_vow, ["CHAR_ID", "IMAGE_FILE", "å…¬å¼ã‚­ãƒ£ãƒ©å"], "CHAR_TO_VOW")
    ensure_cols(stage_dict, ["STAGE_ID", "LABEL"], "STAGE_DICT")
    ensure_cols(stage_to_axis, ["STAGE_ID", "AXIS_SEI", "AXIS_RYU", "AXIS_MA", "AXIS_MAKOTO"], "STAGE_TO_AXIS")
    ensure_cols(quotes, ["QUOTE_ID", "QUOTE", "SOURCE", "LANG"], "QUOTES")

    return Pack(
        vow_dict=vow_dict,
        axis_dict=axis_dict,
        char_master=char_master,
        char_to_vow=char_to_vow,
        stage_dict=stage_dict,
        stage_to_axis=stage_to_axis,
        quotes=quotes,
    )

def load_pack_from_uploader(uploaded_file) -> Pack:
    b = uploaded_file.getvalue()
    return load_pack_excel_bytes(b)

# ----------------------------
# Text -> vow auto vector (char n-gram)
# ----------------------------
def char_ngrams(s: str, n: int = 2) -> List[str]:
    s = re.sub(r"\s+", "", str(s))
    if len(s) < n:
        return [s] if s else []
    return [s[i:i+n] for i in range(len(s)-n+1)]

def build_vow_text_corpus(vow_dict: pd.DataFrame) -> Dict[str, str]:
    # vow_text = "LABEL TITLE SUBTITLE DESCRIPTION_LONG UI_HINT" ã‚’ã¾ã¨ã‚ã‚‹
    cols = ["VOW_ID", "LABEL", "TITLE", "SUBTITLE", "DESCRIPTION_LONG", "UI_HINT", "TRAIT_FROM_FILE"]
    exists = [c for c in cols if c in vow_dict.columns]
    corpus = {}
    for _, r in vow_dict[exists].iterrows():
        vid = str(r.get("VOW_ID"))
        texts = []
        for c in exists:
            if c == "VOW_ID":
                continue
            v = r.get(c)
            if pd.notna(v):
                texts.append(str(v))
        corpus[vid] = " ".join(texts)
    return corpus

def text_to_vow_auto(text: str, vow_ids: List[str], vow_corpus: Dict[str, str], ngram_n: int = 2) -> np.ndarray:
    # å˜ç´”ãª n-gram é‡ãªã‚Šã‚¹ã‚³ã‚¢ï¼ˆè»½é‡ãƒ»ãƒ­ãƒ¼ã‚«ãƒ«å®Œçµï¼‰
    tx = str(text or "")
    tgrams = set(char_ngrams(tx, ngram_n))
    if not tgrams:
        return np.zeros(len(vow_ids), dtype=float)

    scores = np.zeros(len(vow_ids), dtype=float)
    for i, vid in enumerate(vow_ids):
        c = vow_corpus.get(vid, "")
        cgrams = set(char_ngrams(c, ngram_n))
        if not cgrams:
            scores[i] = 0.0
            continue
        inter = len(tgrams & cgrams)
        # æ­£è¦åŒ–ï¼ˆé•·ã•ã®å½±éŸ¿ã‚’æŠ‘ãˆã‚‹ï¼‰
        scores[i] = inter / (math.sqrt(len(tgrams) * len(cgrams)) + 1e-9)

    # 0..5 ã‚¹ã‚±ãƒ¼ãƒ«ã«å¯„ã›ã‚‹ï¼ˆæœ€å¤§ã‚’ 5 ã«ï¼‰
    mx = float(np.max(scores))
    if mx > 1e-12:
        scores = scores / mx * 5.0
    return scores

def extract_keywords_simple(text: str, topk: int = 8) -> List[str]:
    # å½¢æ…‹ç´ ãªã—ã®ç°¡æ˜“ï¼šæ¼¢å­—/ã²ã‚‰ãŒãª/ã‚«ã‚¿ã‚«ãƒŠã®2-3gramä¸Šä½
    s = re.sub(r"\s+", "", str(text or ""))
    grams = []
    for n in [2, 3]:
        grams += char_ngrams(s, n)
    # è¨˜å·ã£ã½ã„ã‚‚ã®é™¤å»
    grams = [g for g in grams if re.search(r"[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥]", g)]
    if not grams:
        return []
    from collections import Counter
    cnt = Counter(grams)
    return [w for w, _ in cnt.most_common(topk)]

# ----------------------------
# Stage (season Ã— time)
# ----------------------------
def season_from_month(month: int) -> str:
    # æ—¥æœ¬ã®æ„Ÿè¦šï¼ˆã–ã£ãã‚Šï¼‰
    if month in [3, 4, 5]:
        return "SPRING"
    if month in [6, 7, 8]:
        return "SUMMER"
    if month in [9, 10, 11]:
        return "AUTUMN"
    return "WINTER"

def time_slot_from_hour(hour: int) -> str:
    # ã–ã£ãã‚Š4åŒºåˆ†
    if 5 <= hour <= 10:
        return "MORNING"
    if 11 <= hour <= 16:
        return "DAY"
    if 17 <= hour <= 20:
        return "EVENING"
    return "NIGHT"

def build_stage_id(season: str, time_slot: str) -> str:
    return f"{season}_{time_slot}"

def get_stage_axis_weights(pack: Pack, stage_id: str) -> np.ndarray:
    row = pack.stage_to_axis[pack.stage_to_axis["STAGE_ID"].astype(str) == str(stage_id)]
    if row.empty:
        return np.zeros(4, dtype=float)
    r = row.iloc[0]
    return np.array([
        _safe_float(r["AXIS_SEI"]),
        _safe_float(r["AXIS_RYU"]),
        _safe_float(r["AXIS_MA"]),
        _safe_float(r["AXIS_MAKOTO"]),
    ], dtype=float)

# ----------------------------
# Energy model (QUBO "like")
# ----------------------------
def get_vow_cols(df: pd.DataFrame) -> List[str]:
    cols = [c for c in df.columns if re.match(r"VOW_\d+", str(c))]
    # sort by number
    cols.sort(key=lambda x: vow_key_to_num(x))
    return cols

def build_char_matrix(pack: Pack) -> Tuple[pd.DataFrame, np.ndarray, List[str]]:
    c2v = pack.char_to_vow.copy()
    vow_cols = get_vow_cols(c2v)
    if len(vow_cols) == 0:
        raise ValueError("CHAR_TO_VOW ã« VOW_01.. ã®åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    W = c2v[vow_cols].fillna(0).astype(float).to_numpy()  # (n_char, n_vow)
    return c2v, W, vow_cols

def build_char_axis_matrix(pack: Pack) -> Tuple[np.ndarray, List[str]]:
    cm = pack.char_master.copy()
    axis_cols = ["AXIS_SEI", "AXIS_RYU", "AXIS_MA", "AXIS_MAKOTO"]
    A = cm[axis_cols].fillna(0).astype(float).to_numpy()  # (n_char, 4)
    return A, axis_cols

def compute_energy(
    v_mix: np.ndarray,
    W_char_vow: np.ndarray,
    stage_axis_w: np.ndarray,
    A_char_axis: np.ndarray,
    stage_gain: float,
    eps_noise: float,
    rng: np.random.Generator,
) -> np.ndarray:
    # base score: vowsã¨ã®æ•´åˆï¼ˆå¤§ãã„ã»ã©è‰¯ã„ï¼‰ => energy ã¯ä½ã„ã»ã©è‰¯ã„ã®ã§è² ã«ã™ã‚‹
    base_score = W_char_vow @ v_mix  # (n_char,)

    # stage bias: (char_axis â‹… stage_axis_w) ã‚’åŠ ç‚¹ï¼ˆçŠ¶æ³ã«åˆã†è»¸ãŒé«˜ã„ã‚­ãƒ£ãƒ©ã‚’æŠ¼ã™ï¼‰
    stage_score = A_char_axis @ stage_axis_w  # (n_char,)

    # energy: å°ã•ã„ã»ã©é¸ã°ã‚Œã‚„ã™ã„
    noise = rng.normal(0.0, eps_noise, size=base_score.shape[0])
    energy = -(base_score + stage_gain * stage_score) + noise
    return energy

def observe_distribution(energy: np.ndarray, beta: float, n_samples: int, rng: np.random.Generator):
    # p âˆ exp(-beta * energy)
    p = softmax(-beta * energy, temperature=1.0)
    idxs = rng.choice(len(p), size=int(n_samples), replace=True, p=p)
    return p, idxs

# ----------------------------
# QUOTES selection (energy-like)
# ----------------------------
def build_vow_id_list_from_pack(pack: Pack, vow_cols: List[str]) -> List[str]:
    # vow_cols: ["VOW_01",...]
    # pack.vow_dict has VOW_ID like "VOW_01"
    # Keep vow_cols order
    return [str(v) for v in vow_cols]

def quote_score_row(
    r: pd.Series,
    observed_char_id: str,
    top_vow_ids: List[str],
    v_mix_map: Dict[str, float],
    keywords: List[str],
    stage_axis_label: str,
    quote_char_gain: float = 2.0,
    quote_vow_gain: float = 1.2,
    quote_kw_gain: float = 0.25,
    quote_axis_gain: float = 0.5,
) -> float:
    s = 0.0

    # 1) char match
    q_char = str(r.get("CHAR_ID") or "")
    if q_char and q_char == str(observed_char_id):
        s += quote_char_gain

    # 2) vow match
    q_vow = str(r.get("VOW_ID") or "")
    if q_vow:
        s += quote_vow_gain * float(v_mix_map.get(q_vow, 0.0))
        if q_vow in top_vow_ids:
            s += 0.6

    # 3) keyword match (SENSE_TAG or quote text itself)
    q_sense = str(r.get("SENSE_TAG") or "")
    q_text = str(r.get("QUOTE") or "")
    for kw in keywords:
        if kw and (kw in q_sense or kw in q_text):
            s += quote_kw_gain

    # 4) axis tag match (stage axis label is like "é™/æµ/é–“/èª " ã®ã„ãšã‚Œã‹)
    q_axis = str(r.get("AXIS_TAG") or "")
    if stage_axis_label and q_axis and (stage_axis_label in q_axis):
        s += quote_axis_gain

    return float(s)

def pick_quote_temperature(
    quotes_df: pd.DataFrame,
    lang: str,
    observed_char_id: str,
    top_vow_ids: List[str],
    v_mix_map: Dict[str, float],
    keywords: List[str],
    stage_axis_label: str,
    temperature: float,
    topn: int = 30,
    rng: Optional[np.random.Generator] = None,
):
    if rng is None:
        rng = np.random.default_rng()

    df = quotes_df.copy()
    df["LANG"] = df["LANG"].fillna("").astype(str)

    # language filter (ç©ºãªã‚‰å…¨éƒ¨)
    if lang:
        cand = df[df["LANG"].str.lower() == lang.lower()].copy()
        if cand.empty:
            cand = df.copy()
    else:
        cand = df.copy()

    if cand.empty:
        return None, cand

    scores = []
    for _, r in cand.iterrows():
        scores.append(
            quote_score_row(
                r,
                observed_char_id=observed_char_id,
                top_vow_ids=top_vow_ids,
                v_mix_map=v_mix_map,
                keywords=keywords,
                stage_axis_label=stage_axis_label,
            )
        )

    cand["SCORE"] = scores

    # ä¸Šä½å€™è£œã«çµã£ã¦æ¸©åº¦ä»˜ãæŠ½é¸
    cand = cand.sort_values("SCORE", ascending=False)
    cand_top = cand.head(int(topn)).copy()

    # ã‚¹ã‚³ã‚¢â†’ç¢ºç‡ï¼ˆæ¸©åº¦ãŒé«˜ã„ã»ã©ãƒ©ãƒ³ãƒ€ãƒ ï¼‰
    # ã“ã“ã¯ "energy-like": scoreãŒé«˜ã„ã»ã©é¸ã°ã‚Œã‚„ã™ã„
    p = softmax(cand_top["SCORE"].to_numpy(dtype=float), temperature=max(1e-6, float(temperature)))

    choice, idx = pick_one_by_prob(cand_top.to_dict("records"), p)
    return choice, cand_top

# ----------------------------
# Image loader
# ----------------------------
@st.cache_data(show_spinner=False)
def load_image(path: str) -> Optional[Image.Image]:
    try:
        if not path or not os.path.exists(path):
            return None
        return Image.open(path)
    except Exception:
        return None

# ----------------------------
# Main UI
# ----------------------------
st.title(APP_TITLE)

with st.sidebar:
    st.header("ğŸ“ ãƒ‡ãƒ¼ã‚¿")

    pack_file = st.file_uploader(
        "çµ±åˆExcelï¼ˆpackï¼‰",
        type=["xlsx"],
        help="quantum_shintaku_pack_v3_with_sense_20260213_oposite_modify.xlsx ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    )

    img_dir = st.text_input(
        "ğŸ–¼ï¸ ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ï¼ˆç›¸å¯¾/çµ¶å¯¾ï¼‰",
        value="./assets/images/characters",
        help="ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ: ./assets/images/characters ã§OKã€‚Windowsçµ¶å¯¾ãƒ‘ã‚¹ã§ã‚‚å¯ã€‚",
    )

    st.divider()
    st.header("ğŸ•°ï¸ å­£ç¯€Ã—æ™‚é–“ï¼ˆStageï¼‰")
    auto_now = st.checkbox("ç¾åœ¨æ™‚åˆ»ã‹ã‚‰è‡ªå‹•æ¨å®š", value=True)

    if auto_now:
        from datetime import datetime
        now = datetime.now()
        month = now.month
        hour = now.hour
    else:
        month = st.slider("æœˆ", 1, 12, 2)
        hour = st.slider("æ™‚åˆ»ï¼ˆ0-23ï¼‰", 0, 23, 21)

    season = season_from_month(month)
    time_slot = time_slot_from_hour(hour)
    stage_id_guess = build_stage_id(season, time_slot)

    # stage override (å­˜åœ¨ã—ãªã„stage_idã‚’é¿ã‘ã‚‹)
    stage_ids = []
    stage_label_map = {}
    if pack_file is not None:
        try:
            tmp_pack = load_pack_from_uploader(pack_file)
            for _, r in tmp_pack.stage_dict.iterrows():
                sid = str(r["STAGE_ID"])
                stage_ids.append(sid)
                stage_label_map[sid] = str(r.get("LABEL") or sid)
        except Exception:
            stage_ids = []
            stage_label_map = {}

    if stage_ids:
        default_idx = stage_ids.index(stage_id_guess) if stage_id_guess in stage_ids else 0
        stage_id = st.selectbox(
            "STAGE_IDï¼ˆæ‰‹å‹•ä¸Šæ›¸ãå¯ï¼‰",
            options=stage_ids,
            index=default_idx,
            format_func=lambda x: f"{x}  |  {stage_label_map.get(x, '')}",
        )
    else:
        stage_id = stage_id_guess
        st.caption(f"STAGE_ID æ¨å®š: {stage_id_guess}ï¼ˆpackæœªèª­è¾¼ã®ãŸã‚å€™è£œä¸€è¦§ã¯å¾Œã§å‡ºã¾ã™ï¼‰")

    st.divider()
    st.header("ğŸ›ï¸ æºã‚‰ãï¼ˆè¦³æ¸¬ã®ãƒ–ãƒ¬ï¼‰")
    beta = st.slider("Î²ï¼ˆå¤§â†’æœ€å°ã‚¨ãƒãƒ«ã‚®ãƒ¼å¯„ã‚Š / å°â†’å¤šæ§˜ï¼‰", 0.2, 6.0, 2.2, 0.1)
    eps_noise = st.slider("å¾®å°ãƒã‚¤ã‚º Îµï¼ˆã‚¨ãƒãƒ«ã‚®ãƒ¼ã«åŠ ãˆã‚‹ï¼‰", 0.0, 0.30, 0.08, 0.01)
    n_samples = st.slider("ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆè¦³æ¸¬åˆ†å¸ƒï¼‰", 50, 1000, 300, 50)

    st.divider()
    st.header("ğŸ§  ãƒ†ã‚­ã‚¹ãƒˆâ†’èª“é¡˜ï¼ˆè‡ªå‹•ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰")
    ngram_n = st.selectbox("n-gram", [2, 3], index=0)
    mix_alpha = st.slider("mixæ¯”ç‡ Î±ï¼ˆ1=ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®ã¿ / 0=ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼‰", 0.0, 1.0, 0.55, 0.05)

    st.divider()
    st.header("ğŸ—£ï¸ QUOTESç¥è¨—ï¼ˆæ¸©åº¦ä»˜ãé¸æŠï¼‰")
    quote_lang = st.selectbox("LANG", ["ja", "en", ""], index=0, help="ç©ºã¯å…¨è¨€èª")
    quote_temp = st.slider("æ ¼è¨€æ¸©åº¦ï¼ˆé«˜â†’ãƒ©ãƒ³ãƒ€ãƒ  / ä½â†’ä¸Šä½å›ºå®šï¼‰", 0.2, 3.0, 1.2, 0.1)

# Load pack
if pack_file is None:
    st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ **çµ±åˆExcelï¼ˆpackï¼‰** ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

try:
    pack = load_pack_from_uploader(pack_file)
except Exception as e:
    st.error(f"çµ±åˆExcelã®è§£æã«å¤±æ•—: {e}")
    st.stop()

# Build matrices
c2v_df, W_char_vow, vow_cols = build_char_matrix(pack)
A_char_axis, axis_cols = build_char_axis_matrix(pack)

# vow ids in order (VOW_01..)
vow_ids = build_vow_id_list_from_pack(pack, vow_cols)

# VOW_DICT map
vow_title_map = {}
vow_desc_map = {}
for _, r in pack.vow_dict.iterrows():
    vid = str(r["VOW_ID"])
    vow_title_map[vid] = str(r.get("TITLE") or vid)
    # å¸¸æ™‚è¡¨ç¤ºã—ãŸã„èª¬æ˜ï¼ˆçŸ­ã„ã‚‚ã®ï¼‰
    hint = str(r.get("SUBTITLE") or r.get("UI_HINT") or r.get("LABEL") or "")
    vow_desc_map[vid] = hint

# Stage axis weights + stage axis label (æœ€ã‚‚åŠ¹ã„ã¦ã‚‹è»¸)
stage_axis_w = get_stage_axis_weights(pack, stage_id)
axis_labels = ["é™", "æµ", "é–“", "èª "]
stage_axis_label = axis_labels[int(np.argmax(np.abs(stage_axis_w)))] if np.any(stage_axis_w) else ""

# Main layout
left, right = st.columns([1.05, 1.0], gap="large")

with left:
    st.subheader("Step 1ï¼šèª“é¡˜å…¥åŠ›ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼‰ï¼‹ ãƒ†ã‚­ã‚¹ãƒˆï¼ˆè‡ªå‹•ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰")

    user_text = st.text_area(
        "ã‚ãªãŸã®çŠ¶æ³ã‚’ä¸€æ–‡ã§ï¼ˆä¾‹ï¼šç–²ã‚Œã¦ã„ã¦æ±ºæ–­ãŒã§ããªã„ / æ–°ã—ã„æŒ‘æˆ¦ãŒæ€–ã„ ãªã©ï¼‰",
        value="",
        height=90,
    )

    st.caption("ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼å…¥åŠ›ã¯ **TITLEã‚’å¸¸æ™‚è¡¨ç¤º** ã—ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã®è‡ªå‹•æ¨å®šã¨ mix ã—ã¾ã™ã€‚")

    manual = np.zeros(len(vow_ids), dtype=float)

    for i, vid in enumerate(vow_ids):
        title = vow_title_map.get(vid, vid)
        hint = vow_desc_map.get(vid, "")
        label = f"{vid}ï½œ{title}"
        manual[i] = st.slider(
            label,
            0.0, 5.0, 0.0, 0.5,
            help=hint if hint else None,
            key=f"vow_slider_{vid}",
        )

    # Auto vector
    vow_corpus = build_vow_text_corpus(pack.vow_dict)
    auto = text_to_vow_auto(user_text, vow_ids, vow_corpus, ngram_n=ngram_n)

    # Mix
    v_mix = mix_alpha * manual + (1.0 - mix_alpha) * auto

    # Show vector table
    vec_df = pd.DataFrame({
        "VOW_ID": vow_ids,
        "TITLE": [vow_title_map.get(v, v) for v in vow_ids],
        "manual(0-5)": np.round(manual, 3),
        "auto(0-5)": np.round(auto, 3),
        "mix(0-5)": np.round(v_mix, 3),
    })
    with st.expander("ğŸ” èª“é¡˜ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆmanual / auto / mixï¼‰"):
        st.dataframe(vec_df, use_container_width=True, hide_index=True)

    # Buttons
    observe_btn = st.button("ğŸ§ª è¦³æ¸¬ã™ã‚‹ï¼ˆQUBOã‹ã‚‰æŠ½å‡ºï¼‰", use_container_width=True)

# Compute energies & distribution
rng = np.random.default_rng()

# stage gain (å½±éŸ¿é‡ã¯UIåŒ–ã—ã¦ã‚‚è‰¯ã„ãŒã€ã¾ãšå›ºå®š)
stage_gain = 0.35

energy = compute_energy(
    v_mix=v_mix,
    W_char_vow=W_char_vow,
    stage_axis_w=stage_axis_w,
    A_char_axis=A_char_axis,
    stage_gain=stage_gain,
    eps_noise=eps_noise,
    rng=rng
)

p_char, sample_idxs = observe_distribution(energy, beta=beta, n_samples=n_samples, rng=rng)

# chars list
char_ids = c2v_df["CHAR_ID"].astype(str).tolist()
char_names = c2v_df["å…¬å¼ã‚­ãƒ£ãƒ©å"].astype(str).tolist()
img_files = c2v_df["IMAGE_FILE"].astype(str).tolist()

# If not pressed, still show â€œcurrentâ€ best (argmin energy)
best_idx = int(np.argmin(energy))
observed_idx = int(sample_idxs[-1]) if observe_btn else best_idx
observed_char_id = char_ids[observed_idx]
observed_char_name = char_names[observed_idx]
observed_img_file = img_files[observed_idx]

# Contributing vows (Top)
# Use char's vow weights Ã— mix
char_w = W_char_vow[observed_idx, :]
contrib = char_w * v_mix
top_k = 6
top_idx = np.argsort(contrib)[::-1][:top_k]
top_vow_ids = [vow_ids[i] for i in top_idx]

v_mix_map = {vow_ids[i]: float(v_mix[i]) for i in range(len(vow_ids))}

# Keywords from user text
keywords = extract_keywords_simple(user_text, topk=10)

# Pick quote
quote_choice, quote_top = pick_quote_temperature(
    quotes_df=pack.quotes,
    lang=quote_lang,
    observed_char_id=observed_char_id,
    top_vow_ids=top_vow_ids,
    v_mix_map=v_mix_map,
    keywords=keywords,
    stage_axis_label=stage_axis_label,
    temperature=quote_temp,
    topn=30,
    rng=rng
)

# Build oracle text
top_titles = [vow_title_map.get(v, v) for v in top_vow_ids[:3]]
top_titles_txt = "ãƒ»".join(top_titles) if top_titles else "ï¼ˆæœªè¨­å®šï¼‰"

quote_text = ""
quote_source = ""
if quote_choice:
    quote_text = str(quote_choice.get("QUOTE") or "").strip()
    quote_source = str(quote_choice.get("SOURCE") or "").strip()

oracle_lines = []
if user_text.strip():
    oracle_lines.append(f"ã€Œ{user_text.strip()}ã€ã®å¥¥ã«ã€**{top_titles_txt}** ãŒè¦‹ãˆã¦ã„ã‚‹ã€‚")
else:
    oracle_lines.append(f"ã„ã¾ã®æ³¢ã¯ **{top_titles_txt}** ã«å¯„ã£ã¦ã„ã‚‹ã€‚")

if stage_axis_label:
    oracle_lines.append(f"å­£ç¯€Ã—æ™‚é–“ã®æ°—é…ï¼ˆStageï¼‰ã¯ **{stage_axis_label}** ã‚’å¼·ã‚ã‚‹ã€‚")

if quote_text:
    oracle_lines.append(f"æ ¼è¨€ï¼šã€{quote_text}ã€")
    if quote_source:
        oracle_lines.append(f"â€” {quote_source}")

oracle = "\n".join(oracle_lines)

# Right column outputs
with right:
    st.subheader("Step 3ï¼šçµæœï¼ˆè¦³æ¸¬ã•ã‚ŒãŸç¥ï¼‹ç†ç”±ï¼‹QUOTESç¥è¨—ï¼‰")

    # Table of top 3 by energy
    rank_idx = np.argsort(energy)[:3]
    rank_df = pd.DataFrame({
        "é †ä½": [1, 2, 3],
        "CHAR_ID": [char_ids[i] for i in rank_idx],
        "ç¥": [char_names[i] for i in rank_idx],
        "energyï¼ˆä½ã„ã»ã©é¸ã°ã‚Œã‚„ã™ã„ï¼‰": [float(np.round(energy[i], 4)) for i in rank_idx],
        "ç¢ºç‡pï¼ˆsoftmaxï¼‰": [float(np.round(p_char[i], 4)) for i in rank_idx],
    })
    st.dataframe(rank_df, use_container_width=True, hide_index=True)

    st.markdown(f"### ğŸŒŸ ä»Šå›â€œè¦³æ¸¬â€ã•ã‚ŒãŸç¥ï¼š**{observed_char_name}**ï¼ˆ{observed_char_id}ï¼‰")
    st.caption(
        "â€»ã“ã“ã¯ã€Œå˜ç™ºã®è¦³æ¸¬ï¼ˆ1å›æŠ½é¸ï¼‰ã€ã§ã™ã€‚ä¸‹ã®ğŸ“Šè¦³æ¸¬åˆ†å¸ƒï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰ã¯ã€ŒåŒæ¡ä»¶ã§ä½•å›ã‚‚è¦³æ¸¬ã—ãŸã‚‰ã©ã†å‡ºã‚‹ã‹ã€ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã§ã™ã€‚"
        " ãã®ãŸã‚ã€åˆ†å¸ƒã®æœ€å¤šã¨å˜ç™ºã®è¦³æ¸¬çµæœãŒä¸€è‡´ã—ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ï¼ˆæ­£å¸¸æŒ™å‹•ï¼‰ã€‚"
    )

    # Image
    img_path = os.path.join(img_dir, observed_img_file) if observed_img_file else ""
    img = load_image(img_path)
    if img is not None:
        st.image(img, caption=f"{observed_char_name}ï¼ˆ{observed_img_file}ï¼‰", use_container_width=True)
    else:
        st.warning(f"ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {img_path}")

    # Oracle
    st.success(oracle)

    # Contrib table
    contrib_df = pd.DataFrame({
        "VOW": top_vow_ids,
        "TITLE": [vow_title_map.get(v, v) for v in top_vow_ids],
        "mix(v)": [float(np.round(v_mix_map.get(v, 0.0), 3)) for v in top_vow_ids],
        "W(char,v)": [float(np.round(char_w[vow_ids.index(v)], 3)) for v in top_vow_ids],
        "å¯„ä¸(v*w)": [float(np.round(contrib[vow_ids.index(v)], 3)) for v in top_vow_ids],
    })
    st.markdown("#### ğŸ§© å¯„ä¸ã—ãŸèª“é¡˜ï¼ˆTopï¼‰")
    st.dataframe(contrib_df, use_container_width=True, hide_index=True)

    # Quote debug
    st.markdown("#### ğŸ—£ï¸ QUOTESç¥è¨—ï¼ˆæ¸©åº¦ä»˜ãã§é¸æŠï¼‰")
    if quote_text:
        st.info(f"ã€{quote_text}ã€\n\nâ€” {quote_source}")
        with st.expander("ğŸ” æ ¼è¨€å€™è£œTopï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰"):
            show_cols = [c for c in ["QUOTE_ID","QUOTE","SOURCE","LANG","CHAR_ID","VOW_ID","SENSE_TAG","AXIS_TAG","SCORE"] if c in quote_top.columns]
            st.dataframe(quote_top[show_cols].head(10), use_container_width=True, hide_index=True)
    else:
        st.warning("QUOTESã‹ã‚‰æ ¼è¨€ãŒé¸ã¹ã¾ã›ã‚“ã§ã—ãŸï¼ˆLANGãƒ•ã‚£ãƒ«ã‚¿ã‚„ã‚·ãƒ¼ãƒˆå†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼‰ã€‚")

# Visualizations (bottom)
st.divider()
st.subheader("ğŸ“Š å¯è¦–åŒ–ï¼šãƒ†ã‚­ã‚¹ãƒˆã®å½±éŸ¿ãƒ»è¦³æ¸¬åˆ†å¸ƒãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼åœ°å½¢")

colA, colB = st.columns([1, 1], gap="large")

with colA:
    st.markdown("### 1) ãƒ†ã‚­ã‚¹ãƒˆâ†’èª“é¡˜ è‡ªå‹•æ¨å®šã®å½±éŸ¿ï¼ˆauto vs manual vs mixï¼‰")
    plot_df = pd.DataFrame({
        "VOW": vow_ids,
        "manual": manual,
        "auto": auto,
        "mix": v_mix
    })
    st.caption("autoï¼ˆãƒ†ã‚­ã‚¹ãƒˆç”±æ¥ï¼‰ã¨ manualï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼‰ã¨ mix ã®å·®ãŒè¦‹ãˆã‚‹åŒ–ã•ã‚Œã¾ã™ã€‚")
    st.line_chart(plot_df.set_index("VOW"))

    st.markdown("### 2) ã‚¨ãƒãƒ«ã‚®ãƒ¼åœ°å½¢ï¼ˆå…¨å€™è£œï¼‰")
    land_df = pd.DataFrame({
        "CHAR": char_names,
        "energy": energy,
        "p": p_char
    }).sort_values("energy", ascending=True)
    st.bar_chart(land_df.set_index("CHAR")["energy"])

with colB:
    st.markdown("### 3) è¦³æ¸¬åˆ†å¸ƒï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰")
    # histogram of sampled chars
    from collections import Counter
    cnt = Counter(sample_idxs.tolist())
    hist_df = pd.DataFrame({
        "CHAR": [char_names[i] for i in range(len(char_names))],
        "count": [cnt.get(i, 0) for i in range(len(char_names))]
    }).sort_values("count", ascending=False)
    st.bar_chart(hist_df.set_index("CHAR")["count"])

    st.markdown("### 4) ãƒ†ã‚­ã‚¹ãƒˆã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆç°¡æ˜“ï¼‰")
    if keywords:
        st.write(" / ".join(keywords))
    else:
        st.caption("ï¼ˆå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã„/ç©ºã®ãŸã‚ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ï¼‰")

st.caption("Â© Q-Quest / Quantum Shintaku prototype (app09)")
